Metadata(name='MOTSChallenge_val', thing_classes=['None', 'Car', 'Pedestrian'])
Loading sequence 0002
Loading sequence 0005
Loading sequence 0009
Loading sequence 0011
0002
0005
0009
0011
Loaded 2862 images!
../mask_rcnn_R_50_FPN_3x_MOTS/output/model_final.pth
Loading sequence 0002
Loading sequence 0005
Loading sequence 0009
Loading sequence 0011
0002
0005
0009
0011
Loaded 2862 images!
[5m[31mWARNING[0m [32m[03/26 11:33:49 d2.evaluation.coco_evaluation]: [0mjson_file was not found in MetaDataCatalog for 'MOTSChallenge_val'. Trying to convert it to COCO format ...
[32m[03/26 11:33:49 d2.data.datasets.coco]: [0mConverting annotations of dataset 'MOTSChallenge_val' to COCO format ...)
Loading sequence 0002
Loading sequence 0005
Loading sequence 0009
Loading sequence 0011
0002
0005
0009
0011
Loaded 2862 images!
[32m[03/26 11:40:03 d2.data.datasets.coco]: [0mConverting dataset dicts into COCO format
[32m[03/26 11:41:32 d2.data.datasets.coco]: [0mConversion finished, num images: 2862, num annotations: 26892
[32m[03/26 11:41:32 d2.data.datasets.coco]: [0mCaching COCO format annotations at '../mask_rcnn_R_50_FPN_3x_MOTS/output/MOTSChallenge_val_coco_format.json' ...
Loading sequence 0002
Loading sequence 0005
Loading sequence 0009
Loading sequence 0011
0002
0005
0009
0011
Loaded 2862 images!
[32m[03/26 11:50:32 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    None    | 0            |    Car     | 0            | Pedestrian | 26892        |
|            |              |            |              |            |              |
|   total    | 26892        |            |              |            |              |[0m
[32m[03/26 11:50:32 d2.data.common]: [0mSerializing 2862 elements to byte tensors and concatenating them all ...
[32m[03/26 11:50:33 d2.data.common]: [0mSerialized dataset takes 57.16 MiB
[32m[03/26 11:50:33 d2.evaluation.evaluator]: [0mStart inference on 2862 images
[32m[03/26 11:50:35 d2.evaluation.evaluator]: [0mInference done 11/2862. 0.0515 s / img. ETA=0:02:35
[32m[03/26 11:50:40 d2.evaluation.evaluator]: [0mInference done 99/2862. 0.0472 s / img. ETA=0:02:37
[32m[03/26 11:50:45 d2.evaluation.evaluator]: [0mInference done 185/2862. 0.0469 s / img. ETA=0:02:35
[32m[03/26 11:50:50 d2.evaluation.evaluator]: [0mInference done 271/2862. 0.0469 s / img. ETA=0:02:30
[32m[03/26 11:50:55 d2.evaluation.evaluator]: [0mInference done 357/2862. 0.0467 s / img. ETA=0:02:26
[32m[03/26 11:51:00 d2.evaluation.evaluator]: [0mInference done 442/2862. 0.0467 s / img. ETA=0:02:21
[32m[03/26 11:51:05 d2.evaluation.evaluator]: [0mInference done 529/2862. 0.0468 s / img. ETA=0:02:16
[32m[03/26 11:51:10 d2.evaluation.evaluator]: [0mInference done 626/2862. 0.0461 s / img. ETA=0:02:08
[32m[03/26 11:51:15 d2.evaluation.evaluator]: [0mInference done 762/2862. 0.0443 s / img. ETA=0:01:52
[32m[03/26 11:51:20 d2.evaluation.evaluator]: [0mInference done 898/2862. 0.0430 s / img. ETA=0:01:40
[32m[03/26 11:51:25 d2.evaluation.evaluator]: [0mInference done 1033/2862. 0.0420 s / img. ETA=0:01:30
[32m[03/26 11:51:30 d2.evaluation.evaluator]: [0mInference done 1171/2862. 0.0412 s / img. ETA=0:01:20
[32m[03/26 11:51:35 d2.evaluation.evaluator]: [0mInference done 1306/2862. 0.0407 s / img. ETA=0:01:12
[32m[03/26 11:51:40 d2.evaluation.evaluator]: [0mInference done 1438/2862. 0.0403 s / img. ETA=0:01:05
[32m[03/26 11:51:45 d2.evaluation.evaluator]: [0mInference done 1520/2862. 0.0407 s / img. ETA=0:01:02
[32m[03/26 11:51:50 d2.evaluation.evaluator]: [0mInference done 1601/2862. 0.0410 s / img. ETA=0:00:59
[32m[03/26 11:51:55 d2.evaluation.evaluator]: [0mInference done 1683/2862. 0.0414 s / img. ETA=0:00:56
[32m[03/26 11:52:00 d2.evaluation.evaluator]: [0mInference done 1769/2862. 0.0418 s / img. ETA=0:00:53
[32m[03/26 11:52:05 d2.evaluation.evaluator]: [0mInference done 1854/2862. 0.0421 s / img. ETA=0:00:49
[32m[03/26 11:52:10 d2.evaluation.evaluator]: [0mInference done 1939/2862. 0.0423 s / img. ETA=0:00:45
[32m[03/26 11:52:15 d2.evaluation.evaluator]: [0mInference done 2021/2862. 0.0424 s / img. ETA=0:00:42
[32m[03/26 11:52:20 d2.evaluation.evaluator]: [0mInference done 2108/2862. 0.0427 s / img. ETA=0:00:38
[32m[03/26 11:52:25 d2.evaluation.evaluator]: [0mInference done 2194/2862. 0.0429 s / img. ETA=0:00:33
[32m[03/26 11:52:31 d2.evaluation.evaluator]: [0mInference done 2281/2862. 0.0430 s / img. ETA=0:00:29
[32m[03/26 11:52:36 d2.evaluation.evaluator]: [0mInference done 2365/2862. 0.0432 s / img. ETA=0:00:25
[32m[03/26 11:52:41 d2.evaluation.evaluator]: [0mInference done 2451/2862. 0.0433 s / img. ETA=0:00:21
[32m[03/26 11:52:46 d2.evaluation.evaluator]: [0mInference done 2535/2862. 0.0434 s / img. ETA=0:00:16
[32m[03/26 11:52:51 d2.evaluation.evaluator]: [0mInference done 2618/2862. 0.0435 s / img. ETA=0:00:12
[32m[03/26 11:52:56 d2.evaluation.evaluator]: [0mInference done 2703/2862. 0.0436 s / img. ETA=0:00:08
[32m[03/26 11:53:01 d2.evaluation.evaluator]: [0mInference done 2788/2862. 0.0437 s / img. ETA=0:00:03
[32m[03/26 11:53:05 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:30.929597 (0.052828 s / img per device, on 1 devices)
[32m[03/26 11:53:05 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:05 (0.043786 s / img per device, on 1 devices)
[32m[03/26 11:53:05 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/26 11:53:05 d2.evaluation.coco_evaluation]: [0mSaving results to ../mask_rcnn_R_50_FPN_3x_MOTS/output/coco_instances_results.json
[32m[03/26 11:53:05 d2.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=90.51s).
Accumulating evaluation results...
DONE (t=0.22s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[32m[03/26 11:54:36 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.000 | 0.000  | 0.000  | 0.000 | 0.000 | 0.000 |
[32m[03/26 11:54:36 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP   | category   | AP   | category   | AP    |
|:-----------|:-----|:-----------|:-----|:-----------|:------|
| None       | nan  | Car        | nan  | Pedestrian | 0.000 |
../mask_rcnn_R_50_FPN_MOTS/output/model_final.pth
