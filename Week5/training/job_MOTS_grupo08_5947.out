/home/grupo08/datasets/MOTSChallenge/instances_txt/
.jpg
Loading sequence 0002
Loading sequence 0005
Loading sequence 0009
Loading sequence 0011
0002
0005
0009
0011
Loaded 2862 images!
[32m[03/26 18:17:34 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=4, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
/home/grupo08/datasets/MOTSChallenge/instances_txt/
.jpg
Loading sequence 0002
Loading sequence 0005
Loading sequence 0009
Loading sequence 0011
0002
0005
0009
0011
Loaded 2862 images!
[32m[03/26 18:24:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2862 images left.
[32m[03/26 18:24:57 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    None    | 0            |    Car     | 0            | Pedestrian | 26892        |
|            |              |            |              |            |              |
|   total    | 26892        |            |              |            |              |[0m
[32m[03/26 18:24:57 d2.data.common]: [0mSerializing 2862 elements to byte tensors and concatenating them all ...
[32m[03/26 18:25:00 d2.data.common]: [0mSerialized dataset takes 57.16 MiB
[32m[03/26 18:25:00 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(800, 832, 864, 896, 928, 960, 992, 1024), max_size=2048, sample_style='choice'), RandomFlip()]
[32m[03/26 18:25:00 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/26 18:25:01 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/26 18:25:13 d2.utils.events]: [0m eta: 0:43:30  iter: 19  total_loss: 3.108  loss_cls: 1.375  loss_box_reg: 0.898  loss_mask: 0.691  loss_rpn_cls: 0.085  loss_rpn_loc: 0.067  time: 0.5219  data_time: 0.0546  lr: 0.000005  max_mem: 5269M
[32m[03/26 18:25:24 d2.utils.events]: [0m eta: 0:43:46  iter: 39  total_loss: 3.027  loss_cls: 1.339  loss_box_reg: 0.881  loss_mask: 0.689  loss_rpn_cls: 0.046  loss_rpn_loc: 0.071  time: 0.5338  data_time: 0.0114  lr: 0.000010  max_mem: 5377M
[32m[03/26 18:25:34 d2.utils.events]: [0m eta: 0:44:12  iter: 59  total_loss: 2.995  loss_cls: 1.268  loss_box_reg: 0.892  loss_mask: 0.685  loss_rpn_cls: 0.106  loss_rpn_loc: 0.065  time: 0.5363  data_time: 0.0118  lr: 0.000015  max_mem: 5377M
[32m[03/26 18:25:46 d2.utils.events]: [0m eta: 0:45:02  iter: 79  total_loss: 2.829  loss_cls: 1.167  loss_box_reg: 0.889  loss_mask: 0.678  loss_rpn_cls: 0.031  loss_rpn_loc: 0.058  time: 0.5456  data_time: 0.0119  lr: 0.000020  max_mem: 5377M
[32m[03/26 18:25:57 d2.utils.events]: [0m eta: 0:45:23  iter: 99  total_loss: 2.726  loss_cls: 1.047  loss_box_reg: 0.879  loss_mask: 0.669  loss_rpn_cls: 0.047  loss_rpn_loc: 0.064  time: 0.5489  data_time: 0.0118  lr: 0.000025  max_mem: 5377M
[32m[03/26 18:26:08 d2.utils.events]: [0m eta: 0:45:12  iter: 119  total_loss: 2.581  loss_cls: 0.930  loss_box_reg: 0.872  loss_mask: 0.663  loss_rpn_cls: 0.047  loss_rpn_loc: 0.069  time: 0.5506  data_time: 0.0113  lr: 0.000030  max_mem: 5379M
[32m[03/26 18:26:20 d2.utils.events]: [0m eta: 0:45:15  iter: 139  total_loss: 2.413  loss_cls: 0.806  loss_box_reg: 0.863  loss_mask: 0.654  loss_rpn_cls: 0.027  loss_rpn_loc: 0.075  time: 0.5531  data_time: 0.0133  lr: 0.000035  max_mem: 5379M
[32m[03/26 18:26:31 d2.utils.events]: [0m eta: 0:44:47  iter: 159  total_loss: 2.321  loss_cls: 0.683  loss_box_reg: 0.875  loss_mask: 0.639  loss_rpn_cls: 0.022  loss_rpn_loc: 0.079  time: 0.5533  data_time: 0.0113  lr: 0.000040  max_mem: 5379M
[32m[03/26 18:26:42 d2.utils.events]: [0m eta: 0:44:36  iter: 179  total_loss: 2.258  loss_cls: 0.613  loss_box_reg: 0.853  loss_mask: 0.628  loss_rpn_cls: 0.050  loss_rpn_loc: 0.070  time: 0.5533  data_time: 0.0103  lr: 0.000045  max_mem: 5383M
[32m[03/26 18:26:53 d2.utils.events]: [0m eta: 0:44:12  iter: 199  total_loss: 2.114  loss_cls: 0.538  loss_box_reg: 0.822  loss_mask: 0.604  loss_rpn_cls: 0.033  loss_rpn_loc: 0.071  time: 0.5517  data_time: 0.0119  lr: 0.000050  max_mem: 5383M
[32m[03/26 18:27:04 d2.utils.events]: [0m eta: 0:43:56  iter: 219  total_loss: 2.051  loss_cls: 0.512  loss_box_reg: 0.840  loss_mask: 0.581  loss_rpn_cls: 0.032  loss_rpn_loc: 0.065  time: 0.5512  data_time: 0.0109  lr: 0.000055  max_mem: 5417M
[32m[03/26 18:27:15 d2.utils.events]: [0m eta: 0:43:49  iter: 239  total_loss: 1.949  loss_cls: 0.476  loss_box_reg: 0.811  loss_mask: 0.571  loss_rpn_cls: 0.027  loss_rpn_loc: 0.069  time: 0.5524  data_time: 0.0154  lr: 0.000060  max_mem: 5417M
[32m[03/26 18:27:26 d2.utils.events]: [0m eta: 0:43:42  iter: 259  total_loss: 1.900  loss_cls: 0.429  loss_box_reg: 0.783  loss_mask: 0.543  loss_rpn_cls: 0.045  loss_rpn_loc: 0.072  time: 0.5531  data_time: 0.0127  lr: 0.000065  max_mem: 5417M
[32m[03/26 18:27:37 d2.utils.events]: [0m eta: 0:43:35  iter: 279  total_loss: 1.796  loss_cls: 0.394  loss_box_reg: 0.779  loss_mask: 0.507  loss_rpn_cls: 0.023  loss_rpn_loc: 0.061  time: 0.5542  data_time: 0.0101  lr: 0.000070  max_mem: 5417M
[32m[03/26 18:27:49 d2.utils.events]: [0m eta: 0:43:26  iter: 299  total_loss: 1.722  loss_cls: 0.352  loss_box_reg: 0.779  loss_mask: 0.479  loss_rpn_cls: 0.027  loss_rpn_loc: 0.065  time: 0.5548  data_time: 0.0098  lr: 0.000075  max_mem: 5417M
[32m[03/26 18:28:00 d2.utils.events]: [0m eta: 0:43:17  iter: 319  total_loss: 1.652  loss_cls: 0.309  loss_box_reg: 0.731  loss_mask: 0.441  loss_rpn_cls: 0.037  loss_rpn_loc: 0.066  time: 0.5544  data_time: 0.0181  lr: 0.000080  max_mem: 5417M
[32m[03/26 18:28:11 d2.utils.events]: [0m eta: 0:43:10  iter: 339  total_loss: 1.519  loss_cls: 0.303  loss_box_reg: 0.706  loss_mask: 0.413  loss_rpn_cls: 0.035  loss_rpn_loc: 0.071  time: 0.5552  data_time: 0.0102  lr: 0.000085  max_mem: 5417M
[32m[03/26 18:28:22 d2.utils.events]: [0m eta: 0:42:56  iter: 359  total_loss: 1.465  loss_cls: 0.259  loss_box_reg: 0.668  loss_mask: 0.401  loss_rpn_cls: 0.041  loss_rpn_loc: 0.077  time: 0.5554  data_time: 0.0099  lr: 0.000090  max_mem: 5417M
[32m[03/26 18:28:33 d2.utils.events]: [0m eta: 0:42:45  iter: 379  total_loss: 1.352  loss_cls: 0.243  loss_box_reg: 0.641  loss_mask: 0.362  loss_rpn_cls: 0.030  loss_rpn_loc: 0.060  time: 0.5555  data_time: 0.0143  lr: 0.000095  max_mem: 5417M
[32m[03/26 18:28:45 d2.utils.events]: [0m eta: 0:42:36  iter: 399  total_loss: 1.319  loss_cls: 0.238  loss_box_reg: 0.603  loss_mask: 0.355  loss_rpn_cls: 0.029  loss_rpn_loc: 0.072  time: 0.5560  data_time: 0.0117  lr: 0.000100  max_mem: 5417M
[32m[03/26 18:28:56 d2.utils.events]: [0m eta: 0:42:32  iter: 419  total_loss: 1.209  loss_cls: 0.199  loss_box_reg: 0.551  loss_mask: 0.333  loss_rpn_cls: 0.030  loss_rpn_loc: 0.051  time: 0.5563  data_time: 0.0129  lr: 0.000105  max_mem: 5417M
[32m[03/26 18:29:07 d2.utils.events]: [0m eta: 0:42:21  iter: 439  total_loss: 1.113  loss_cls: 0.195  loss_box_reg: 0.505  loss_mask: 0.324  loss_rpn_cls: 0.031  loss_rpn_loc: 0.064  time: 0.5560  data_time: 0.0105  lr: 0.000110  max_mem: 5417M
[32m[03/26 18:29:18 d2.utils.events]: [0m eta: 0:42:11  iter: 459  total_loss: 1.050  loss_cls: 0.173  loss_box_reg: 0.467  loss_mask: 0.325  loss_rpn_cls: 0.034  loss_rpn_loc: 0.056  time: 0.5561  data_time: 0.0112  lr: 0.000115  max_mem: 5417M
[32m[03/26 18:29:29 d2.utils.events]: [0m eta: 0:42:00  iter: 479  total_loss: 1.051  loss_cls: 0.178  loss_box_reg: 0.446  loss_mask: 0.310  loss_rpn_cls: 0.021  loss_rpn_loc: 0.053  time: 0.5560  data_time: 0.0134  lr: 0.000120  max_mem: 5417M
[32m[03/26 18:29:41 d2.utils.events]: [0m eta: 0:41:55  iter: 499  total_loss: 1.071  loss_cls: 0.204  loss_box_reg: 0.475  loss_mask: 0.333  loss_rpn_cls: 0.019  loss_rpn_loc: 0.055  time: 0.5569  data_time: 0.0094  lr: 0.000125  max_mem: 5417M
[32m[03/26 18:29:52 d2.utils.events]: [0m eta: 0:41:42  iter: 519  total_loss: 1.083  loss_cls: 0.212  loss_box_reg: 0.443  loss_mask: 0.317  loss_rpn_cls: 0.021  loss_rpn_loc: 0.069  time: 0.5563  data_time: 0.0122  lr: 0.000130  max_mem: 5417M
[32m[03/26 18:30:03 d2.utils.events]: [0m eta: 0:41:29  iter: 539  total_loss: 0.937  loss_cls: 0.166  loss_box_reg: 0.378  loss_mask: 0.284  loss_rpn_cls: 0.022  loss_rpn_loc: 0.055  time: 0.5565  data_time: 0.0087  lr: 0.000135  max_mem: 5417M
[32m[03/26 18:30:14 d2.utils.events]: [0m eta: 0:41:18  iter: 559  total_loss: 0.972  loss_cls: 0.168  loss_box_reg: 0.404  loss_mask: 0.297  loss_rpn_cls: 0.025  loss_rpn_loc: 0.074  time: 0.5570  data_time: 0.0089  lr: 0.000140  max_mem: 5417M
[32m[03/26 18:30:26 d2.utils.events]: [0m eta: 0:41:10  iter: 579  total_loss: 0.932  loss_cls: 0.165  loss_box_reg: 0.399  loss_mask: 0.287  loss_rpn_cls: 0.020  loss_rpn_loc: 0.054  time: 0.5574  data_time: 0.0135  lr: 0.000145  max_mem: 5417M
[32m[03/26 18:30:38 d2.utils.events]: [0m eta: 0:41:03  iter: 599  total_loss: 1.064  loss_cls: 0.207  loss_box_reg: 0.417  loss_mask: 0.302  loss_rpn_cls: 0.023  loss_rpn_loc: 0.064  time: 0.5586  data_time: 0.0122  lr: 0.000150  max_mem: 5417M
[32m[03/26 18:30:49 d2.utils.events]: [0m eta: 0:40:56  iter: 619  total_loss: 0.912  loss_cls: 0.171  loss_box_reg: 0.363  loss_mask: 0.291  loss_rpn_cls: 0.024  loss_rpn_loc: 0.057  time: 0.5593  data_time: 0.0094  lr: 0.000155  max_mem: 5417M
[32m[03/26 18:31:01 d2.utils.events]: [0m eta: 0:40:49  iter: 639  total_loss: 0.909  loss_cls: 0.147  loss_box_reg: 0.352  loss_mask: 0.283  loss_rpn_cls: 0.031  loss_rpn_loc: 0.069  time: 0.5608  data_time: 0.0099  lr: 0.000160  max_mem: 5417M
[32m[03/26 18:31:13 d2.utils.events]: [0m eta: 0:40:41  iter: 659  total_loss: 0.923  loss_cls: 0.166  loss_box_reg: 0.372  loss_mask: 0.275  loss_rpn_cls: 0.012  loss_rpn_loc: 0.053  time: 0.5612  data_time: 0.0093  lr: 0.000165  max_mem: 5417M
[32m[03/26 18:31:24 d2.utils.events]: [0m eta: 0:40:32  iter: 679  total_loss: 0.887  loss_cls: 0.162  loss_box_reg: 0.369  loss_mask: 0.276  loss_rpn_cls: 0.014  loss_rpn_loc: 0.052  time: 0.5614  data_time: 0.0088  lr: 0.000170  max_mem: 5417M
[32m[03/26 18:31:36 d2.utils.events]: [0m eta: 0:40:22  iter: 699  total_loss: 0.856  loss_cls: 0.161  loss_box_reg: 0.341  loss_mask: 0.260  loss_rpn_cls: 0.026  loss_rpn_loc: 0.054  time: 0.5621  data_time: 0.0126  lr: 0.000175  max_mem: 5417M
[32m[03/26 18:31:47 d2.utils.events]: [0m eta: 0:40:09  iter: 719  total_loss: 0.832  loss_cls: 0.156  loss_box_reg: 0.332  loss_mask: 0.264  loss_rpn_cls: 0.016  loss_rpn_loc: 0.059  time: 0.5618  data_time: 0.0106  lr: 0.000180  max_mem: 5417M
[32m[03/26 18:31:59 d2.utils.events]: [0m eta: 0:40:00  iter: 739  total_loss: 0.950  loss_cls: 0.176  loss_box_reg: 0.376  loss_mask: 0.279  loss_rpn_cls: 0.026  loss_rpn_loc: 0.056  time: 0.5623  data_time: 0.0094  lr: 0.000185  max_mem: 5417M
[32m[03/26 18:32:10 d2.utils.events]: [0m eta: 0:39:46  iter: 759  total_loss: 0.834  loss_cls: 0.150  loss_box_reg: 0.338  loss_mask: 0.267  loss_rpn_cls: 0.023  loss_rpn_loc: 0.047  time: 0.5618  data_time: 0.0112  lr: 0.000190  max_mem: 5417M
[32m[03/26 18:32:20 d2.utils.events]: [0m eta: 0:39:28  iter: 779  total_loss: 0.868  loss_cls: 0.160  loss_box_reg: 0.346  loss_mask: 0.276  loss_rpn_cls: 0.020  loss_rpn_loc: 0.047  time: 0.5609  data_time: 0.0084  lr: 0.000195  max_mem: 5417M
[32m[03/26 18:32:31 d2.utils.events]: [0m eta: 0:39:17  iter: 799  total_loss: 0.856  loss_cls: 0.136  loss_box_reg: 0.360  loss_mask: 0.259  loss_rpn_cls: 0.031  loss_rpn_loc: 0.056  time: 0.5608  data_time: 0.0089  lr: 0.000200  max_mem: 5417M
[32m[03/26 18:32:43 d2.utils.events]: [0m eta: 0:39:06  iter: 819  total_loss: 0.952  loss_cls: 0.177  loss_box_reg: 0.368  loss_mask: 0.259  loss_rpn_cls: 0.025  loss_rpn_loc: 0.064  time: 0.5609  data_time: 0.0131  lr: 0.000205  max_mem: 5417M
[32m[03/26 18:32:54 d2.utils.events]: [0m eta: 0:39:01  iter: 839  total_loss: 0.895  loss_cls: 0.166  loss_box_reg: 0.349  loss_mask: 0.248  loss_rpn_cls: 0.029  loss_rpn_loc: 0.046  time: 0.5615  data_time: 0.0197  lr: 0.000210  max_mem: 5417M
[32m[03/26 18:33:06 d2.utils.events]: [0m eta: 0:38:49  iter: 859  total_loss: 0.896  loss_cls: 0.155  loss_box_reg: 0.350  loss_mask: 0.281  loss_rpn_cls: 0.026  loss_rpn_loc: 0.057  time: 0.5615  data_time: 0.0115  lr: 0.000215  max_mem: 5417M
[32m[03/26 18:33:17 d2.utils.events]: [0m eta: 0:38:40  iter: 879  total_loss: 0.832  loss_cls: 0.142  loss_box_reg: 0.337  loss_mask: 0.255  loss_rpn_cls: 0.018  loss_rpn_loc: 0.056  time: 0.5620  data_time: 0.0129  lr: 0.000220  max_mem: 5417M
[32m[03/26 18:33:29 d2.utils.events]: [0m eta: 0:38:29  iter: 899  total_loss: 0.867  loss_cls: 0.148  loss_box_reg: 0.341  loss_mask: 0.268  loss_rpn_cls: 0.022  loss_rpn_loc: 0.052  time: 0.5622  data_time: 0.0106  lr: 0.000225  max_mem: 5417M
[32m[03/26 18:33:40 d2.utils.events]: [0m eta: 0:38:18  iter: 919  total_loss: 0.843  loss_cls: 0.162  loss_box_reg: 0.346  loss_mask: 0.263  loss_rpn_cls: 0.020  loss_rpn_loc: 0.058  time: 0.5621  data_time: 0.0099  lr: 0.000230  max_mem: 5417M
[32m[03/26 18:33:51 d2.utils.events]: [0m eta: 0:38:07  iter: 939  total_loss: 0.802  loss_cls: 0.155  loss_box_reg: 0.328  loss_mask: 0.245  loss_rpn_cls: 0.008  loss_rpn_loc: 0.061  time: 0.5621  data_time: 0.0108  lr: 0.000235  max_mem: 5417M
[32m[03/26 18:34:02 d2.utils.events]: [0m eta: 0:37:55  iter: 959  total_loss: 0.826  loss_cls: 0.148  loss_box_reg: 0.332  loss_mask: 0.233  loss_rpn_cls: 0.021  loss_rpn_loc: 0.055  time: 0.5620  data_time: 0.0125  lr: 0.000240  max_mem: 5418M
[32m[03/26 18:34:13 d2.utils.events]: [0m eta: 0:37:43  iter: 979  total_loss: 0.772  loss_cls: 0.152  loss_box_reg: 0.304  loss_mask: 0.225  loss_rpn_cls: 0.013  loss_rpn_loc: 0.053  time: 0.5620  data_time: 0.0112  lr: 0.000245  max_mem: 5418M
[32m[03/26 18:34:25 d2.utils.events]: [0m eta: 0:37:33  iter: 999  total_loss: 0.826  loss_cls: 0.156  loss_box_reg: 0.333  loss_mask: 0.254  loss_rpn_cls: 0.022  loss_rpn_loc: 0.052  time: 0.5621  data_time: 0.0119  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:34:36 d2.utils.events]: [0m eta: 0:37:22  iter: 1019  total_loss: 0.741  loss_cls: 0.149  loss_box_reg: 0.305  loss_mask: 0.219  loss_rpn_cls: 0.012  loss_rpn_loc: 0.049  time: 0.5624  data_time: 0.0158  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:34:48 d2.utils.events]: [0m eta: 0:37:12  iter: 1039  total_loss: 0.730  loss_cls: 0.134  loss_box_reg: 0.300  loss_mask: 0.212  loss_rpn_cls: 0.017  loss_rpn_loc: 0.047  time: 0.5626  data_time: 0.0125  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:34:59 d2.utils.events]: [0m eta: 0:37:02  iter: 1059  total_loss: 0.819  loss_cls: 0.161  loss_box_reg: 0.311  loss_mask: 0.258  loss_rpn_cls: 0.021  loss_rpn_loc: 0.049  time: 0.5627  data_time: 0.0144  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:35:11 d2.utils.events]: [0m eta: 0:36:48  iter: 1079  total_loss: 0.832  loss_cls: 0.164  loss_box_reg: 0.332  loss_mask: 0.251  loss_rpn_cls: 0.021  loss_rpn_loc: 0.058  time: 0.5629  data_time: 0.0117  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:35:22 d2.utils.events]: [0m eta: 0:36:36  iter: 1099  total_loss: 0.770  loss_cls: 0.137  loss_box_reg: 0.303  loss_mask: 0.236  loss_rpn_cls: 0.015  loss_rpn_loc: 0.051  time: 0.5628  data_time: 0.0108  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:35:33 d2.utils.events]: [0m eta: 0:36:25  iter: 1119  total_loss: 0.779  loss_cls: 0.133  loss_box_reg: 0.324  loss_mask: 0.235  loss_rpn_cls: 0.015  loss_rpn_loc: 0.047  time: 0.5628  data_time: 0.0112  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:35:45 d2.utils.events]: [0m eta: 0:36:15  iter: 1139  total_loss: 0.747  loss_cls: 0.141  loss_box_reg: 0.288  loss_mask: 0.241  loss_rpn_cls: 0.016  loss_rpn_loc: 0.053  time: 0.5632  data_time: 0.0117  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:35:56 d2.utils.events]: [0m eta: 0:36:04  iter: 1159  total_loss: 0.845  loss_cls: 0.156  loss_box_reg: 0.311  loss_mask: 0.250  loss_rpn_cls: 0.019  loss_rpn_loc: 0.065  time: 0.5631  data_time: 0.0121  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:36:07 d2.utils.events]: [0m eta: 0:35:53  iter: 1179  total_loss: 0.773  loss_cls: 0.128  loss_box_reg: 0.299  loss_mask: 0.229  loss_rpn_cls: 0.020  loss_rpn_loc: 0.060  time: 0.5632  data_time: 0.0122  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:36:19 d2.utils.events]: [0m eta: 0:35:43  iter: 1199  total_loss: 0.797  loss_cls: 0.149  loss_box_reg: 0.281  loss_mask: 0.239  loss_rpn_cls: 0.021  loss_rpn_loc: 0.048  time: 0.5631  data_time: 0.0114  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:36:30 d2.utils.events]: [0m eta: 0:35:33  iter: 1219  total_loss: 0.778  loss_cls: 0.142  loss_box_reg: 0.302  loss_mask: 0.230  loss_rpn_cls: 0.018  loss_rpn_loc: 0.059  time: 0.5630  data_time: 0.0135  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:36:41 d2.utils.events]: [0m eta: 0:35:24  iter: 1239  total_loss: 0.756  loss_cls: 0.135  loss_box_reg: 0.304  loss_mask: 0.231  loss_rpn_cls: 0.023  loss_rpn_loc: 0.056  time: 0.5632  data_time: 0.0136  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:36:53 d2.utils.events]: [0m eta: 0:35:15  iter: 1259  total_loss: 0.714  loss_cls: 0.118  loss_box_reg: 0.277  loss_mask: 0.208  loss_rpn_cls: 0.019  loss_rpn_loc: 0.051  time: 0.5632  data_time: 0.0116  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:37:05 d2.utils.events]: [0m eta: 0:35:09  iter: 1279  total_loss: 0.670  loss_cls: 0.127  loss_box_reg: 0.269  loss_mask: 0.217  loss_rpn_cls: 0.021  loss_rpn_loc: 0.042  time: 0.5638  data_time: 0.0120  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:37:16 d2.utils.events]: [0m eta: 0:35:01  iter: 1299  total_loss: 0.803  loss_cls: 0.140  loss_box_reg: 0.322  loss_mask: 0.227  loss_rpn_cls: 0.021  loss_rpn_loc: 0.057  time: 0.5641  data_time: 0.0127  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:37:28 d2.utils.events]: [0m eta: 0:34:50  iter: 1319  total_loss: 0.724  loss_cls: 0.126  loss_box_reg: 0.290  loss_mask: 0.218  loss_rpn_cls: 0.015  loss_rpn_loc: 0.050  time: 0.5641  data_time: 0.0138  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:37:39 d2.utils.events]: [0m eta: 0:34:35  iter: 1339  total_loss: 0.670  loss_cls: 0.126  loss_box_reg: 0.269  loss_mask: 0.213  loss_rpn_cls: 0.014  loss_rpn_loc: 0.049  time: 0.5636  data_time: 0.0103  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:37:51 d2.utils.events]: [0m eta: 0:34:24  iter: 1359  total_loss: 0.740  loss_cls: 0.134  loss_box_reg: 0.298  loss_mask: 0.226  loss_rpn_cls: 0.020  loss_rpn_loc: 0.049  time: 0.5637  data_time: 0.0624  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:38:04 d2.utils.events]: [0m eta: 0:34:10  iter: 1379  total_loss: 0.804  loss_cls: 0.161  loss_box_reg: 0.301  loss_mask: 0.251  loss_rpn_cls: 0.014  loss_rpn_loc: 0.054  time: 0.5644  data_time: 0.1065  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:38:16 d2.utils.events]: [0m eta: 0:33:57  iter: 1399  total_loss: 0.766  loss_cls: 0.157  loss_box_reg: 0.296  loss_mask: 0.231  loss_rpn_cls: 0.016  loss_rpn_loc: 0.052  time: 0.5647  data_time: 0.0603  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:38:28 d2.utils.events]: [0m eta: 0:33:46  iter: 1419  total_loss: 0.696  loss_cls: 0.139  loss_box_reg: 0.299  loss_mask: 0.209  loss_rpn_cls: 0.014  loss_rpn_loc: 0.049  time: 0.5648  data_time: 0.0418  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:38:39 d2.utils.events]: [0m eta: 0:33:37  iter: 1439  total_loss: 0.708  loss_cls: 0.136  loss_box_reg: 0.284  loss_mask: 0.217  loss_rpn_cls: 0.014  loss_rpn_loc: 0.048  time: 0.5649  data_time: 0.0149  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:38:51 d2.utils.events]: [0m eta: 0:33:30  iter: 1459  total_loss: 0.725  loss_cls: 0.141  loss_box_reg: 0.272  loss_mask: 0.217  loss_rpn_cls: 0.017  loss_rpn_loc: 0.043  time: 0.5648  data_time: 0.0120  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:39:02 d2.utils.events]: [0m eta: 0:33:22  iter: 1479  total_loss: 0.724  loss_cls: 0.128  loss_box_reg: 0.303  loss_mask: 0.215  loss_rpn_cls: 0.011  loss_rpn_loc: 0.049  time: 0.5649  data_time: 0.0105  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:39:14 d2.utils.events]: [0m eta: 0:33:05  iter: 1499  total_loss: 0.688  loss_cls: 0.122  loss_box_reg: 0.281  loss_mask: 0.213  loss_rpn_cls: 0.016  loss_rpn_loc: 0.049  time: 0.5649  data_time: 0.0137  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:39:26 d2.utils.events]: [0m eta: 0:32:49  iter: 1519  total_loss: 0.651  loss_cls: 0.113  loss_box_reg: 0.268  loss_mask: 0.199  loss_rpn_cls: 0.014  loss_rpn_loc: 0.051  time: 0.5645  data_time: 0.0100  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:39:38 d2.utils.events]: [0m eta: 0:32:42  iter: 1539  total_loss: 0.746  loss_cls: 0.161  loss_box_reg: 0.313  loss_mask: 0.204  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 0.5646  data_time: 0.0111  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:39:50 d2.utils.events]: [0m eta: 0:32:34  iter: 1559  total_loss: 0.670  loss_cls: 0.124  loss_box_reg: 0.267  loss_mask: 0.203  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 0.5647  data_time: 0.0131  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:40:01 d2.utils.events]: [0m eta: 0:32:22  iter: 1579  total_loss: 0.697  loss_cls: 0.131  loss_box_reg: 0.281  loss_mask: 0.201  loss_rpn_cls: 0.015  loss_rpn_loc: 0.049  time: 0.5648  data_time: 0.0108  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:40:13 d2.utils.events]: [0m eta: 0:32:05  iter: 1599  total_loss: 0.655  loss_cls: 0.114  loss_box_reg: 0.247  loss_mask: 0.203  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 0.5647  data_time: 0.0111  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:40:24 d2.utils.events]: [0m eta: 0:31:52  iter: 1619  total_loss: 0.740  loss_cls: 0.136  loss_box_reg: 0.293  loss_mask: 0.219  loss_rpn_cls: 0.014  loss_rpn_loc: 0.051  time: 0.5647  data_time: 0.0131  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:40:35 d2.utils.events]: [0m eta: 0:31:38  iter: 1639  total_loss: 0.740  loss_cls: 0.145  loss_box_reg: 0.299  loss_mask: 0.218  loss_rpn_cls: 0.013  loss_rpn_loc: 0.054  time: 0.5646  data_time: 0.0151  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:40:46 d2.utils.events]: [0m eta: 0:31:25  iter: 1659  total_loss: 0.750  loss_cls: 0.140  loss_box_reg: 0.299  loss_mask: 0.203  loss_rpn_cls: 0.010  loss_rpn_loc: 0.057  time: 0.5647  data_time: 0.0118  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:40:58 d2.utils.events]: [0m eta: 0:31:15  iter: 1679  total_loss: 0.729  loss_cls: 0.150  loss_box_reg: 0.283  loss_mask: 0.222  loss_rpn_cls: 0.018  loss_rpn_loc: 0.058  time: 0.5649  data_time: 0.0144  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:41:10 d2.utils.events]: [0m eta: 0:31:04  iter: 1699  total_loss: 0.703  loss_cls: 0.143  loss_box_reg: 0.273  loss_mask: 0.222  loss_rpn_cls: 0.017  loss_rpn_loc: 0.042  time: 0.5653  data_time: 0.0146  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:41:22 d2.utils.events]: [0m eta: 0:30:54  iter: 1719  total_loss: 0.704  loss_cls: 0.131  loss_box_reg: 0.280  loss_mask: 0.217  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 0.5653  data_time: 0.0144  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:41:33 d2.utils.events]: [0m eta: 0:30:42  iter: 1739  total_loss: 0.714  loss_cls: 0.134  loss_box_reg: 0.274  loss_mask: 0.216  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 0.5656  data_time: 0.0159  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:41:45 d2.utils.events]: [0m eta: 0:30:33  iter: 1759  total_loss: 0.813  loss_cls: 0.141  loss_box_reg: 0.321  loss_mask: 0.243  loss_rpn_cls: 0.019  loss_rpn_loc: 0.064  time: 0.5657  data_time: 0.0129  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:41:56 d2.utils.events]: [0m eta: 0:30:24  iter: 1779  total_loss: 0.645  loss_cls: 0.123  loss_box_reg: 0.256  loss_mask: 0.199  loss_rpn_cls: 0.020  loss_rpn_loc: 0.049  time: 0.5657  data_time: 0.0116  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:42:08 d2.utils.events]: [0m eta: 0:30:11  iter: 1799  total_loss: 0.678  loss_cls: 0.145  loss_box_reg: 0.259  loss_mask: 0.207  loss_rpn_cls: 0.016  loss_rpn_loc: 0.041  time: 0.5658  data_time: 0.0142  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:42:19 d2.utils.events]: [0m eta: 0:30:00  iter: 1819  total_loss: 0.685  loss_cls: 0.128  loss_box_reg: 0.276  loss_mask: 0.206  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 0.5658  data_time: 0.0120  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:42:30 d2.utils.events]: [0m eta: 0:29:46  iter: 1839  total_loss: 0.655  loss_cls: 0.107  loss_box_reg: 0.249  loss_mask: 0.206  loss_rpn_cls: 0.020  loss_rpn_loc: 0.051  time: 0.5655  data_time: 0.0129  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:42:41 d2.utils.events]: [0m eta: 0:29:34  iter: 1859  total_loss: 0.684  loss_cls: 0.122  loss_box_reg: 0.259  loss_mask: 0.216  loss_rpn_cls: 0.016  loss_rpn_loc: 0.045  time: 0.5654  data_time: 0.0097  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:42:52 d2.utils.events]: [0m eta: 0:29:22  iter: 1879  total_loss: 0.715  loss_cls: 0.143  loss_box_reg: 0.300  loss_mask: 0.221  loss_rpn_cls: 0.014  loss_rpn_loc: 0.043  time: 0.5653  data_time: 0.0101  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:43:04 d2.utils.events]: [0m eta: 0:29:12  iter: 1899  total_loss: 0.736  loss_cls: 0.135  loss_box_reg: 0.298  loss_mask: 0.220  loss_rpn_cls: 0.016  loss_rpn_loc: 0.054  time: 0.5657  data_time: 0.0129  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:43:15 d2.utils.events]: [0m eta: 0:29:01  iter: 1919  total_loss: 0.640  loss_cls: 0.115  loss_box_reg: 0.267  loss_mask: 0.190  loss_rpn_cls: 0.013  loss_rpn_loc: 0.055  time: 0.5657  data_time: 0.0125  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:43:27 d2.utils.events]: [0m eta: 0:28:50  iter: 1939  total_loss: 0.655  loss_cls: 0.131  loss_box_reg: 0.266  loss_mask: 0.221  loss_rpn_cls: 0.010  loss_rpn_loc: 0.049  time: 0.5658  data_time: 0.0134  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:43:39 d2.utils.events]: [0m eta: 0:28:40  iter: 1959  total_loss: 0.617  loss_cls: 0.107  loss_box_reg: 0.261  loss_mask: 0.190  loss_rpn_cls: 0.012  loss_rpn_loc: 0.043  time: 0.5659  data_time: 0.0141  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:43:50 d2.utils.events]: [0m eta: 0:28:32  iter: 1979  total_loss: 0.670  loss_cls: 0.117  loss_box_reg: 0.257  loss_mask: 0.217  loss_rpn_cls: 0.015  loss_rpn_loc: 0.049  time: 0.5660  data_time: 0.0139  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:44:02 d2.utils.events]: [0m eta: 0:28:22  iter: 1999  total_loss: 0.609  loss_cls: 0.099  loss_box_reg: 0.246  loss_mask: 0.195  loss_rpn_cls: 0.011  loss_rpn_loc: 0.035  time: 0.5661  data_time: 0.0124  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:44:13 d2.utils.events]: [0m eta: 0:28:12  iter: 2019  total_loss: 0.643  loss_cls: 0.122  loss_box_reg: 0.262  loss_mask: 0.200  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 0.5660  data_time: 0.0130  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:44:24 d2.utils.events]: [0m eta: 0:27:59  iter: 2039  total_loss: 0.715  loss_cls: 0.139  loss_box_reg: 0.272  loss_mask: 0.218  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 0.5661  data_time: 0.0128  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:44:36 d2.utils.events]: [0m eta: 0:27:49  iter: 2059  total_loss: 0.667  loss_cls: 0.139  loss_box_reg: 0.265  loss_mask: 0.212  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 0.5662  data_time: 0.0148  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:44:47 d2.utils.events]: [0m eta: 0:27:37  iter: 2079  total_loss: 0.669  loss_cls: 0.103  loss_box_reg: 0.270  loss_mask: 0.209  loss_rpn_cls: 0.015  loss_rpn_loc: 0.063  time: 0.5662  data_time: 0.0117  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:44:59 d2.utils.events]: [0m eta: 0:27:28  iter: 2099  total_loss: 0.657  loss_cls: 0.125  loss_box_reg: 0.280  loss_mask: 0.214  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 0.5664  data_time: 0.0121  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:45:11 d2.utils.events]: [0m eta: 0:27:18  iter: 2119  total_loss: 0.692  loss_cls: 0.130  loss_box_reg: 0.278  loss_mask: 0.209  loss_rpn_cls: 0.016  loss_rpn_loc: 0.057  time: 0.5666  data_time: 0.0142  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:45:22 d2.utils.events]: [0m eta: 0:27:06  iter: 2139  total_loss: 0.658  loss_cls: 0.116  loss_box_reg: 0.273  loss_mask: 0.195  loss_rpn_cls: 0.013  loss_rpn_loc: 0.042  time: 0.5666  data_time: 0.0116  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:45:33 d2.utils.events]: [0m eta: 0:26:55  iter: 2159  total_loss: 0.679  loss_cls: 0.132  loss_box_reg: 0.274  loss_mask: 0.222  loss_rpn_cls: 0.012  loss_rpn_loc: 0.038  time: 0.5666  data_time: 0.0122  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:45:45 d2.utils.events]: [0m eta: 0:26:43  iter: 2179  total_loss: 0.679  loss_cls: 0.110  loss_box_reg: 0.271  loss_mask: 0.206  loss_rpn_cls: 0.008  loss_rpn_loc: 0.052  time: 0.5665  data_time: 0.0121  lr: 0.000250  max_mem: 5418M
[32m[03/26 18:45:57 d2.utils.events]: [0m eta: 0:26:34  iter: 2199  total_loss: 0.698  loss_cls: 0.128  loss_box_reg: 0.290  loss_mask: 0.225  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 0.5670  data_time: 0.0149  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:46:08 d2.utils.events]: [0m eta: 0:26:23  iter: 2219  total_loss: 0.668  loss_cls: 0.116  loss_box_reg: 0.266  loss_mask: 0.211  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 0.5671  data_time: 0.0117  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:46:20 d2.utils.events]: [0m eta: 0:26:12  iter: 2239  total_loss: 0.690  loss_cls: 0.118  loss_box_reg: 0.286  loss_mask: 0.209  loss_rpn_cls: 0.014  loss_rpn_loc: 0.046  time: 0.5671  data_time: 0.0113  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:46:31 d2.utils.events]: [0m eta: 0:26:00  iter: 2259  total_loss: 0.700  loss_cls: 0.127  loss_box_reg: 0.274  loss_mask: 0.212  loss_rpn_cls: 0.016  loss_rpn_loc: 0.052  time: 0.5670  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:46:42 d2.utils.events]: [0m eta: 0:25:46  iter: 2279  total_loss: 0.669  loss_cls: 0.126  loss_box_reg: 0.267  loss_mask: 0.213  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 0.5670  data_time: 0.0137  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:46:54 d2.utils.events]: [0m eta: 0:25:32  iter: 2299  total_loss: 0.650  loss_cls: 0.120  loss_box_reg: 0.269  loss_mask: 0.207  loss_rpn_cls: 0.013  loss_rpn_loc: 0.051  time: 0.5669  data_time: 0.0121  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:47:05 d2.utils.events]: [0m eta: 0:25:21  iter: 2319  total_loss: 0.680  loss_cls: 0.133  loss_box_reg: 0.281  loss_mask: 0.211  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 0.5669  data_time: 0.0118  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:47:16 d2.utils.events]: [0m eta: 0:25:10  iter: 2339  total_loss: 0.697  loss_cls: 0.130  loss_box_reg: 0.267  loss_mask: 0.219  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 0.5669  data_time: 0.0144  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:47:27 d2.utils.events]: [0m eta: 0:24:58  iter: 2359  total_loss: 0.626  loss_cls: 0.115  loss_box_reg: 0.236  loss_mask: 0.198  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 0.5668  data_time: 0.0140  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:47:39 d2.utils.events]: [0m eta: 0:24:48  iter: 2379  total_loss: 0.662  loss_cls: 0.124  loss_box_reg: 0.254  loss_mask: 0.185  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 0.5668  data_time: 0.0135  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:47:50 d2.utils.events]: [0m eta: 0:24:38  iter: 2399  total_loss: 0.658  loss_cls: 0.124  loss_box_reg: 0.267  loss_mask: 0.212  loss_rpn_cls: 0.015  loss_rpn_loc: 0.046  time: 0.5669  data_time: 0.0121  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:48:02 d2.utils.events]: [0m eta: 0:24:29  iter: 2419  total_loss: 0.669  loss_cls: 0.120  loss_box_reg: 0.264  loss_mask: 0.200  loss_rpn_cls: 0.019  loss_rpn_loc: 0.053  time: 0.5671  data_time: 0.0124  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:48:13 d2.utils.events]: [0m eta: 0:24:17  iter: 2439  total_loss: 0.680  loss_cls: 0.130  loss_box_reg: 0.275  loss_mask: 0.209  loss_rpn_cls: 0.017  loss_rpn_loc: 0.051  time: 0.5671  data_time: 0.0145  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:48:25 d2.utils.events]: [0m eta: 0:24:04  iter: 2459  total_loss: 0.686  loss_cls: 0.135  loss_box_reg: 0.270  loss_mask: 0.214  loss_rpn_cls: 0.015  loss_rpn_loc: 0.047  time: 0.5672  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:48:36 d2.utils.events]: [0m eta: 0:23:53  iter: 2479  total_loss: 0.682  loss_cls: 0.139  loss_box_reg: 0.265  loss_mask: 0.194  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 0.5672  data_time: 0.0129  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:48:48 d2.utils.events]: [0m eta: 0:23:43  iter: 2499  total_loss: 0.689  loss_cls: 0.130  loss_box_reg: 0.263  loss_mask: 0.209  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 0.5672  data_time: 0.0103  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:49:00 d2.utils.events]: [0m eta: 0:23:34  iter: 2519  total_loss: 0.600  loss_cls: 0.106  loss_box_reg: 0.245  loss_mask: 0.193  loss_rpn_cls: 0.014  loss_rpn_loc: 0.050  time: 0.5674  data_time: 0.0120  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:49:11 d2.utils.events]: [0m eta: 0:23:23  iter: 2539  total_loss: 0.667  loss_cls: 0.122  loss_box_reg: 0.264  loss_mask: 0.206  loss_rpn_cls: 0.011  loss_rpn_loc: 0.048  time: 0.5674  data_time: 0.0123  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:49:22 d2.utils.events]: [0m eta: 0:23:10  iter: 2559  total_loss: 0.693  loss_cls: 0.135  loss_box_reg: 0.273  loss_mask: 0.205  loss_rpn_cls: 0.011  loss_rpn_loc: 0.045  time: 0.5672  data_time: 0.0109  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:49:33 d2.utils.events]: [0m eta: 0:22:56  iter: 2579  total_loss: 0.652  loss_cls: 0.129  loss_box_reg: 0.268  loss_mask: 0.211  loss_rpn_cls: 0.016  loss_rpn_loc: 0.046  time: 0.5670  data_time: 0.0118  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:49:44 d2.utils.events]: [0m eta: 0:22:46  iter: 2599  total_loss: 0.619  loss_cls: 0.120  loss_box_reg: 0.252  loss_mask: 0.192  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 0.5671  data_time: 0.0121  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:49:56 d2.utils.events]: [0m eta: 0:22:34  iter: 2619  total_loss: 0.642  loss_cls: 0.129  loss_box_reg: 0.265  loss_mask: 0.198  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 0.5671  data_time: 0.0143  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:50:07 d2.utils.events]: [0m eta: 0:22:23  iter: 2639  total_loss: 0.658  loss_cls: 0.127  loss_box_reg: 0.275  loss_mask: 0.201  loss_rpn_cls: 0.011  loss_rpn_loc: 0.041  time: 0.5670  data_time: 0.0116  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:50:18 d2.utils.events]: [0m eta: 0:22:12  iter: 2659  total_loss: 0.686  loss_cls: 0.120  loss_box_reg: 0.270  loss_mask: 0.198  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 0.5670  data_time: 0.0103  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:50:29 d2.utils.events]: [0m eta: 0:22:00  iter: 2679  total_loss: 0.696  loss_cls: 0.133  loss_box_reg: 0.277  loss_mask: 0.217  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 0.5670  data_time: 0.0137  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:50:41 d2.utils.events]: [0m eta: 0:21:48  iter: 2699  total_loss: 0.671  loss_cls: 0.117  loss_box_reg: 0.268  loss_mask: 0.207  loss_rpn_cls: 0.010  loss_rpn_loc: 0.041  time: 0.5671  data_time: 0.0121  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:50:52 d2.utils.events]: [0m eta: 0:21:38  iter: 2719  total_loss: 0.699  loss_cls: 0.145  loss_box_reg: 0.277  loss_mask: 0.214  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 0.5671  data_time: 0.0125  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:51:04 d2.utils.events]: [0m eta: 0:21:27  iter: 2739  total_loss: 0.672  loss_cls: 0.130  loss_box_reg: 0.267  loss_mask: 0.216  loss_rpn_cls: 0.012  loss_rpn_loc: 0.054  time: 0.5673  data_time: 0.0141  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:51:15 d2.utils.events]: [0m eta: 0:21:14  iter: 2759  total_loss: 0.587  loss_cls: 0.115  loss_box_reg: 0.226  loss_mask: 0.184  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 0.5672  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:51:27 d2.utils.events]: [0m eta: 0:21:04  iter: 2779  total_loss: 0.748  loss_cls: 0.140  loss_box_reg: 0.286  loss_mask: 0.219  loss_rpn_cls: 0.013  loss_rpn_loc: 0.047  time: 0.5673  data_time: 0.0144  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:51:39 d2.utils.events]: [0m eta: 0:20:54  iter: 2799  total_loss: 0.622  loss_cls: 0.108  loss_box_reg: 0.264  loss_mask: 0.196  loss_rpn_cls: 0.008  loss_rpn_loc: 0.048  time: 0.5674  data_time: 0.0131  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:51:50 d2.utils.events]: [0m eta: 0:20:42  iter: 2819  total_loss: 0.668  loss_cls: 0.124  loss_box_reg: 0.254  loss_mask: 0.197  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 0.5674  data_time: 0.0114  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:52:01 d2.utils.events]: [0m eta: 0:20:33  iter: 2839  total_loss: 0.648  loss_cls: 0.107  loss_box_reg: 0.279  loss_mask: 0.196  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 0.5674  data_time: 0.0137  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:52:12 d2.utils.events]: [0m eta: 0:20:21  iter: 2859  total_loss: 0.653  loss_cls: 0.116  loss_box_reg: 0.272  loss_mask: 0.201  loss_rpn_cls: 0.010  loss_rpn_loc: 0.046  time: 0.5673  data_time: 0.0174  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:52:24 d2.utils.events]: [0m eta: 0:20:12  iter: 2879  total_loss: 0.588  loss_cls: 0.101  loss_box_reg: 0.240  loss_mask: 0.191  loss_rpn_cls: 0.007  loss_rpn_loc: 0.034  time: 0.5674  data_time: 0.0126  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:52:35 d2.utils.events]: [0m eta: 0:19:58  iter: 2899  total_loss: 0.596  loss_cls: 0.102  loss_box_reg: 0.245  loss_mask: 0.181  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 0.5672  data_time: 0.0129  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:52:46 d2.utils.events]: [0m eta: 0:19:45  iter: 2919  total_loss: 0.561  loss_cls: 0.099  loss_box_reg: 0.229  loss_mask: 0.179  loss_rpn_cls: 0.010  loss_rpn_loc: 0.040  time: 0.5671  data_time: 0.0135  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:52:57 d2.utils.events]: [0m eta: 0:19:33  iter: 2939  total_loss: 0.638  loss_cls: 0.130  loss_box_reg: 0.258  loss_mask: 0.199  loss_rpn_cls: 0.014  loss_rpn_loc: 0.044  time: 0.5669  data_time: 0.0133  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:53:08 d2.utils.events]: [0m eta: 0:19:21  iter: 2959  total_loss: 0.604  loss_cls: 0.107  loss_box_reg: 0.241  loss_mask: 0.192  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 0.5668  data_time: 0.0115  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:53:19 d2.utils.events]: [0m eta: 0:19:09  iter: 2979  total_loss: 0.614  loss_cls: 0.121  loss_box_reg: 0.257  loss_mask: 0.194  loss_rpn_cls: 0.010  loss_rpn_loc: 0.040  time: 0.5668  data_time: 0.0113  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:53:30 d2.utils.events]: [0m eta: 0:18:56  iter: 2999  total_loss: 0.638  loss_cls: 0.122  loss_box_reg: 0.260  loss_mask: 0.206  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 0.5668  data_time: 0.0124  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:53:42 d2.utils.events]: [0m eta: 0:18:45  iter: 3019  total_loss: 0.653  loss_cls: 0.114  loss_box_reg: 0.257  loss_mask: 0.211  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 0.5669  data_time: 0.0125  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:53:54 d2.utils.events]: [0m eta: 0:18:35  iter: 3039  total_loss: 0.627  loss_cls: 0.126  loss_box_reg: 0.266  loss_mask: 0.190  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 0.5670  data_time: 0.0114  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:54:05 d2.utils.events]: [0m eta: 0:18:21  iter: 3059  total_loss: 0.617  loss_cls: 0.116  loss_box_reg: 0.263  loss_mask: 0.190  loss_rpn_cls: 0.009  loss_rpn_loc: 0.042  time: 0.5668  data_time: 0.0142  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:54:16 d2.utils.events]: [0m eta: 0:18:10  iter: 3079  total_loss: 0.654  loss_cls: 0.123  loss_box_reg: 0.251  loss_mask: 0.203  loss_rpn_cls: 0.013  loss_rpn_loc: 0.038  time: 0.5667  data_time: 0.0125  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:54:27 d2.utils.events]: [0m eta: 0:17:59  iter: 3099  total_loss: 0.642  loss_cls: 0.128  loss_box_reg: 0.255  loss_mask: 0.184  loss_rpn_cls: 0.012  loss_rpn_loc: 0.042  time: 0.5669  data_time: 0.0139  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:54:39 d2.utils.events]: [0m eta: 0:17:47  iter: 3119  total_loss: 0.695  loss_cls: 0.122  loss_box_reg: 0.290  loss_mask: 0.210  loss_rpn_cls: 0.011  loss_rpn_loc: 0.052  time: 0.5668  data_time: 0.0142  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:54:50 d2.utils.events]: [0m eta: 0:17:35  iter: 3139  total_loss: 0.640  loss_cls: 0.121  loss_box_reg: 0.258  loss_mask: 0.194  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 0.5669  data_time: 0.0133  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:55:02 d2.utils.events]: [0m eta: 0:17:24  iter: 3159  total_loss: 0.679  loss_cls: 0.129  loss_box_reg: 0.268  loss_mask: 0.210  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 0.5670  data_time: 0.0132  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:55:13 d2.utils.events]: [0m eta: 0:17:14  iter: 3179  total_loss: 0.615  loss_cls: 0.121  loss_box_reg: 0.234  loss_mask: 0.186  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 0.5670  data_time: 0.0173  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:55:25 d2.utils.events]: [0m eta: 0:17:01  iter: 3199  total_loss: 0.655  loss_cls: 0.115  loss_box_reg: 0.253  loss_mask: 0.196  loss_rpn_cls: 0.017  loss_rpn_loc: 0.046  time: 0.5671  data_time: 0.0135  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:55:37 d2.utils.events]: [0m eta: 0:16:50  iter: 3219  total_loss: 0.642  loss_cls: 0.119  loss_box_reg: 0.270  loss_mask: 0.198  loss_rpn_cls: 0.011  loss_rpn_loc: 0.046  time: 0.5673  data_time: 0.0142  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:55:48 d2.utils.events]: [0m eta: 0:16:39  iter: 3239  total_loss: 0.629  loss_cls: 0.116  loss_box_reg: 0.233  loss_mask: 0.187  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 0.5673  data_time: 0.0149  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:56:00 d2.utils.events]: [0m eta: 0:16:30  iter: 3259  total_loss: 0.615  loss_cls: 0.112  loss_box_reg: 0.239  loss_mask: 0.186  loss_rpn_cls: 0.011  loss_rpn_loc: 0.050  time: 0.5673  data_time: 0.0135  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:56:11 d2.utils.events]: [0m eta: 0:16:19  iter: 3279  total_loss: 0.627  loss_cls: 0.126  loss_box_reg: 0.249  loss_mask: 0.207  loss_rpn_cls: 0.009  loss_rpn_loc: 0.047  time: 0.5674  data_time: 0.0109  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:56:23 d2.utils.events]: [0m eta: 0:16:09  iter: 3299  total_loss: 0.638  loss_cls: 0.116  loss_box_reg: 0.248  loss_mask: 0.178  loss_rpn_cls: 0.012  loss_rpn_loc: 0.051  time: 0.5674  data_time: 0.0105  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:56:34 d2.utils.events]: [0m eta: 0:15:58  iter: 3319  total_loss: 0.630  loss_cls: 0.112  loss_box_reg: 0.252  loss_mask: 0.203  loss_rpn_cls: 0.005  loss_rpn_loc: 0.042  time: 0.5675  data_time: 0.0185  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:56:46 d2.utils.events]: [0m eta: 0:15:48  iter: 3339  total_loss: 0.596  loss_cls: 0.107  loss_box_reg: 0.239  loss_mask: 0.170  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 0.5676  data_time: 0.0121  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:56:57 d2.utils.events]: [0m eta: 0:15:38  iter: 3359  total_loss: 0.614  loss_cls: 0.118  loss_box_reg: 0.238  loss_mask: 0.197  loss_rpn_cls: 0.007  loss_rpn_loc: 0.045  time: 0.5676  data_time: 0.0121  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:57:08 d2.utils.events]: [0m eta: 0:15:25  iter: 3379  total_loss: 0.643  loss_cls: 0.121  loss_box_reg: 0.245  loss_mask: 0.189  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 0.5675  data_time: 0.0138  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:57:19 d2.utils.events]: [0m eta: 0:15:12  iter: 3399  total_loss: 0.580  loss_cls: 0.100  loss_box_reg: 0.233  loss_mask: 0.203  loss_rpn_cls: 0.011  loss_rpn_loc: 0.037  time: 0.5673  data_time: 0.0124  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:57:30 d2.utils.events]: [0m eta: 0:14:58  iter: 3419  total_loss: 0.604  loss_cls: 0.101  loss_box_reg: 0.248  loss_mask: 0.193  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 0.5671  data_time: 0.0117  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:57:41 d2.utils.events]: [0m eta: 0:14:46  iter: 3439  total_loss: 0.656  loss_cls: 0.112  loss_box_reg: 0.259  loss_mask: 0.199  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 0.5671  data_time: 0.0144  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:57:52 d2.utils.events]: [0m eta: 0:14:33  iter: 3459  total_loss: 0.676  loss_cls: 0.119  loss_box_reg: 0.268  loss_mask: 0.193  loss_rpn_cls: 0.009  loss_rpn_loc: 0.048  time: 0.5670  data_time: 0.0146  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:58:04 d2.utils.events]: [0m eta: 0:14:22  iter: 3479  total_loss: 0.570  loss_cls: 0.111  loss_box_reg: 0.227  loss_mask: 0.185  loss_rpn_cls: 0.011  loss_rpn_loc: 0.044  time: 0.5670  data_time: 0.0112  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:58:15 d2.utils.events]: [0m eta: 0:14:11  iter: 3499  total_loss: 0.607  loss_cls: 0.115  loss_box_reg: 0.246  loss_mask: 0.189  loss_rpn_cls: 0.012  loss_rpn_loc: 0.039  time: 0.5670  data_time: 0.0156  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:58:26 d2.utils.events]: [0m eta: 0:13:59  iter: 3519  total_loss: 0.629  loss_cls: 0.114  loss_box_reg: 0.244  loss_mask: 0.198  loss_rpn_cls: 0.014  loss_rpn_loc: 0.041  time: 0.5671  data_time: 0.0134  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:58:38 d2.utils.events]: [0m eta: 0:13:49  iter: 3539  total_loss: 0.549  loss_cls: 0.113  loss_box_reg: 0.228  loss_mask: 0.168  loss_rpn_cls: 0.011  loss_rpn_loc: 0.037  time: 0.5671  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:58:49 d2.utils.events]: [0m eta: 0:13:38  iter: 3559  total_loss: 0.587  loss_cls: 0.093  loss_box_reg: 0.235  loss_mask: 0.192  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 0.5671  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:59:00 d2.utils.events]: [0m eta: 0:13:27  iter: 3579  total_loss: 0.649  loss_cls: 0.120  loss_box_reg: 0.244  loss_mask: 0.196  loss_rpn_cls: 0.015  loss_rpn_loc: 0.049  time: 0.5670  data_time: 0.0116  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:59:11 d2.utils.events]: [0m eta: 0:13:15  iter: 3599  total_loss: 0.650  loss_cls: 0.121  loss_box_reg: 0.259  loss_mask: 0.200  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 0.5669  data_time: 0.0119  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:59:22 d2.utils.events]: [0m eta: 0:13:03  iter: 3619  total_loss: 0.594  loss_cls: 0.113  loss_box_reg: 0.254  loss_mask: 0.183  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 0.5669  data_time: 0.0118  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:59:34 d2.utils.events]: [0m eta: 0:12:53  iter: 3639  total_loss: 0.580  loss_cls: 0.100  loss_box_reg: 0.233  loss_mask: 0.178  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 0.5670  data_time: 0.0178  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:59:45 d2.utils.events]: [0m eta: 0:12:41  iter: 3659  total_loss: 0.609  loss_cls: 0.117  loss_box_reg: 0.236  loss_mask: 0.191  loss_rpn_cls: 0.010  loss_rpn_loc: 0.050  time: 0.5669  data_time: 0.0115  lr: 0.000250  max_mem: 5423M
[32m[03/26 18:59:57 d2.utils.events]: [0m eta: 0:12:29  iter: 3679  total_loss: 0.566  loss_cls: 0.089  loss_box_reg: 0.217  loss_mask: 0.182  loss_rpn_cls: 0.011  loss_rpn_loc: 0.040  time: 0.5669  data_time: 0.0124  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:00:08 d2.utils.events]: [0m eta: 0:12:17  iter: 3699  total_loss: 0.609  loss_cls: 0.105  loss_box_reg: 0.241  loss_mask: 0.187  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 0.5668  data_time: 0.0135  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:00:18 d2.utils.events]: [0m eta: 0:12:04  iter: 3719  total_loss: 0.588  loss_cls: 0.110  loss_box_reg: 0.216  loss_mask: 0.207  loss_rpn_cls: 0.010  loss_rpn_loc: 0.042  time: 0.5666  data_time: 0.0106  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:00:30 d2.utils.events]: [0m eta: 0:11:52  iter: 3739  total_loss: 0.588  loss_cls: 0.112  loss_box_reg: 0.238  loss_mask: 0.188  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 0.5667  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:00:41 d2.utils.events]: [0m eta: 0:11:41  iter: 3759  total_loss: 0.638  loss_cls: 0.116  loss_box_reg: 0.250  loss_mask: 0.188  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 0.5667  data_time: 0.0110  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:00:53 d2.utils.events]: [0m eta: 0:11:30  iter: 3779  total_loss: 0.583  loss_cls: 0.107  loss_box_reg: 0.237  loss_mask: 0.183  loss_rpn_cls: 0.010  loss_rpn_loc: 0.051  time: 0.5668  data_time: 0.0121  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:01:04 d2.utils.events]: [0m eta: 0:11:18  iter: 3799  total_loss: 0.706  loss_cls: 0.140  loss_box_reg: 0.258  loss_mask: 0.214  loss_rpn_cls: 0.009  loss_rpn_loc: 0.040  time: 0.5668  data_time: 0.0127  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:01:16 d2.utils.events]: [0m eta: 0:11:07  iter: 3819  total_loss: 0.695  loss_cls: 0.124  loss_box_reg: 0.283  loss_mask: 0.204  loss_rpn_cls: 0.011  loss_rpn_loc: 0.051  time: 0.5669  data_time: 0.0117  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:01:28 d2.utils.events]: [0m eta: 0:10:56  iter: 3839  total_loss: 0.653  loss_cls: 0.123  loss_box_reg: 0.258  loss_mask: 0.188  loss_rpn_cls: 0.014  loss_rpn_loc: 0.052  time: 0.5669  data_time: 0.0138  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:01:39 d2.utils.events]: [0m eta: 0:10:45  iter: 3859  total_loss: 0.619  loss_cls: 0.107  loss_box_reg: 0.263  loss_mask: 0.184  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 0.5669  data_time: 0.0131  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:01:50 d2.utils.events]: [0m eta: 0:10:33  iter: 3879  total_loss: 0.608  loss_cls: 0.112  loss_box_reg: 0.236  loss_mask: 0.183  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 0.5669  data_time: 0.0116  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:02:01 d2.utils.events]: [0m eta: 0:10:22  iter: 3899  total_loss: 0.650  loss_cls: 0.123  loss_box_reg: 0.250  loss_mask: 0.187  loss_rpn_cls: 0.009  loss_rpn_loc: 0.049  time: 0.5669  data_time: 0.0171  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:02:13 d2.utils.events]: [0m eta: 0:10:11  iter: 3919  total_loss: 0.687  loss_cls: 0.118  loss_box_reg: 0.266  loss_mask: 0.192  loss_rpn_cls: 0.013  loss_rpn_loc: 0.058  time: 0.5669  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:02:24 d2.utils.events]: [0m eta: 0:10:00  iter: 3939  total_loss: 0.608  loss_cls: 0.107  loss_box_reg: 0.241  loss_mask: 0.194  loss_rpn_cls: 0.013  loss_rpn_loc: 0.048  time: 0.5668  data_time: 0.0096  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:02:35 d2.utils.events]: [0m eta: 0:09:49  iter: 3959  total_loss: 0.583  loss_cls: 0.103  loss_box_reg: 0.238  loss_mask: 0.171  loss_rpn_cls: 0.007  loss_rpn_loc: 0.043  time: 0.5668  data_time: 0.0158  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:02:46 d2.utils.events]: [0m eta: 0:09:38  iter: 3979  total_loss: 0.622  loss_cls: 0.123  loss_box_reg: 0.249  loss_mask: 0.187  loss_rpn_cls: 0.011  loss_rpn_loc: 0.047  time: 0.5668  data_time: 0.0134  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:02:58 d2.utils.events]: [0m eta: 0:09:26  iter: 3999  total_loss: 0.603  loss_cls: 0.096  loss_box_reg: 0.250  loss_mask: 0.180  loss_rpn_cls: 0.008  loss_rpn_loc: 0.046  time: 0.5668  data_time: 0.0112  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:03:09 d2.utils.events]: [0m eta: 0:09:15  iter: 4019  total_loss: 0.643  loss_cls: 0.126  loss_box_reg: 0.266  loss_mask: 0.196  loss_rpn_cls: 0.009  loss_rpn_loc: 0.052  time: 0.5667  data_time: 0.0154  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:03:20 d2.utils.events]: [0m eta: 0:09:03  iter: 4039  total_loss: 0.616  loss_cls: 0.119  loss_box_reg: 0.234  loss_mask: 0.176  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 0.5667  data_time: 0.0134  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:03:32 d2.utils.events]: [0m eta: 0:08:52  iter: 4059  total_loss: 0.626  loss_cls: 0.116  loss_box_reg: 0.263  loss_mask: 0.188  loss_rpn_cls: 0.011  loss_rpn_loc: 0.053  time: 0.5668  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:03:44 d2.utils.events]: [0m eta: 0:08:42  iter: 4079  total_loss: 0.620  loss_cls: 0.120  loss_box_reg: 0.245  loss_mask: 0.196  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 0.5669  data_time: 0.0115  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:03:55 d2.utils.events]: [0m eta: 0:08:30  iter: 4099  total_loss: 0.607  loss_cls: 0.112  loss_box_reg: 0.237  loss_mask: 0.172  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 0.5669  data_time: 0.0141  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:04:07 d2.utils.events]: [0m eta: 0:08:19  iter: 4119  total_loss: 0.639  loss_cls: 0.115  loss_box_reg: 0.256  loss_mask: 0.201  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 0.5670  data_time: 0.0131  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:04:18 d2.utils.events]: [0m eta: 0:08:08  iter: 4139  total_loss: 0.581  loss_cls: 0.110  loss_box_reg: 0.250  loss_mask: 0.199  loss_rpn_cls: 0.008  loss_rpn_loc: 0.038  time: 0.5670  data_time: 0.0155  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:04:29 d2.utils.events]: [0m eta: 0:07:56  iter: 4159  total_loss: 0.667  loss_cls: 0.109  loss_box_reg: 0.258  loss_mask: 0.204  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 0.5670  data_time: 0.0115  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:04:41 d2.utils.events]: [0m eta: 0:07:45  iter: 4179  total_loss: 0.540  loss_cls: 0.106  loss_box_reg: 0.216  loss_mask: 0.153  loss_rpn_cls: 0.006  loss_rpn_loc: 0.034  time: 0.5670  data_time: 0.0119  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:04:52 d2.utils.events]: [0m eta: 0:07:33  iter: 4199  total_loss: 0.565  loss_cls: 0.107  loss_box_reg: 0.244  loss_mask: 0.194  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 0.5669  data_time: 0.0149  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:05:03 d2.utils.events]: [0m eta: 0:07:22  iter: 4219  total_loss: 0.593  loss_cls: 0.115  loss_box_reg: 0.228  loss_mask: 0.168  loss_rpn_cls: 0.009  loss_rpn_loc: 0.044  time: 0.5669  data_time: 0.0142  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:05:15 d2.utils.events]: [0m eta: 0:07:11  iter: 4239  total_loss: 0.583  loss_cls: 0.109  loss_box_reg: 0.237  loss_mask: 0.170  loss_rpn_cls: 0.010  loss_rpn_loc: 0.044  time: 0.5671  data_time: 0.0132  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:05:27 d2.utils.events]: [0m eta: 0:07:00  iter: 4259  total_loss: 0.593  loss_cls: 0.121  loss_box_reg: 0.230  loss_mask: 0.180  loss_rpn_cls: 0.011  loss_rpn_loc: 0.042  time: 0.5672  data_time: 0.0136  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:05:39 d2.utils.events]: [0m eta: 0:06:48  iter: 4279  total_loss: 0.684  loss_cls: 0.133  loss_box_reg: 0.266  loss_mask: 0.196  loss_rpn_cls: 0.009  loss_rpn_loc: 0.051  time: 0.5672  data_time: 0.0131  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:05:50 d2.utils.events]: [0m eta: 0:06:37  iter: 4299  total_loss: 0.532  loss_cls: 0.106  loss_box_reg: 0.214  loss_mask: 0.167  loss_rpn_cls: 0.005  loss_rpn_loc: 0.034  time: 0.5672  data_time: 0.0128  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:06:02 d2.utils.events]: [0m eta: 0:06:26  iter: 4319  total_loss: 0.657  loss_cls: 0.113  loss_box_reg: 0.260  loss_mask: 0.193  loss_rpn_cls: 0.007  loss_rpn_loc: 0.047  time: 0.5673  data_time: 0.0125  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:06:13 d2.utils.events]: [0m eta: 0:06:14  iter: 4339  total_loss: 0.628  loss_cls: 0.125  loss_box_reg: 0.258  loss_mask: 0.183  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 0.5672  data_time: 0.0164  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:06:24 d2.utils.events]: [0m eta: 0:06:03  iter: 4359  total_loss: 0.672  loss_cls: 0.123  loss_box_reg: 0.256  loss_mask: 0.183  loss_rpn_cls: 0.009  loss_rpn_loc: 0.050  time: 0.5673  data_time: 0.0129  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:06:35 d2.utils.events]: [0m eta: 0:05:52  iter: 4379  total_loss: 0.667  loss_cls: 0.123  loss_box_reg: 0.287  loss_mask: 0.206  loss_rpn_cls: 0.006  loss_rpn_loc: 0.050  time: 0.5672  data_time: 0.0125  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:06:47 d2.utils.events]: [0m eta: 0:05:42  iter: 4399  total_loss: 0.580  loss_cls: 0.103  loss_box_reg: 0.224  loss_mask: 0.181  loss_rpn_cls: 0.005  loss_rpn_loc: 0.040  time: 0.5673  data_time: 0.0146  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:06:58 d2.utils.events]: [0m eta: 0:05:30  iter: 4419  total_loss: 0.665  loss_cls: 0.114  loss_box_reg: 0.270  loss_mask: 0.187  loss_rpn_cls: 0.005  loss_rpn_loc: 0.047  time: 0.5671  data_time: 0.0140  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:07:09 d2.utils.events]: [0m eta: 0:05:19  iter: 4439  total_loss: 0.607  loss_cls: 0.111  loss_box_reg: 0.239  loss_mask: 0.187  loss_rpn_cls: 0.008  loss_rpn_loc: 0.044  time: 0.5672  data_time: 0.0148  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:07:21 d2.utils.events]: [0m eta: 0:05:08  iter: 4459  total_loss: 0.680  loss_cls: 0.113  loss_box_reg: 0.270  loss_mask: 0.184  loss_rpn_cls: 0.010  loss_rpn_loc: 0.058  time: 0.5673  data_time: 0.0125  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:07:32 d2.utils.events]: [0m eta: 0:04:57  iter: 4479  total_loss: 0.571  loss_cls: 0.102  loss_box_reg: 0.228  loss_mask: 0.197  loss_rpn_cls: 0.007  loss_rpn_loc: 0.042  time: 0.5673  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:07:44 d2.utils.events]: [0m eta: 0:04:45  iter: 4499  total_loss: 0.556  loss_cls: 0.105  loss_box_reg: 0.202  loss_mask: 0.191  loss_rpn_cls: 0.010  loss_rpn_loc: 0.043  time: 0.5672  data_time: 0.0122  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:07:54 d2.utils.events]: [0m eta: 0:04:33  iter: 4519  total_loss: 0.661  loss_cls: 0.126  loss_box_reg: 0.254  loss_mask: 0.190  loss_rpn_cls: 0.010  loss_rpn_loc: 0.047  time: 0.5671  data_time: 0.0142  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:08:06 d2.utils.events]: [0m eta: 0:04:21  iter: 4539  total_loss: 0.609  loss_cls: 0.112  loss_box_reg: 0.240  loss_mask: 0.195  loss_rpn_cls: 0.011  loss_rpn_loc: 0.035  time: 0.5672  data_time: 0.0119  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:08:18 d2.utils.events]: [0m eta: 0:04:10  iter: 4559  total_loss: 0.593  loss_cls: 0.105  loss_box_reg: 0.224  loss_mask: 0.190  loss_rpn_cls: 0.010  loss_rpn_loc: 0.037  time: 0.5672  data_time: 0.0111  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:08:29 d2.utils.events]: [0m eta: 0:03:59  iter: 4579  total_loss: 0.590  loss_cls: 0.101  loss_box_reg: 0.236  loss_mask: 0.187  loss_rpn_cls: 0.011  loss_rpn_loc: 0.043  time: 0.5672  data_time: 0.0127  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:08:40 d2.utils.events]: [0m eta: 0:03:48  iter: 4599  total_loss: 0.595  loss_cls: 0.100  loss_box_reg: 0.226  loss_mask: 0.179  loss_rpn_cls: 0.009  loss_rpn_loc: 0.041  time: 0.5672  data_time: 0.0107  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:08:51 d2.utils.events]: [0m eta: 0:03:36  iter: 4619  total_loss: 0.646  loss_cls: 0.103  loss_box_reg: 0.258  loss_mask: 0.210  loss_rpn_cls: 0.012  loss_rpn_loc: 0.056  time: 0.5671  data_time: 0.0128  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:09:02 d2.utils.events]: [0m eta: 0:03:25  iter: 4639  total_loss: 0.601  loss_cls: 0.114  loss_box_reg: 0.227  loss_mask: 0.186  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 0.5670  data_time: 0.0142  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:09:13 d2.utils.events]: [0m eta: 0:03:13  iter: 4659  total_loss: 0.566  loss_cls: 0.091  loss_box_reg: 0.235  loss_mask: 0.189  loss_rpn_cls: 0.011  loss_rpn_loc: 0.040  time: 0.5670  data_time: 0.0151  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:09:24 d2.utils.events]: [0m eta: 0:03:02  iter: 4679  total_loss: 0.571  loss_cls: 0.097  loss_box_reg: 0.219  loss_mask: 0.180  loss_rpn_cls: 0.012  loss_rpn_loc: 0.043  time: 0.5669  data_time: 0.0115  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:09:36 d2.utils.events]: [0m eta: 0:02:51  iter: 4699  total_loss: 0.573  loss_cls: 0.104  loss_box_reg: 0.228  loss_mask: 0.180  loss_rpn_cls: 0.012  loss_rpn_loc: 0.047  time: 0.5670  data_time: 0.0125  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:09:47 d2.utils.events]: [0m eta: 0:02:40  iter: 4719  total_loss: 0.610  loss_cls: 0.103  loss_box_reg: 0.259  loss_mask: 0.201  loss_rpn_cls: 0.013  loss_rpn_loc: 0.042  time: 0.5670  data_time: 0.0139  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:09:59 d2.utils.events]: [0m eta: 0:02:28  iter: 4739  total_loss: 0.585  loss_cls: 0.086  loss_box_reg: 0.227  loss_mask: 0.169  loss_rpn_cls: 0.006  loss_rpn_loc: 0.043  time: 0.5670  data_time: 0.0110  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:10:10 d2.utils.events]: [0m eta: 0:02:17  iter: 4759  total_loss: 0.608  loss_cls: 0.107  loss_box_reg: 0.241  loss_mask: 0.169  loss_rpn_cls: 0.008  loss_rpn_loc: 0.041  time: 0.5669  data_time: 0.0133  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:10:21 d2.utils.events]: [0m eta: 0:02:05  iter: 4779  total_loss: 0.556  loss_cls: 0.103  loss_box_reg: 0.227  loss_mask: 0.176  loss_rpn_cls: 0.009  loss_rpn_loc: 0.039  time: 0.5669  data_time: 0.0162  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:10:33 d2.utils.events]: [0m eta: 0:01:54  iter: 4799  total_loss: 0.565  loss_cls: 0.083  loss_box_reg: 0.210  loss_mask: 0.182  loss_rpn_cls: 0.012  loss_rpn_loc: 0.048  time: 0.5670  data_time: 0.0154  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:10:45 d2.utils.events]: [0m eta: 0:01:43  iter: 4819  total_loss: 0.603  loss_cls: 0.120  loss_box_reg: 0.240  loss_mask: 0.195  loss_rpn_cls: 0.007  loss_rpn_loc: 0.041  time: 0.5671  data_time: 0.0129  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:10:56 d2.utils.events]: [0m eta: 0:01:31  iter: 4839  total_loss: 0.537  loss_cls: 0.095  loss_box_reg: 0.212  loss_mask: 0.165  loss_rpn_cls: 0.007  loss_rpn_loc: 0.037  time: 0.5672  data_time: 0.0126  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:11:07 d2.utils.events]: [0m eta: 0:01:20  iter: 4859  total_loss: 0.608  loss_cls: 0.120  loss_box_reg: 0.237  loss_mask: 0.201  loss_rpn_cls: 0.008  loss_rpn_loc: 0.045  time: 0.5671  data_time: 0.0153  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:11:19 d2.utils.events]: [0m eta: 0:01:08  iter: 4879  total_loss: 0.606  loss_cls: 0.126  loss_box_reg: 0.257  loss_mask: 0.190  loss_rpn_cls: 0.008  loss_rpn_loc: 0.040  time: 0.5671  data_time: 0.0109  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:11:30 d2.utils.events]: [0m eta: 0:00:57  iter: 4899  total_loss: 0.613  loss_cls: 0.106  loss_box_reg: 0.244  loss_mask: 0.187  loss_rpn_cls: 0.010  loss_rpn_loc: 0.045  time: 0.5670  data_time: 0.0126  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:11:41 d2.utils.events]: [0m eta: 0:00:46  iter: 4919  total_loss: 0.563  loss_cls: 0.106  loss_box_reg: 0.233  loss_mask: 0.187  loss_rpn_cls: 0.007  loss_rpn_loc: 0.039  time: 0.5670  data_time: 0.0127  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:11:52 d2.utils.events]: [0m eta: 0:00:34  iter: 4939  total_loss: 0.623  loss_cls: 0.109  loss_box_reg: 0.258  loss_mask: 0.190  loss_rpn_cls: 0.009  loss_rpn_loc: 0.046  time: 0.5670  data_time: 0.0105  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:12:04 d2.utils.events]: [0m eta: 0:00:23  iter: 4959  total_loss: 0.635  loss_cls: 0.123  loss_box_reg: 0.253  loss_mask: 0.175  loss_rpn_cls: 0.007  loss_rpn_loc: 0.050  time: 0.5670  data_time: 0.0118  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:12:15 d2.utils.events]: [0m eta: 0:00:11  iter: 4979  total_loss: 0.634  loss_cls: 0.119  loss_box_reg: 0.255  loss_mask: 0.186  loss_rpn_cls: 0.008  loss_rpn_loc: 0.050  time: 0.5670  data_time: 0.0147  lr: 0.000250  max_mem: 5423M
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
.png
Loading sequence 0002
Loading sequence 0006
Loading sequence 0007
Loading sequence 0008
Loading sequence 0010
Loading sequence 0013
Loading sequence 0014
Loading sequence 0016
Loading sequence 0018
0002
0006
0007
0008
0010
0013
0014
0016
0018
Loaded 2920 images!
[32m[03/26 19:14:53 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    None    | 0            |    Car     | 8029         | Pedestrian | 3347         |
|            |              |            |              |            |              |
|   total    | 11376        |            |              |            |              |[0m
[32m[03/26 19:14:53 d2.data.common]: [0mSerializing 2920 elements to byte tensors and concatenating them all ...
[32m[03/26 19:14:54 d2.data.common]: [0mSerialized dataset takes 7.44 MiB
[5m[31mWARNING[0m [32m[03/26 19:14:54 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/26 19:14:54 d2.utils.events]: [0m eta: 0:00:00  iter: 4999  total_loss: 0.568  loss_cls: 0.108  loss_box_reg: 0.211  loss_mask: 0.169  loss_rpn_cls: 0.005  loss_rpn_loc: 0.035  time: 0.5670  data_time: 0.0106  lr: 0.000250  max_mem: 5423M
[32m[03/26 19:14:54 d2.engine.hooks]: [0mOverall training speed: 4997 iterations in 0:47:13 (0.5671 s / it)
[32m[03/26 19:14:54 d2.engine.hooks]: [0mTotal training time: 0:49:50 (0:02:36 on hooks)
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
.png
Loading sequence 0002
Loading sequence 0006
Loading sequence 0007
Loading sequence 0008
Loading sequence 0010
Loading sequence 0013
Loading sequence 0014
Loading sequence 0016
Loading sequence 0018
0002
0006
0007
0008
0010
0013
0014
0016
0018
Loaded 2920 images!
[5m[31mWARNING[0m [32m[03/26 19:16:28 d2.evaluation.coco_evaluation]: [0mjson_file was not found in MetaDataCatalog for 'KITTI_MOTS_val'. Trying to convert it to COCO format ...
[32m[03/26 19:16:28 d2.data.datasets.coco]: [0mConverting annotations of dataset 'KITTI_MOTS_val' to COCO format ...)
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
.png
Loading sequence 0002
Loading sequence 0006
Loading sequence 0007
Loading sequence 0008
Loading sequence 0010
Loading sequence 0013
Loading sequence 0014
Loading sequence 0016
Loading sequence 0018
0002
0006
0007
0008
0010
0013
0014
0016
0018
Loaded 2920 images!
[32m[03/26 19:17:26 d2.data.datasets.coco]: [0mConverting dataset dicts into COCO format
[32m[03/26 19:17:30 d2.data.datasets.coco]: [0mConversion finished, num images: 2920, num annotations: 11376
[32m[03/26 19:17:30 d2.data.datasets.coco]: [0mCaching COCO format annotations at '../mask_rcnn_R_50_FPN/output/KITTI_MOTS_val_coco_format.json' ...
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
.png
Loading sequence 0002
Loading sequence 0006
Loading sequence 0007
Loading sequence 0008
Loading sequence 0010
Loading sequence 0013
Loading sequence 0014
Loading sequence 0016
Loading sequence 0018
0002
0006
0007
0008
0010
0013
0014
0016
0018
Loaded 2920 images!
[32m[03/26 19:18:33 d2.data.common]: [0mSerializing 2920 elements to byte tensors and concatenating them all ...
[32m[03/26 19:18:33 d2.data.common]: [0mSerialized dataset takes 7.44 MiB
[32m[03/26 19:18:33 d2.evaluation.evaluator]: [0mStart inference on 2920 images
[32m[03/26 19:18:35 d2.evaluation.evaluator]: [0mInference done 11/2920. 0.0916 s / img. ETA=0:04:33
[32m[03/26 19:18:40 d2.evaluation.evaluator]: [0mInference done 66/2920. 0.0897 s / img. ETA=0:04:22
[32m[03/26 19:18:45 d2.evaluation.evaluator]: [0mInference done 120/2920. 0.0904 s / img. ETA=0:04:20
[32m[03/26 19:18:50 d2.evaluation.evaluator]: [0mInference done 174/2920. 0.0908 s / img. ETA=0:04:16
[32m[03/26 19:18:55 d2.evaluation.evaluator]: [0mInference done 228/2920. 0.0909 s / img. ETA=0:04:11
[32m[03/26 19:19:00 d2.evaluation.evaluator]: [0mInference done 283/2920. 0.0908 s / img. ETA=0:04:05
[32m[03/26 19:19:05 d2.evaluation.evaluator]: [0mInference done 337/2920. 0.0908 s / img. ETA=0:04:00
[32m[03/26 19:19:10 d2.evaluation.evaluator]: [0mInference done 391/2920. 0.0909 s / img. ETA=0:03:55
[32m[03/26 19:19:15 d2.evaluation.evaluator]: [0mInference done 445/2920. 0.0910 s / img. ETA=0:03:50
[32m[03/26 19:19:21 d2.evaluation.evaluator]: [0mInference done 498/2920. 0.0912 s / img. ETA=0:03:46
[32m[03/26 19:19:26 d2.evaluation.evaluator]: [0mInference done 551/2920. 0.0913 s / img. ETA=0:03:41
[32m[03/26 19:19:31 d2.evaluation.evaluator]: [0mInference done 604/2920. 0.0915 s / img. ETA=0:03:37
[32m[03/26 19:19:36 d2.evaluation.evaluator]: [0mInference done 657/2920. 0.0915 s / img. ETA=0:03:32
[32m[03/26 19:19:41 d2.evaluation.evaluator]: [0mInference done 710/2920. 0.0917 s / img. ETA=0:03:27
[32m[03/26 19:19:46 d2.evaluation.evaluator]: [0mInference done 764/2920. 0.0917 s / img. ETA=0:03:22
[32m[03/26 19:19:51 d2.evaluation.evaluator]: [0mInference done 818/2920. 0.0917 s / img. ETA=0:03:17
[32m[03/26 19:19:56 d2.evaluation.evaluator]: [0mInference done 872/2920. 0.0917 s / img. ETA=0:03:12
[32m[03/26 19:20:01 d2.evaluation.evaluator]: [0mInference done 926/2920. 0.0917 s / img. ETA=0:03:07
[32m[03/26 19:20:06 d2.evaluation.evaluator]: [0mInference done 980/2920. 0.0918 s / img. ETA=0:03:02
[32m[03/26 19:20:11 d2.evaluation.evaluator]: [0mInference done 1034/2920. 0.0918 s / img. ETA=0:02:57
[32m[03/26 19:20:16 d2.evaluation.evaluator]: [0mInference done 1088/2920. 0.0918 s / img. ETA=0:02:52
[32m[03/26 19:20:21 d2.evaluation.evaluator]: [0mInference done 1142/2920. 0.0918 s / img. ETA=0:02:47
[32m[03/26 19:20:26 d2.evaluation.evaluator]: [0mInference done 1196/2920. 0.0918 s / img. ETA=0:02:42
[32m[03/26 19:20:31 d2.evaluation.evaluator]: [0mInference done 1250/2920. 0.0918 s / img. ETA=0:02:36
[32m[03/26 19:20:36 d2.evaluation.evaluator]: [0mInference done 1303/2920. 0.0918 s / img. ETA=0:02:32
[32m[03/26 19:20:42 d2.evaluation.evaluator]: [0mInference done 1356/2920. 0.0919 s / img. ETA=0:02:27
[32m[03/26 19:20:47 d2.evaluation.evaluator]: [0mInference done 1408/2920. 0.0919 s / img. ETA=0:02:22
[32m[03/26 19:20:52 d2.evaluation.evaluator]: [0mInference done 1461/2920. 0.0920 s / img. ETA=0:02:17
[32m[03/26 19:20:57 d2.evaluation.evaluator]: [0mInference done 1514/2920. 0.0920 s / img. ETA=0:02:12
[32m[03/26 19:21:02 d2.evaluation.evaluator]: [0mInference done 1567/2920. 0.0920 s / img. ETA=0:02:07
[32m[03/26 19:21:07 d2.evaluation.evaluator]: [0mInference done 1618/2920. 0.0921 s / img. ETA=0:02:02
[32m[03/26 19:21:12 d2.evaluation.evaluator]: [0mInference done 1671/2920. 0.0922 s / img. ETA=0:01:57
[32m[03/26 19:21:17 d2.evaluation.evaluator]: [0mInference done 1724/2920. 0.0922 s / img. ETA=0:01:53
[32m[03/26 19:21:22 d2.evaluation.evaluator]: [0mInference done 1777/2920. 0.0922 s / img. ETA=0:01:48
[32m[03/26 19:21:27 d2.evaluation.evaluator]: [0mInference done 1830/2920. 0.0922 s / img. ETA=0:01:43
[32m[03/26 19:21:32 d2.evaluation.evaluator]: [0mInference done 1882/2920. 0.0923 s / img. ETA=0:01:38
[32m[03/26 19:21:37 d2.evaluation.evaluator]: [0mInference done 1934/2920. 0.0923 s / img. ETA=0:01:33
[32m[03/26 19:21:42 d2.evaluation.evaluator]: [0mInference done 1983/2920. 0.0924 s / img. ETA=0:01:28
[32m[03/26 19:21:47 d2.evaluation.evaluator]: [0mInference done 2033/2920. 0.0925 s / img. ETA=0:01:24
[32m[03/26 19:21:52 d2.evaluation.evaluator]: [0mInference done 2082/2920. 0.0926 s / img. ETA=0:01:19
[32m[03/26 19:21:57 d2.evaluation.evaluator]: [0mInference done 2132/2920. 0.0927 s / img. ETA=0:01:15
[32m[03/26 19:22:02 d2.evaluation.evaluator]: [0mInference done 2182/2920. 0.0927 s / img. ETA=0:01:10
[32m[03/26 19:22:07 d2.evaluation.evaluator]: [0mInference done 2231/2920. 0.0929 s / img. ETA=0:01:05
[32m[03/26 19:22:12 d2.evaluation.evaluator]: [0mInference done 2281/2920. 0.0929 s / img. ETA=0:01:01
[32m[03/26 19:22:17 d2.evaluation.evaluator]: [0mInference done 2332/2920. 0.0930 s / img. ETA=0:00:56
[32m[03/26 19:22:22 d2.evaluation.evaluator]: [0mInference done 2382/2920. 0.0931 s / img. ETA=0:00:51
[32m[03/26 19:22:27 d2.evaluation.evaluator]: [0mInference done 2431/2920. 0.0931 s / img. ETA=0:00:46
[32m[03/26 19:22:33 d2.evaluation.evaluator]: [0mInference done 2480/2920. 0.0932 s / img. ETA=0:00:42
[32m[03/26 19:22:38 d2.evaluation.evaluator]: [0mInference done 2527/2920. 0.0933 s / img. ETA=0:00:37
[32m[03/26 19:22:43 d2.evaluation.evaluator]: [0mInference done 2576/2920. 0.0933 s / img. ETA=0:00:33
[32m[03/26 19:22:48 d2.evaluation.evaluator]: [0mInference done 2627/2920. 0.0934 s / img. ETA=0:00:28
[32m[03/26 19:22:53 d2.evaluation.evaluator]: [0mInference done 2678/2920. 0.0935 s / img. ETA=0:00:23
[32m[03/26 19:22:58 d2.evaluation.evaluator]: [0mInference done 2730/2920. 0.0935 s / img. ETA=0:00:18
[32m[03/26 19:23:03 d2.evaluation.evaluator]: [0mInference done 2782/2920. 0.0935 s / img. ETA=0:00:13
[32m[03/26 19:23:08 d2.evaluation.evaluator]: [0mInference done 2833/2920. 0.0935 s / img. ETA=0:00:08
[32m[03/26 19:23:13 d2.evaluation.evaluator]: [0mInference done 2884/2920. 0.0936 s / img. ETA=0:00:03
[32m[03/26 19:23:17 d2.evaluation.evaluator]: [0mTotal inference time: 0:04:42.108376 (0.096778 s / img per device, on 1 devices)
[32m[03/26 19:23:17 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:04:32 (0.093607 s / img per device, on 1 devices)
[32m[03/26 19:23:17 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/26 19:23:17 d2.evaluation.coco_evaluation]: [0mSaving results to ../mask_rcnn_R_50_FPN/output/coco_instances_results.json
[32m[03/26 19:23:17 d2.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=17.76s).
Accumulating evaluation results...
DONE (t=0.35s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.359
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.286
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.315
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.082
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.199
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.431
[32m[03/26 19:23:35 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 24.563 | 35.879 | 28.602 | 16.700 | 31.456 | 31.677 |
[32m[03/26 19:23:35 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP   | category   | AP    | category   | AP     |
|:-----------|:-----|:-----------|:------|:-----------|:-------|
| None       | nan  | Car        | 0.000 | Pedestrian | 49.127 |
Loading and preparing results...
DONE (t=0.07s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
DONE (t=13.07s).
Accumulating evaluation results...
DONE (t=0.43s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.328
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.164
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.219
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.323
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.059
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.208
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.211
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.153
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.256
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.361
[32m[03/26 19:23:49 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |
|:------:|:------:|:------:|:-----:|:------:|:------:|
| 17.127 | 32.806 | 16.430 | 9.370 | 21.865 | 32.260 |
[32m[03/26 19:23:49 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP   | category   | AP    | category   | AP     |
|:-----------|:-----|:-----------|:------|:-----------|:-------|
| None       | nan  | Car        | 0.000 | Pedestrian | 34.254 |
