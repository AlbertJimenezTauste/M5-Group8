Metadata(name='KITTI_MOTS_train', thing_classes=['None', 'Car', 'Pedestrian'])
Loading sequence 0000
Loading sequence 0001
Loading sequence 0003
Loading sequence 0004
Loading sequence 0005
Loading sequence 0009
Loading sequence 0011
Loading sequence 0012
Loading sequence 0015
Loading sequence 0017
Loading sequence 0019
Loading sequence 0020
0000
0001
0003
0004
0005
0009
0011
0012
0015
0017
0019
0020
Loaded 5007 images!
/home/mcv/datasets/KITTI-MOTS/training/image_02/0011/000126.png
/home/mcv/datasets/KITTI-MOTS/training/image_02/0009/000475.png
[32m[03/28 11:29:51 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=4, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
Loading sequence 0000
Loading sequence 0001
Loading sequence 0003
Loading sequence 0004
Loading sequence 0005
Loading sequence 0009
Loading sequence 0011
Loading sequence 0012
Loading sequence 0015
Loading sequence 0017
Loading sequence 0019
Loading sequence 0020
0000
0001
0003
0004
0005
0009
0011
0012
0015
0017
0019
0020
Loaded 5007 images!
[32m[03/28 11:33:16 d2.data.build]: [0mRemoved 487 images with no usable annotations. 4520 images left.
[32m[03/28 11:33:16 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    None    | 0            |    Car     | 18830        | Pedestrian | 8067         |
|            |              |            |              |            |              |
|   total    | 26897        |            |              |            |              |[0m
[32m[03/28 11:33:16 d2.data.common]: [0mSerializing 4520 elements to byte tensors and concatenating them all ...
[32m[03/28 11:33:17 d2.data.common]: [0mSerialized dataset takes 17.95 MiB
[32m[03/28 11:33:17 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(800, 832, 864, 896, 928, 960, 992, 1024), max_size=2048, sample_style='choice'), RandomFlip()]
[32m[03/28 11:33:17 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 11:33:18 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[03/28 11:33:28 d2.utils.events]: [0m eta: 0:37:58  iter: 19  total_loss: 2.977  loss_cls: 1.359  loss_box_reg: 0.871  loss_mask: 0.693  loss_rpn_cls: 0.016  loss_rpn_loc: 0.024  time: 0.4590  data_time: 0.0252  lr: 0.000005  max_mem: 4051M
[32m[03/28 11:33:38 d2.utils.events]: [0m eta: 0:37:49  iter: 39  total_loss: 2.822  loss_cls: 1.323  loss_box_reg: 0.743  loss_mask: 0.688  loss_rpn_cls: 0.015  loss_rpn_loc: 0.014  time: 0.4587  data_time: 0.0084  lr: 0.000010  max_mem: 4055M
[32m[03/28 11:33:47 d2.utils.events]: [0m eta: 0:37:55  iter: 59  total_loss: 2.741  loss_cls: 1.254  loss_box_reg: 0.816  loss_mask: 0.676  loss_rpn_cls: 0.011  loss_rpn_loc: 0.016  time: 0.4595  data_time: 0.0083  lr: 0.000015  max_mem: 4057M
[32m[03/28 11:33:56 d2.utils.events]: [0m eta: 0:37:46  iter: 79  total_loss: 2.708  loss_cls: 1.162  loss_box_reg: 0.835  loss_mask: 0.660  loss_rpn_cls: 0.019  loss_rpn_loc: 0.021  time: 0.4605  data_time: 0.0081  lr: 0.000020  max_mem: 4057M
[32m[03/28 11:34:05 d2.utils.events]: [0m eta: 0:37:42  iter: 99  total_loss: 2.590  loss_cls: 1.033  loss_box_reg: 0.879  loss_mask: 0.640  loss_rpn_cls: 0.014  loss_rpn_loc: 0.019  time: 0.4623  data_time: 0.0098  lr: 0.000025  max_mem: 4057M
[32m[03/28 11:34:15 d2.utils.events]: [0m eta: 0:37:40  iter: 119  total_loss: 2.339  loss_cls: 0.889  loss_box_reg: 0.750  loss_mask: 0.630  loss_rpn_cls: 0.028  loss_rpn_loc: 0.021  time: 0.4631  data_time: 0.0079  lr: 0.000030  max_mem: 4057M
[32m[03/28 11:34:24 d2.utils.events]: [0m eta: 0:37:31  iter: 139  total_loss: 2.219  loss_cls: 0.785  loss_box_reg: 0.829  loss_mask: 0.603  loss_rpn_cls: 0.018  loss_rpn_loc: 0.015  time: 0.4638  data_time: 0.0077  lr: 0.000035  max_mem: 4058M
[32m[03/28 11:34:34 d2.utils.events]: [0m eta: 0:37:28  iter: 159  total_loss: 2.159  loss_cls: 0.690  loss_box_reg: 0.826  loss_mask: 0.568  loss_rpn_cls: 0.022  loss_rpn_loc: 0.030  time: 0.4652  data_time: 0.0089  lr: 0.000040  max_mem: 4059M
[32m[03/28 11:34:43 d2.utils.events]: [0m eta: 0:37:24  iter: 179  total_loss: 2.029  loss_cls: 0.619  loss_box_reg: 0.847  loss_mask: 0.538  loss_rpn_cls: 0.018  loss_rpn_loc: 0.021  time: 0.4662  data_time: 0.0100  lr: 0.000045  max_mem: 4059M
[32m[03/28 11:34:53 d2.utils.events]: [0m eta: 0:37:16  iter: 199  total_loss: 1.876  loss_cls: 0.517  loss_box_reg: 0.806  loss_mask: 0.493  loss_rpn_cls: 0.011  loss_rpn_loc: 0.021  time: 0.4665  data_time: 0.0090  lr: 0.000050  max_mem: 4059M
[32m[03/28 11:35:02 d2.utils.events]: [0m eta: 0:37:09  iter: 219  total_loss: 1.874  loss_cls: 0.525  loss_box_reg: 0.819  loss_mask: 0.463  loss_rpn_cls: 0.022  loss_rpn_loc: 0.025  time: 0.4669  data_time: 0.0085  lr: 0.000055  max_mem: 4059M
[32m[03/28 11:35:11 d2.utils.events]: [0m eta: 0:37:02  iter: 239  total_loss: 1.719  loss_cls: 0.471  loss_box_reg: 0.801  loss_mask: 0.431  loss_rpn_cls: 0.009  loss_rpn_loc: 0.014  time: 0.4673  data_time: 0.0083  lr: 0.000060  max_mem: 4059M
[32m[03/28 11:35:21 d2.utils.events]: [0m eta: 0:36:57  iter: 259  total_loss: 1.718  loss_cls: 0.483  loss_box_reg: 0.805  loss_mask: 0.423  loss_rpn_cls: 0.019  loss_rpn_loc: 0.019  time: 0.4678  data_time: 0.0111  lr: 0.000065  max_mem: 4059M
[32m[03/28 11:35:30 d2.utils.events]: [0m eta: 0:36:49  iter: 279  total_loss: 1.644  loss_cls: 0.431  loss_box_reg: 0.757  loss_mask: 0.406  loss_rpn_cls: 0.016  loss_rpn_loc: 0.017  time: 0.4679  data_time: 0.0106  lr: 0.000070  max_mem: 4059M
[32m[03/28 11:35:40 d2.utils.events]: [0m eta: 0:36:40  iter: 299  total_loss: 1.613  loss_cls: 0.419  loss_box_reg: 0.758  loss_mask: 0.398  loss_rpn_cls: 0.015  loss_rpn_loc: 0.022  time: 0.4681  data_time: 0.0109  lr: 0.000075  max_mem: 4059M
[32m[03/28 11:35:49 d2.utils.events]: [0m eta: 0:36:33  iter: 319  total_loss: 1.655  loss_cls: 0.406  loss_box_reg: 0.752  loss_mask: 0.392  loss_rpn_cls: 0.014  loss_rpn_loc: 0.026  time: 0.4683  data_time: 0.0099  lr: 0.000080  max_mem: 4059M
[32m[03/28 11:35:59 d2.utils.events]: [0m eta: 0:36:24  iter: 339  total_loss: 1.423  loss_cls: 0.367  loss_box_reg: 0.717  loss_mask: 0.350  loss_rpn_cls: 0.017  loss_rpn_loc: 0.024  time: 0.4685  data_time: 0.0081  lr: 0.000085  max_mem: 4059M
[32m[03/28 11:36:08 d2.utils.events]: [0m eta: 0:36:14  iter: 359  total_loss: 1.310  loss_cls: 0.316  loss_box_reg: 0.620  loss_mask: 0.336  loss_rpn_cls: 0.013  loss_rpn_loc: 0.020  time: 0.4685  data_time: 0.0081  lr: 0.000090  max_mem: 4059M
[32m[03/28 11:36:18 d2.utils.events]: [0m eta: 0:36:06  iter: 379  total_loss: 1.422  loss_cls: 0.342  loss_box_reg: 0.687  loss_mask: 0.330  loss_rpn_cls: 0.014  loss_rpn_loc: 0.025  time: 0.4689  data_time: 0.0092  lr: 0.000095  max_mem: 4059M
[32m[03/28 11:36:27 d2.utils.events]: [0m eta: 0:35:57  iter: 399  total_loss: 1.205  loss_cls: 0.266  loss_box_reg: 0.588  loss_mask: 0.273  loss_rpn_cls: 0.021  loss_rpn_loc: 0.019  time: 0.4694  data_time: 0.0080  lr: 0.000100  max_mem: 4059M
[32m[03/28 11:36:37 d2.utils.events]: [0m eta: 0:35:49  iter: 419  total_loss: 1.209  loss_cls: 0.283  loss_box_reg: 0.570  loss_mask: 0.301  loss_rpn_cls: 0.010  loss_rpn_loc: 0.019  time: 0.4698  data_time: 0.0082  lr: 0.000105  max_mem: 4059M
[32m[03/28 11:36:46 d2.utils.events]: [0m eta: 0:35:41  iter: 439  total_loss: 1.236  loss_cls: 0.277  loss_box_reg: 0.578  loss_mask: 0.322  loss_rpn_cls: 0.014  loss_rpn_loc: 0.019  time: 0.4702  data_time: 0.0086  lr: 0.000110  max_mem: 4059M
[32m[03/28 11:36:56 d2.utils.events]: [0m eta: 0:35:34  iter: 459  total_loss: 1.090  loss_cls: 0.270  loss_box_reg: 0.520  loss_mask: 0.243  loss_rpn_cls: 0.026  loss_rpn_loc: 0.026  time: 0.4709  data_time: 0.0092  lr: 0.000115  max_mem: 4059M
[32m[03/28 11:37:06 d2.utils.events]: [0m eta: 0:35:25  iter: 479  total_loss: 0.905  loss_cls: 0.216  loss_box_reg: 0.414  loss_mask: 0.231  loss_rpn_cls: 0.013  loss_rpn_loc: 0.012  time: 0.4710  data_time: 0.0081  lr: 0.000120  max_mem: 4059M
[32m[03/28 11:37:15 d2.utils.events]: [0m eta: 0:35:17  iter: 499  total_loss: 1.015  loss_cls: 0.240  loss_box_reg: 0.436  loss_mask: 0.252  loss_rpn_cls: 0.026  loss_rpn_loc: 0.021  time: 0.4714  data_time: 0.0076  lr: 0.000125  max_mem: 4059M
[32m[03/28 11:37:25 d2.utils.events]: [0m eta: 0:35:08  iter: 519  total_loss: 0.945  loss_cls: 0.220  loss_box_reg: 0.404  loss_mask: 0.271  loss_rpn_cls: 0.025  loss_rpn_loc: 0.024  time: 0.4717  data_time: 0.0091  lr: 0.000130  max_mem: 4059M
[32m[03/28 11:37:34 d2.utils.events]: [0m eta: 0:35:00  iter: 539  total_loss: 0.940  loss_cls: 0.209  loss_box_reg: 0.401  loss_mask: 0.241  loss_rpn_cls: 0.014  loss_rpn_loc: 0.020  time: 0.4720  data_time: 0.0090  lr: 0.000135  max_mem: 4059M
[32m[03/28 11:37:44 d2.utils.events]: [0m eta: 0:34:51  iter: 559  total_loss: 0.901  loss_cls: 0.202  loss_box_reg: 0.385  loss_mask: 0.229  loss_rpn_cls: 0.011  loss_rpn_loc: 0.023  time: 0.4726  data_time: 0.0082  lr: 0.000140  max_mem: 4059M
[32m[03/28 11:37:54 d2.utils.events]: [0m eta: 0:34:43  iter: 579  total_loss: 0.807  loss_cls: 0.180  loss_box_reg: 0.342  loss_mask: 0.209  loss_rpn_cls: 0.009  loss_rpn_loc: 0.023  time: 0.4730  data_time: 0.0090  lr: 0.000145  max_mem: 4059M
[32m[03/28 11:38:03 d2.utils.events]: [0m eta: 0:34:35  iter: 599  total_loss: 0.688  loss_cls: 0.176  loss_box_reg: 0.310  loss_mask: 0.177  loss_rpn_cls: 0.013  loss_rpn_loc: 0.015  time: 0.4732  data_time: 0.0082  lr: 0.000150  max_mem: 4059M
[32m[03/28 11:38:13 d2.utils.events]: [0m eta: 0:34:25  iter: 619  total_loss: 0.753  loss_cls: 0.163  loss_box_reg: 0.315  loss_mask: 0.210  loss_rpn_cls: 0.010  loss_rpn_loc: 0.017  time: 0.4733  data_time: 0.0083  lr: 0.000155  max_mem: 4059M
[32m[03/28 11:38:23 d2.utils.events]: [0m eta: 0:34:17  iter: 639  total_loss: 0.694  loss_cls: 0.158  loss_box_reg: 0.299  loss_mask: 0.207  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 0.4735  data_time: 0.0103  lr: 0.000160  max_mem: 4059M
[32m[03/28 11:38:32 d2.utils.events]: [0m eta: 0:34:08  iter: 659  total_loss: 0.662  loss_cls: 0.160  loss_box_reg: 0.265  loss_mask: 0.186  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 0.4737  data_time: 0.0096  lr: 0.000165  max_mem: 4059M
[32m[03/28 11:38:42 d2.utils.events]: [0m eta: 0:33:59  iter: 679  total_loss: 0.894  loss_cls: 0.205  loss_box_reg: 0.388  loss_mask: 0.251  loss_rpn_cls: 0.031  loss_rpn_loc: 0.034  time: 0.4740  data_time: 0.0097  lr: 0.000170  max_mem: 4059M
[32m[03/28 11:38:52 d2.utils.events]: [0m eta: 0:33:50  iter: 699  total_loss: 0.686  loss_cls: 0.144  loss_box_reg: 0.277  loss_mask: 0.171  loss_rpn_cls: 0.011  loss_rpn_loc: 0.018  time: 0.4744  data_time: 0.0094  lr: 0.000175  max_mem: 4059M
[32m[03/28 11:39:01 d2.utils.events]: [0m eta: 0:33:42  iter: 719  total_loss: 0.820  loss_cls: 0.177  loss_box_reg: 0.348  loss_mask: 0.238  loss_rpn_cls: 0.019  loss_rpn_loc: 0.030  time: 0.4746  data_time: 0.0090  lr: 0.000180  max_mem: 4059M
[32m[03/28 11:39:11 d2.utils.events]: [0m eta: 0:33:33  iter: 739  total_loss: 0.668  loss_cls: 0.156  loss_box_reg: 0.309  loss_mask: 0.200  loss_rpn_cls: 0.014  loss_rpn_loc: 0.020  time: 0.4747  data_time: 0.0093  lr: 0.000185  max_mem: 4059M
[32m[03/28 11:39:21 d2.utils.events]: [0m eta: 0:33:24  iter: 759  total_loss: 0.605  loss_cls: 0.129  loss_box_reg: 0.265  loss_mask: 0.196  loss_rpn_cls: 0.013  loss_rpn_loc: 0.016  time: 0.4750  data_time: 0.0103  lr: 0.000190  max_mem: 4059M
[32m[03/28 11:39:30 d2.utils.events]: [0m eta: 0:33:15  iter: 779  total_loss: 0.702  loss_cls: 0.149  loss_box_reg: 0.305  loss_mask: 0.212  loss_rpn_cls: 0.016  loss_rpn_loc: 0.021  time: 0.4752  data_time: 0.0082  lr: 0.000195  max_mem: 4059M
[32m[03/28 11:39:40 d2.utils.events]: [0m eta: 0:33:07  iter: 799  total_loss: 0.715  loss_cls: 0.177  loss_box_reg: 0.298  loss_mask: 0.185  loss_rpn_cls: 0.011  loss_rpn_loc: 0.019  time: 0.4754  data_time: 0.0107  lr: 0.000200  max_mem: 4061M
[32m[03/28 11:39:50 d2.utils.events]: [0m eta: 0:32:58  iter: 819  total_loss: 0.720  loss_cls: 0.159  loss_box_reg: 0.309  loss_mask: 0.228  loss_rpn_cls: 0.006  loss_rpn_loc: 0.017  time: 0.4756  data_time: 0.0090  lr: 0.000205  max_mem: 4061M
[32m[03/28 11:39:59 d2.utils.events]: [0m eta: 0:32:49  iter: 839  total_loss: 0.658  loss_cls: 0.166  loss_box_reg: 0.245  loss_mask: 0.184  loss_rpn_cls: 0.015  loss_rpn_loc: 0.017  time: 0.4757  data_time: 0.0090  lr: 0.000210  max_mem: 4061M
[32m[03/28 11:40:09 d2.utils.events]: [0m eta: 0:32:40  iter: 859  total_loss: 0.784  loss_cls: 0.169  loss_box_reg: 0.310  loss_mask: 0.231  loss_rpn_cls: 0.019  loss_rpn_loc: 0.026  time: 0.4758  data_time: 0.0084  lr: 0.000215  max_mem: 4061M
[32m[03/28 11:40:18 d2.utils.events]: [0m eta: 0:32:31  iter: 879  total_loss: 0.608  loss_cls: 0.141  loss_box_reg: 0.234  loss_mask: 0.195  loss_rpn_cls: 0.011  loss_rpn_loc: 0.013  time: 0.4757  data_time: 0.0081  lr: 0.000220  max_mem: 4061M
[32m[03/28 11:40:28 d2.utils.events]: [0m eta: 0:32:22  iter: 899  total_loss: 0.656  loss_cls: 0.135  loss_box_reg: 0.244  loss_mask: 0.223  loss_rpn_cls: 0.013  loss_rpn_loc: 0.018  time: 0.4759  data_time: 0.0106  lr: 0.000225  max_mem: 4061M
[32m[03/28 11:40:38 d2.utils.events]: [0m eta: 0:32:13  iter: 919  total_loss: 0.563  loss_cls: 0.134  loss_box_reg: 0.219  loss_mask: 0.193  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 0.4762  data_time: 0.0107  lr: 0.000230  max_mem: 4061M
[32m[03/28 11:40:47 d2.utils.events]: [0m eta: 0:32:04  iter: 939  total_loss: 0.553  loss_cls: 0.112  loss_box_reg: 0.189  loss_mask: 0.176  loss_rpn_cls: 0.008  loss_rpn_loc: 0.014  time: 0.4763  data_time: 0.0091  lr: 0.000235  max_mem: 4061M
[32m[03/28 11:40:57 d2.utils.events]: [0m eta: 0:31:55  iter: 959  total_loss: 0.608  loss_cls: 0.128  loss_box_reg: 0.211  loss_mask: 0.191  loss_rpn_cls: 0.009  loss_rpn_loc: 0.014  time: 0.4763  data_time: 0.0081  lr: 0.000240  max_mem: 4061M
[32m[03/28 11:41:07 d2.utils.events]: [0m eta: 0:31:45  iter: 979  total_loss: 0.620  loss_cls: 0.146  loss_box_reg: 0.240  loss_mask: 0.178  loss_rpn_cls: 0.008  loss_rpn_loc: 0.020  time: 0.4763  data_time: 0.0081  lr: 0.000245  max_mem: 4061M
[32m[03/28 11:41:16 d2.utils.events]: [0m eta: 0:31:36  iter: 999  total_loss: 0.577  loss_cls: 0.115  loss_box_reg: 0.241  loss_mask: 0.184  loss_rpn_cls: 0.011  loss_rpn_loc: 0.023  time: 0.4763  data_time: 0.0099  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:41:26 d2.utils.events]: [0m eta: 0:31:28  iter: 1019  total_loss: 0.662  loss_cls: 0.148  loss_box_reg: 0.239  loss_mask: 0.208  loss_rpn_cls: 0.013  loss_rpn_loc: 0.018  time: 0.4764  data_time: 0.0111  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:41:35 d2.utils.events]: [0m eta: 0:31:20  iter: 1039  total_loss: 0.497  loss_cls: 0.115  loss_box_reg: 0.217  loss_mask: 0.174  loss_rpn_cls: 0.007  loss_rpn_loc: 0.015  time: 0.4763  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:41:45 d2.utils.events]: [0m eta: 0:31:12  iter: 1059  total_loss: 0.600  loss_cls: 0.115  loss_box_reg: 0.251  loss_mask: 0.176  loss_rpn_cls: 0.013  loss_rpn_loc: 0.021  time: 0.4764  data_time: 0.0096  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:41:55 d2.utils.events]: [0m eta: 0:31:04  iter: 1079  total_loss: 0.620  loss_cls: 0.141  loss_box_reg: 0.248  loss_mask: 0.193  loss_rpn_cls: 0.013  loss_rpn_loc: 0.018  time: 0.4765  data_time: 0.0099  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:42:04 d2.utils.events]: [0m eta: 0:30:55  iter: 1099  total_loss: 0.574  loss_cls: 0.135  loss_box_reg: 0.230  loss_mask: 0.192  loss_rpn_cls: 0.009  loss_rpn_loc: 0.018  time: 0.4767  data_time: 0.0092  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:42:14 d2.utils.events]: [0m eta: 0:30:47  iter: 1119  total_loss: 0.595  loss_cls: 0.125  loss_box_reg: 0.243  loss_mask: 0.195  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 0.4767  data_time: 0.0090  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:42:24 d2.utils.events]: [0m eta: 0:30:39  iter: 1139  total_loss: 0.640  loss_cls: 0.123  loss_box_reg: 0.239  loss_mask: 0.207  loss_rpn_cls: 0.009  loss_rpn_loc: 0.020  time: 0.4769  data_time: 0.0083  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:42:33 d2.utils.events]: [0m eta: 0:30:30  iter: 1159  total_loss: 0.656  loss_cls: 0.141  loss_box_reg: 0.257  loss_mask: 0.214  loss_rpn_cls: 0.015  loss_rpn_loc: 0.025  time: 0.4769  data_time: 0.0115  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:42:43 d2.utils.events]: [0m eta: 0:30:21  iter: 1179  total_loss: 0.552  loss_cls: 0.106  loss_box_reg: 0.246  loss_mask: 0.165  loss_rpn_cls: 0.006  loss_rpn_loc: 0.014  time: 0.4769  data_time: 0.0104  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:42:52 d2.utils.events]: [0m eta: 0:30:12  iter: 1199  total_loss: 0.589  loss_cls: 0.134  loss_box_reg: 0.242  loss_mask: 0.174  loss_rpn_cls: 0.008  loss_rpn_loc: 0.015  time: 0.4771  data_time: 0.0110  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:43:02 d2.utils.events]: [0m eta: 0:30:03  iter: 1219  total_loss: 0.601  loss_cls: 0.117  loss_box_reg: 0.278  loss_mask: 0.167  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 0.4771  data_time: 0.0096  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:43:12 d2.utils.events]: [0m eta: 0:29:54  iter: 1239  total_loss: 0.599  loss_cls: 0.127  loss_box_reg: 0.234  loss_mask: 0.176  loss_rpn_cls: 0.012  loss_rpn_loc: 0.014  time: 0.4771  data_time: 0.0085  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:43:21 d2.utils.events]: [0m eta: 0:29:44  iter: 1259  total_loss: 0.564  loss_cls: 0.120  loss_box_reg: 0.237  loss_mask: 0.162  loss_rpn_cls: 0.008  loss_rpn_loc: 0.016  time: 0.4771  data_time: 0.0087  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:43:31 d2.utils.events]: [0m eta: 0:29:35  iter: 1279  total_loss: 0.678  loss_cls: 0.128  loss_box_reg: 0.258  loss_mask: 0.208  loss_rpn_cls: 0.016  loss_rpn_loc: 0.019  time: 0.4772  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:43:40 d2.utils.events]: [0m eta: 0:29:26  iter: 1299  total_loss: 0.481  loss_cls: 0.108  loss_box_reg: 0.192  loss_mask: 0.141  loss_rpn_cls: 0.008  loss_rpn_loc: 0.017  time: 0.4773  data_time: 0.0090  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:43:50 d2.utils.events]: [0m eta: 0:29:17  iter: 1319  total_loss: 0.540  loss_cls: 0.135  loss_box_reg: 0.220  loss_mask: 0.173  loss_rpn_cls: 0.010  loss_rpn_loc: 0.015  time: 0.4773  data_time: 0.0097  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:44:00 d2.utils.events]: [0m eta: 0:29:09  iter: 1339  total_loss: 0.605  loss_cls: 0.134  loss_box_reg: 0.249  loss_mask: 0.165  loss_rpn_cls: 0.009  loss_rpn_loc: 0.016  time: 0.4774  data_time: 0.0108  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:44:09 d2.utils.events]: [0m eta: 0:29:01  iter: 1359  total_loss: 0.628  loss_cls: 0.129  loss_box_reg: 0.241  loss_mask: 0.179  loss_rpn_cls: 0.008  loss_rpn_loc: 0.019  time: 0.4774  data_time: 0.0108  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:44:19 d2.utils.events]: [0m eta: 0:28:52  iter: 1379  total_loss: 0.543  loss_cls: 0.110  loss_box_reg: 0.213  loss_mask: 0.183  loss_rpn_cls: 0.007  loss_rpn_loc: 0.016  time: 0.4775  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:44:29 d2.utils.events]: [0m eta: 0:28:42  iter: 1399  total_loss: 0.549  loss_cls: 0.135  loss_box_reg: 0.222  loss_mask: 0.174  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 0.4775  data_time: 0.0098  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:44:38 d2.utils.events]: [0m eta: 0:28:33  iter: 1419  total_loss: 0.600  loss_cls: 0.126  loss_box_reg: 0.228  loss_mask: 0.184  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 0.4777  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:44:48 d2.utils.events]: [0m eta: 0:28:24  iter: 1439  total_loss: 0.500  loss_cls: 0.118  loss_box_reg: 0.220  loss_mask: 0.156  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  time: 0.4777  data_time: 0.0099  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:44:58 d2.utils.events]: [0m eta: 0:28:14  iter: 1459  total_loss: 0.607  loss_cls: 0.127  loss_box_reg: 0.225  loss_mask: 0.175  loss_rpn_cls: 0.007  loss_rpn_loc: 0.021  time: 0.4777  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:45:07 d2.utils.events]: [0m eta: 0:28:05  iter: 1479  total_loss: 0.530  loss_cls: 0.142  loss_box_reg: 0.199  loss_mask: 0.159  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 0.4778  data_time: 0.0104  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:45:17 d2.utils.events]: [0m eta: 0:27:56  iter: 1499  total_loss: 0.499  loss_cls: 0.109  loss_box_reg: 0.214  loss_mask: 0.171  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 0.4779  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:45:27 d2.utils.events]: [0m eta: 0:27:47  iter: 1519  total_loss: 0.552  loss_cls: 0.111  loss_box_reg: 0.198  loss_mask: 0.154  loss_rpn_cls: 0.004  loss_rpn_loc: 0.015  time: 0.4779  data_time: 0.0103  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:45:36 d2.utils.events]: [0m eta: 0:27:37  iter: 1539  total_loss: 0.480  loss_cls: 0.091  loss_box_reg: 0.208  loss_mask: 0.175  loss_rpn_cls: 0.004  loss_rpn_loc: 0.010  time: 0.4779  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:45:46 d2.utils.events]: [0m eta: 0:27:27  iter: 1559  total_loss: 0.551  loss_cls: 0.125  loss_box_reg: 0.221  loss_mask: 0.160  loss_rpn_cls: 0.010  loss_rpn_loc: 0.021  time: 0.4780  data_time: 0.0097  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:45:56 d2.utils.events]: [0m eta: 0:27:17  iter: 1579  total_loss: 0.516  loss_cls: 0.126  loss_box_reg: 0.179  loss_mask: 0.183  loss_rpn_cls: 0.011  loss_rpn_loc: 0.016  time: 0.4780  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:46:05 d2.utils.events]: [0m eta: 0:27:08  iter: 1599  total_loss: 0.501  loss_cls: 0.124  loss_box_reg: 0.208  loss_mask: 0.138  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 0.4781  data_time: 0.0114  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:46:15 d2.utils.events]: [0m eta: 0:26:59  iter: 1619  total_loss: 0.603  loss_cls: 0.138  loss_box_reg: 0.238  loss_mask: 0.182  loss_rpn_cls: 0.008  loss_rpn_loc: 0.019  time: 0.4782  data_time: 0.0103  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:46:25 d2.utils.events]: [0m eta: 0:26:50  iter: 1639  total_loss: 0.500  loss_cls: 0.105  loss_box_reg: 0.207  loss_mask: 0.171  loss_rpn_cls: 0.007  loss_rpn_loc: 0.020  time: 0.4784  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:46:34 d2.utils.events]: [0m eta: 0:26:40  iter: 1659  total_loss: 0.531  loss_cls: 0.133  loss_box_reg: 0.206  loss_mask: 0.161  loss_rpn_cls: 0.007  loss_rpn_loc: 0.016  time: 0.4783  data_time: 0.0091  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:46:44 d2.utils.events]: [0m eta: 0:26:31  iter: 1679  total_loss: 0.560  loss_cls: 0.116  loss_box_reg: 0.236  loss_mask: 0.172  loss_rpn_cls: 0.008  loss_rpn_loc: 0.016  time: 0.4784  data_time: 0.0091  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:46:54 d2.utils.events]: [0m eta: 0:26:21  iter: 1699  total_loss: 0.487  loss_cls: 0.106  loss_box_reg: 0.183  loss_mask: 0.148  loss_rpn_cls: 0.006  loss_rpn_loc: 0.014  time: 0.4784  data_time: 0.0078  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:47:03 d2.utils.events]: [0m eta: 0:26:12  iter: 1719  total_loss: 0.620  loss_cls: 0.115  loss_box_reg: 0.239  loss_mask: 0.166  loss_rpn_cls: 0.008  loss_rpn_loc: 0.022  time: 0.4785  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:47:13 d2.utils.events]: [0m eta: 0:26:02  iter: 1739  total_loss: 0.536  loss_cls: 0.140  loss_box_reg: 0.213  loss_mask: 0.160  loss_rpn_cls: 0.009  loss_rpn_loc: 0.014  time: 0.4785  data_time: 0.0099  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:47:23 d2.utils.events]: [0m eta: 0:25:52  iter: 1759  total_loss: 0.523  loss_cls: 0.130  loss_box_reg: 0.201  loss_mask: 0.180  loss_rpn_cls: 0.009  loss_rpn_loc: 0.021  time: 0.4785  data_time: 0.0089  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:47:32 d2.utils.events]: [0m eta: 0:25:43  iter: 1779  total_loss: 0.507  loss_cls: 0.107  loss_box_reg: 0.199  loss_mask: 0.156  loss_rpn_cls: 0.008  loss_rpn_loc: 0.014  time: 0.4785  data_time: 0.0082  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:47:42 d2.utils.events]: [0m eta: 0:25:33  iter: 1799  total_loss: 0.567  loss_cls: 0.114  loss_box_reg: 0.232  loss_mask: 0.171  loss_rpn_cls: 0.016  loss_rpn_loc: 0.022  time: 0.4786  data_time: 0.0079  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:47:51 d2.utils.events]: [0m eta: 0:25:24  iter: 1819  total_loss: 0.560  loss_cls: 0.103  loss_box_reg: 0.220  loss_mask: 0.181  loss_rpn_cls: 0.010  loss_rpn_loc: 0.022  time: 0.4786  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:48:01 d2.utils.events]: [0m eta: 0:25:14  iter: 1839  total_loss: 0.486  loss_cls: 0.087  loss_box_reg: 0.176  loss_mask: 0.169  loss_rpn_cls: 0.008  loss_rpn_loc: 0.013  time: 0.4786  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:48:11 d2.utils.events]: [0m eta: 0:25:04  iter: 1859  total_loss: 0.516  loss_cls: 0.115  loss_box_reg: 0.223  loss_mask: 0.148  loss_rpn_cls: 0.009  loss_rpn_loc: 0.015  time: 0.4786  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:48:20 d2.utils.events]: [0m eta: 0:24:55  iter: 1879  total_loss: 0.504  loss_cls: 0.106  loss_box_reg: 0.213  loss_mask: 0.158  loss_rpn_cls: 0.008  loss_rpn_loc: 0.018  time: 0.4786  data_time: 0.0098  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:48:30 d2.utils.events]: [0m eta: 0:24:45  iter: 1899  total_loss: 0.582  loss_cls: 0.122  loss_box_reg: 0.228  loss_mask: 0.179  loss_rpn_cls: 0.015  loss_rpn_loc: 0.017  time: 0.4786  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:48:39 d2.utils.events]: [0m eta: 0:24:36  iter: 1919  total_loss: 0.620  loss_cls: 0.115  loss_box_reg: 0.230  loss_mask: 0.178  loss_rpn_cls: 0.014  loss_rpn_loc: 0.023  time: 0.4786  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:48:49 d2.utils.events]: [0m eta: 0:24:26  iter: 1939  total_loss: 0.485  loss_cls: 0.101  loss_box_reg: 0.210  loss_mask: 0.152  loss_rpn_cls: 0.006  loss_rpn_loc: 0.014  time: 0.4786  data_time: 0.0092  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:48:59 d2.utils.events]: [0m eta: 0:24:17  iter: 1959  total_loss: 0.526  loss_cls: 0.105  loss_box_reg: 0.223  loss_mask: 0.172  loss_rpn_cls: 0.006  loss_rpn_loc: 0.017  time: 0.4787  data_time: 0.0097  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:49:08 d2.utils.events]: [0m eta: 0:24:07  iter: 1979  total_loss: 0.478  loss_cls: 0.096  loss_box_reg: 0.176  loss_mask: 0.158  loss_rpn_cls: 0.007  loss_rpn_loc: 0.014  time: 0.4787  data_time: 0.0109  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:49:18 d2.utils.events]: [0m eta: 0:23:58  iter: 1999  total_loss: 0.489  loss_cls: 0.105  loss_box_reg: 0.209  loss_mask: 0.147  loss_rpn_cls: 0.009  loss_rpn_loc: 0.016  time: 0.4787  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:49:28 d2.utils.events]: [0m eta: 0:23:49  iter: 2019  total_loss: 0.436  loss_cls: 0.100  loss_box_reg: 0.194  loss_mask: 0.149  loss_rpn_cls: 0.007  loss_rpn_loc: 0.014  time: 0.4788  data_time: 0.0110  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:49:37 d2.utils.events]: [0m eta: 0:23:40  iter: 2039  total_loss: 0.521  loss_cls: 0.099  loss_box_reg: 0.181  loss_mask: 0.143  loss_rpn_cls: 0.007  loss_rpn_loc: 0.014  time: 0.4788  data_time: 0.0113  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:49:47 d2.utils.events]: [0m eta: 0:23:30  iter: 2059  total_loss: 0.481  loss_cls: 0.106  loss_box_reg: 0.206  loss_mask: 0.145  loss_rpn_cls: 0.006  loss_rpn_loc: 0.010  time: 0.4788  data_time: 0.0096  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:49:57 d2.utils.events]: [0m eta: 0:23:20  iter: 2079  total_loss: 0.543  loss_cls: 0.144  loss_box_reg: 0.210  loss_mask: 0.170  loss_rpn_cls: 0.009  loss_rpn_loc: 0.026  time: 0.4789  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:50:06 d2.utils.events]: [0m eta: 0:23:11  iter: 2099  total_loss: 0.533  loss_cls: 0.101  loss_box_reg: 0.220  loss_mask: 0.171  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 0.4789  data_time: 0.0106  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:50:16 d2.utils.events]: [0m eta: 0:23:02  iter: 2119  total_loss: 0.464  loss_cls: 0.130  loss_box_reg: 0.187  loss_mask: 0.148  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  time: 0.4790  data_time: 0.0110  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:50:26 d2.utils.events]: [0m eta: 0:22:52  iter: 2139  total_loss: 0.509  loss_cls: 0.106  loss_box_reg: 0.200  loss_mask: 0.174  loss_rpn_cls: 0.005  loss_rpn_loc: 0.014  time: 0.4790  data_time: 0.0095  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:50:35 d2.utils.events]: [0m eta: 0:22:42  iter: 2159  total_loss: 0.539  loss_cls: 0.116  loss_box_reg: 0.222  loss_mask: 0.185  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 0.4789  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:50:45 d2.utils.events]: [0m eta: 0:22:33  iter: 2179  total_loss: 0.423  loss_cls: 0.085  loss_box_reg: 0.180  loss_mask: 0.143  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.4790  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:50:55 d2.utils.events]: [0m eta: 0:22:24  iter: 2199  total_loss: 0.523  loss_cls: 0.103  loss_box_reg: 0.217  loss_mask: 0.162  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 0.4791  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:51:04 d2.utils.events]: [0m eta: 0:22:14  iter: 2219  total_loss: 0.460  loss_cls: 0.104  loss_box_reg: 0.187  loss_mask: 0.145  loss_rpn_cls: 0.011  loss_rpn_loc: 0.012  time: 0.4791  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:51:14 d2.utils.events]: [0m eta: 0:22:05  iter: 2239  total_loss: 0.585  loss_cls: 0.123  loss_box_reg: 0.237  loss_mask: 0.163  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 0.4791  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:51:24 d2.utils.events]: [0m eta: 0:21:55  iter: 2259  total_loss: 0.435  loss_cls: 0.093  loss_box_reg: 0.165  loss_mask: 0.156  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  time: 0.4792  data_time: 0.0095  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:51:33 d2.utils.events]: [0m eta: 0:21:46  iter: 2279  total_loss: 0.561  loss_cls: 0.126  loss_box_reg: 0.237  loss_mask: 0.182  loss_rpn_cls: 0.013  loss_rpn_loc: 0.018  time: 0.4792  data_time: 0.0103  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:51:43 d2.utils.events]: [0m eta: 0:21:36  iter: 2299  total_loss: 0.476  loss_cls: 0.109  loss_box_reg: 0.203  loss_mask: 0.161  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  time: 0.4792  data_time: 0.0091  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:51:53 d2.utils.events]: [0m eta: 0:21:26  iter: 2319  total_loss: 0.452  loss_cls: 0.100  loss_box_reg: 0.192  loss_mask: 0.133  loss_rpn_cls: 0.003  loss_rpn_loc: 0.012  time: 0.4793  data_time: 0.0112  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:52:02 d2.utils.events]: [0m eta: 0:21:17  iter: 2339  total_loss: 0.555  loss_cls: 0.115  loss_box_reg: 0.234  loss_mask: 0.172  loss_rpn_cls: 0.005  loss_rpn_loc: 0.019  time: 0.4793  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:52:12 d2.utils.events]: [0m eta: 0:21:07  iter: 2359  total_loss: 0.477  loss_cls: 0.098  loss_box_reg: 0.189  loss_mask: 0.151  loss_rpn_cls: 0.003  loss_rpn_loc: 0.012  time: 0.4793  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:52:22 d2.utils.events]: [0m eta: 0:20:58  iter: 2379  total_loss: 0.564  loss_cls: 0.115  loss_box_reg: 0.232  loss_mask: 0.176  loss_rpn_cls: 0.013  loss_rpn_loc: 0.021  time: 0.4794  data_time: 0.0112  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:52:31 d2.utils.events]: [0m eta: 0:20:48  iter: 2399  total_loss: 0.479  loss_cls: 0.110  loss_box_reg: 0.211  loss_mask: 0.154  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 0.4794  data_time: 0.0114  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:52:41 d2.utils.events]: [0m eta: 0:20:39  iter: 2419  total_loss: 0.541  loss_cls: 0.115  loss_box_reg: 0.212  loss_mask: 0.178  loss_rpn_cls: 0.008  loss_rpn_loc: 0.019  time: 0.4794  data_time: 0.0114  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:52:51 d2.utils.events]: [0m eta: 0:20:29  iter: 2439  total_loss: 0.440  loss_cls: 0.105  loss_box_reg: 0.182  loss_mask: 0.135  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  time: 0.4794  data_time: 0.0116  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:53:00 d2.utils.events]: [0m eta: 0:20:19  iter: 2459  total_loss: 0.516  loss_cls: 0.104  loss_box_reg: 0.218  loss_mask: 0.174  loss_rpn_cls: 0.004  loss_rpn_loc: 0.015  time: 0.4794  data_time: 0.0110  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:53:10 d2.utils.events]: [0m eta: 0:20:10  iter: 2479  total_loss: 0.464  loss_cls: 0.092  loss_box_reg: 0.202  loss_mask: 0.147  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 0.4795  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:53:20 d2.utils.events]: [0m eta: 0:20:00  iter: 2499  total_loss: 0.466  loss_cls: 0.088  loss_box_reg: 0.197  loss_mask: 0.136  loss_rpn_cls: 0.003  loss_rpn_loc: 0.012  time: 0.4795  data_time: 0.0096  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:53:29 d2.utils.events]: [0m eta: 0:19:50  iter: 2519  total_loss: 0.473  loss_cls: 0.113  loss_box_reg: 0.188  loss_mask: 0.139  loss_rpn_cls: 0.007  loss_rpn_loc: 0.013  time: 0.4795  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:53:39 d2.utils.events]: [0m eta: 0:19:41  iter: 2539  total_loss: 0.518  loss_cls: 0.115  loss_box_reg: 0.235  loss_mask: 0.156  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  time: 0.4795  data_time: 0.0106  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:53:48 d2.utils.events]: [0m eta: 0:19:31  iter: 2559  total_loss: 0.472  loss_cls: 0.109  loss_box_reg: 0.198  loss_mask: 0.148  loss_rpn_cls: 0.002  loss_rpn_loc: 0.018  time: 0.4795  data_time: 0.0086  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:53:58 d2.utils.events]: [0m eta: 0:19:22  iter: 2579  total_loss: 0.596  loss_cls: 0.118  loss_box_reg: 0.262  loss_mask: 0.172  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 0.4795  data_time: 0.0088  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:54:08 d2.utils.events]: [0m eta: 0:19:12  iter: 2599  total_loss: 0.529  loss_cls: 0.125  loss_box_reg: 0.208  loss_mask: 0.157  loss_rpn_cls: 0.009  loss_rpn_loc: 0.018  time: 0.4795  data_time: 0.0108  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:54:17 d2.utils.events]: [0m eta: 0:19:02  iter: 2619  total_loss: 0.473  loss_cls: 0.117  loss_box_reg: 0.191  loss_mask: 0.155  loss_rpn_cls: 0.005  loss_rpn_loc: 0.015  time: 0.4795  data_time: 0.0111  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:54:27 d2.utils.events]: [0m eta: 0:18:53  iter: 2639  total_loss: 0.529  loss_cls: 0.120  loss_box_reg: 0.208  loss_mask: 0.162  loss_rpn_cls: 0.007  loss_rpn_loc: 0.016  time: 0.4795  data_time: 0.0120  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:54:36 d2.utils.events]: [0m eta: 0:18:43  iter: 2659  total_loss: 0.390  loss_cls: 0.103  loss_box_reg: 0.167  loss_mask: 0.130  loss_rpn_cls: 0.002  loss_rpn_loc: 0.009  time: 0.4795  data_time: 0.0080  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:54:46 d2.utils.events]: [0m eta: 0:18:33  iter: 2679  total_loss: 0.493  loss_cls: 0.099  loss_box_reg: 0.205  loss_mask: 0.153  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 0.4795  data_time: 0.0097  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:54:56 d2.utils.events]: [0m eta: 0:18:24  iter: 2699  total_loss: 0.504  loss_cls: 0.098  loss_box_reg: 0.211  loss_mask: 0.149  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 0.4795  data_time: 0.0106  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:55:05 d2.utils.events]: [0m eta: 0:18:14  iter: 2719  total_loss: 0.467  loss_cls: 0.101  loss_box_reg: 0.198  loss_mask: 0.143  loss_rpn_cls: 0.004  loss_rpn_loc: 0.018  time: 0.4795  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:55:15 d2.utils.events]: [0m eta: 0:18:05  iter: 2739  total_loss: 0.510  loss_cls: 0.123  loss_box_reg: 0.192  loss_mask: 0.163  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 0.4795  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:55:25 d2.utils.events]: [0m eta: 0:17:55  iter: 2759  total_loss: 0.463  loss_cls: 0.105  loss_box_reg: 0.167  loss_mask: 0.151  loss_rpn_cls: 0.007  loss_rpn_loc: 0.017  time: 0.4795  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:55:34 d2.utils.events]: [0m eta: 0:17:45  iter: 2779  total_loss: 0.418  loss_cls: 0.096  loss_box_reg: 0.170  loss_mask: 0.138  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.4795  data_time: 0.0104  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:55:44 d2.utils.events]: [0m eta: 0:17:36  iter: 2799  total_loss: 0.485  loss_cls: 0.094  loss_box_reg: 0.199  loss_mask: 0.147  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 0.4795  data_time: 0.0091  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:55:53 d2.utils.events]: [0m eta: 0:17:26  iter: 2819  total_loss: 0.503  loss_cls: 0.097  loss_box_reg: 0.203  loss_mask: 0.142  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  time: 0.4795  data_time: 0.0114  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:56:03 d2.utils.events]: [0m eta: 0:17:16  iter: 2839  total_loss: 0.428  loss_cls: 0.089  loss_box_reg: 0.182  loss_mask: 0.155  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 0.4795  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:56:13 d2.utils.events]: [0m eta: 0:17:07  iter: 2859  total_loss: 0.439  loss_cls: 0.076  loss_box_reg: 0.176  loss_mask: 0.135  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.4795  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:56:22 d2.utils.events]: [0m eta: 0:16:57  iter: 2879  total_loss: 0.522  loss_cls: 0.120  loss_box_reg: 0.196  loss_mask: 0.162  loss_rpn_cls: 0.009  loss_rpn_loc: 0.016  time: 0.4795  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:56:32 d2.utils.events]: [0m eta: 0:16:47  iter: 2899  total_loss: 0.539  loss_cls: 0.108  loss_box_reg: 0.217  loss_mask: 0.183  loss_rpn_cls: 0.012  loss_rpn_loc: 0.024  time: 0.4795  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:56:41 d2.utils.events]: [0m eta: 0:16:38  iter: 2919  total_loss: 0.438  loss_cls: 0.097  loss_box_reg: 0.188  loss_mask: 0.154  loss_rpn_cls: 0.009  loss_rpn_loc: 0.015  time: 0.4795  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:56:51 d2.utils.events]: [0m eta: 0:16:28  iter: 2939  total_loss: 0.427  loss_cls: 0.096  loss_box_reg: 0.183  loss_mask: 0.126  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.4795  data_time: 0.0109  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:57:01 d2.utils.events]: [0m eta: 0:16:19  iter: 2959  total_loss: 0.503  loss_cls: 0.096  loss_box_reg: 0.189  loss_mask: 0.153  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  time: 0.4795  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:57:10 d2.utils.events]: [0m eta: 0:16:09  iter: 2979  total_loss: 0.448  loss_cls: 0.103  loss_box_reg: 0.181  loss_mask: 0.139  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.4795  data_time: 0.0103  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:57:20 d2.utils.events]: [0m eta: 0:15:59  iter: 2999  total_loss: 0.490  loss_cls: 0.111  loss_box_reg: 0.185  loss_mask: 0.147  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 0.4795  data_time: 0.0097  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:57:29 d2.utils.events]: [0m eta: 0:15:49  iter: 3019  total_loss: 0.553  loss_cls: 0.128  loss_box_reg: 0.225  loss_mask: 0.167  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 0.4795  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:57:39 d2.utils.events]: [0m eta: 0:15:40  iter: 3039  total_loss: 0.504  loss_cls: 0.114  loss_box_reg: 0.210  loss_mask: 0.150  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 0.4795  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:57:49 d2.utils.events]: [0m eta: 0:15:30  iter: 3059  total_loss: 0.435  loss_cls: 0.075  loss_box_reg: 0.187  loss_mask: 0.144  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 0.4795  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:57:58 d2.utils.events]: [0m eta: 0:15:20  iter: 3079  total_loss: 0.516  loss_cls: 0.117  loss_box_reg: 0.224  loss_mask: 0.135  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 0.4795  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:58:08 d2.utils.events]: [0m eta: 0:15:11  iter: 3099  total_loss: 0.467  loss_cls: 0.106  loss_box_reg: 0.192  loss_mask: 0.151  loss_rpn_cls: 0.005  loss_rpn_loc: 0.014  time: 0.4795  data_time: 0.0103  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:58:17 d2.utils.events]: [0m eta: 0:15:01  iter: 3119  total_loss: 0.468  loss_cls: 0.112  loss_box_reg: 0.179  loss_mask: 0.146  loss_rpn_cls: 0.006  loss_rpn_loc: 0.013  time: 0.4795  data_time: 0.0095  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:58:27 d2.utils.events]: [0m eta: 0:14:51  iter: 3139  total_loss: 0.445  loss_cls: 0.095  loss_box_reg: 0.180  loss_mask: 0.140  loss_rpn_cls: 0.008  loss_rpn_loc: 0.015  time: 0.4795  data_time: 0.0106  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:58:37 d2.utils.events]: [0m eta: 0:14:41  iter: 3159  total_loss: 0.385  loss_cls: 0.075  loss_box_reg: 0.154  loss_mask: 0.133  loss_rpn_cls: 0.001  loss_rpn_loc: 0.011  time: 0.4795  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:58:46 d2.utils.events]: [0m eta: 0:14:31  iter: 3179  total_loss: 0.516  loss_cls: 0.118  loss_box_reg: 0.219  loss_mask: 0.167  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.4794  data_time: 0.0098  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:58:56 d2.utils.events]: [0m eta: 0:14:21  iter: 3199  total_loss: 0.483  loss_cls: 0.099  loss_box_reg: 0.200  loss_mask: 0.142  loss_rpn_cls: 0.006  loss_rpn_loc: 0.018  time: 0.4795  data_time: 0.0116  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:59:05 d2.utils.events]: [0m eta: 0:14:12  iter: 3219  total_loss: 0.467  loss_cls: 0.107  loss_box_reg: 0.197  loss_mask: 0.142  loss_rpn_cls: 0.005  loss_rpn_loc: 0.014  time: 0.4795  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:59:15 d2.utils.events]: [0m eta: 0:14:02  iter: 3239  total_loss: 0.470  loss_cls: 0.124  loss_box_reg: 0.193  loss_mask: 0.150  loss_rpn_cls: 0.003  loss_rpn_loc: 0.018  time: 0.4794  data_time: 0.0109  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:59:24 d2.utils.events]: [0m eta: 0:13:52  iter: 3259  total_loss: 0.518  loss_cls: 0.101  loss_box_reg: 0.224  loss_mask: 0.156  loss_rpn_cls: 0.006  loss_rpn_loc: 0.020  time: 0.4794  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:59:34 d2.utils.events]: [0m eta: 0:13:42  iter: 3279  total_loss: 0.468  loss_cls: 0.095  loss_box_reg: 0.207  loss_mask: 0.143  loss_rpn_cls: 0.003  loss_rpn_loc: 0.012  time: 0.4794  data_time: 0.0109  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:59:43 d2.utils.events]: [0m eta: 0:13:33  iter: 3299  total_loss: 0.464  loss_cls: 0.107  loss_box_reg: 0.191  loss_mask: 0.156  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 0.4794  data_time: 0.0098  lr: 0.000250  max_mem: 4061M
[32m[03/28 11:59:53 d2.utils.events]: [0m eta: 0:13:23  iter: 3319  total_loss: 0.524  loss_cls: 0.111  loss_box_reg: 0.211  loss_mask: 0.154  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.4794  data_time: 0.0084  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:00:03 d2.utils.events]: [0m eta: 0:13:13  iter: 3339  total_loss: 0.514  loss_cls: 0.102  loss_box_reg: 0.219  loss_mask: 0.163  loss_rpn_cls: 0.005  loss_rpn_loc: 0.021  time: 0.4794  data_time: 0.0117  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:00:12 d2.utils.events]: [0m eta: 0:13:04  iter: 3359  total_loss: 0.486  loss_cls: 0.101  loss_box_reg: 0.197  loss_mask: 0.142  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 0.4794  data_time: 0.0103  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:00:22 d2.utils.events]: [0m eta: 0:12:54  iter: 3379  total_loss: 0.513  loss_cls: 0.116  loss_box_reg: 0.213  loss_mask: 0.160  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 0.4794  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:00:31 d2.utils.events]: [0m eta: 0:12:45  iter: 3399  total_loss: 0.471  loss_cls: 0.101  loss_box_reg: 0.200  loss_mask: 0.126  loss_rpn_cls: 0.001  loss_rpn_loc: 0.015  time: 0.4794  data_time: 0.0096  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:00:41 d2.utils.events]: [0m eta: 0:12:35  iter: 3419  total_loss: 0.484  loss_cls: 0.089  loss_box_reg: 0.201  loss_mask: 0.168  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.4794  data_time: 0.0112  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:00:51 d2.utils.events]: [0m eta: 0:12:25  iter: 3439  total_loss: 0.462  loss_cls: 0.104  loss_box_reg: 0.173  loss_mask: 0.147  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 0.4794  data_time: 0.0084  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:01:00 d2.utils.events]: [0m eta: 0:12:15  iter: 3459  total_loss: 0.488  loss_cls: 0.090  loss_box_reg: 0.197  loss_mask: 0.152  loss_rpn_cls: 0.008  loss_rpn_loc: 0.019  time: 0.4794  data_time: 0.0086  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:01:10 d2.utils.events]: [0m eta: 0:12:06  iter: 3479  total_loss: 0.498  loss_cls: 0.106  loss_box_reg: 0.210  loss_mask: 0.160  loss_rpn_cls: 0.004  loss_rpn_loc: 0.015  time: 0.4793  data_time: 0.0084  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:01:19 d2.utils.events]: [0m eta: 0:11:56  iter: 3499  total_loss: 0.500  loss_cls: 0.094  loss_box_reg: 0.201  loss_mask: 0.165  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  time: 0.4793  data_time: 0.0086  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:01:29 d2.utils.events]: [0m eta: 0:11:47  iter: 3519  total_loss: 0.406  loss_cls: 0.092  loss_box_reg: 0.166  loss_mask: 0.154  loss_rpn_cls: 0.003  loss_rpn_loc: 0.012  time: 0.4793  data_time: 0.0078  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:01:38 d2.utils.events]: [0m eta: 0:11:37  iter: 3539  total_loss: 0.435  loss_cls: 0.085  loss_box_reg: 0.189  loss_mask: 0.141  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.4793  data_time: 0.0079  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:01:48 d2.utils.events]: [0m eta: 0:11:28  iter: 3559  total_loss: 0.507  loss_cls: 0.110  loss_box_reg: 0.198  loss_mask: 0.146  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 0.4793  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:01:57 d2.utils.events]: [0m eta: 0:11:18  iter: 3579  total_loss: 0.542  loss_cls: 0.118  loss_box_reg: 0.234  loss_mask: 0.165  loss_rpn_cls: 0.004  loss_rpn_loc: 0.021  time: 0.4792  data_time: 0.0078  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:02:07 d2.utils.events]: [0m eta: 0:11:08  iter: 3599  total_loss: 0.412  loss_cls: 0.087  loss_box_reg: 0.193  loss_mask: 0.138  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 0.4793  data_time: 0.0106  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:02:17 d2.utils.events]: [0m eta: 0:10:59  iter: 3619  total_loss: 0.490  loss_cls: 0.097  loss_box_reg: 0.230  loss_mask: 0.147  loss_rpn_cls: 0.002  loss_rpn_loc: 0.015  time: 0.4793  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:02:26 d2.utils.events]: [0m eta: 0:10:49  iter: 3639  total_loss: 0.559  loss_cls: 0.123  loss_box_reg: 0.222  loss_mask: 0.164  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  time: 0.4792  data_time: 0.0092  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:02:36 d2.utils.events]: [0m eta: 0:10:40  iter: 3659  total_loss: 0.489  loss_cls: 0.123  loss_box_reg: 0.223  loss_mask: 0.133  loss_rpn_cls: 0.006  loss_rpn_loc: 0.019  time: 0.4793  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:02:45 d2.utils.events]: [0m eta: 0:10:30  iter: 3679  total_loss: 0.381  loss_cls: 0.080  loss_box_reg: 0.166  loss_mask: 0.150  loss_rpn_cls: 0.003  loss_rpn_loc: 0.011  time: 0.4793  data_time: 0.0103  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:02:55 d2.utils.events]: [0m eta: 0:10:21  iter: 3699  total_loss: 0.431  loss_cls: 0.086  loss_box_reg: 0.184  loss_mask: 0.141  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 0.4792  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:03:05 d2.utils.events]: [0m eta: 0:10:11  iter: 3719  total_loss: 0.477  loss_cls: 0.091  loss_box_reg: 0.192  loss_mask: 0.151  loss_rpn_cls: 0.003  loss_rpn_loc: 0.017  time: 0.4793  data_time: 0.0115  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:03:14 d2.utils.events]: [0m eta: 0:10:02  iter: 3739  total_loss: 0.456  loss_cls: 0.096  loss_box_reg: 0.187  loss_mask: 0.143  loss_rpn_cls: 0.004  loss_rpn_loc: 0.015  time: 0.4793  data_time: 0.0116  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:03:24 d2.utils.events]: [0m eta: 0:09:52  iter: 3759  total_loss: 0.437  loss_cls: 0.066  loss_box_reg: 0.202  loss_mask: 0.151  loss_rpn_cls: 0.002  loss_rpn_loc: 0.008  time: 0.4793  data_time: 0.0094  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:03:34 d2.utils.events]: [0m eta: 0:09:42  iter: 3779  total_loss: 0.445  loss_cls: 0.107  loss_box_reg: 0.194  loss_mask: 0.136  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.4793  data_time: 0.0103  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:03:43 d2.utils.events]: [0m eta: 0:09:33  iter: 3799  total_loss: 0.451  loss_cls: 0.084  loss_box_reg: 0.163  loss_mask: 0.151  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 0.4793  data_time: 0.0113  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:03:53 d2.utils.events]: [0m eta: 0:09:23  iter: 3819  total_loss: 0.483  loss_cls: 0.103  loss_box_reg: 0.185  loss_mask: 0.133  loss_rpn_cls: 0.003  loss_rpn_loc: 0.015  time: 0.4794  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:04:03 d2.utils.events]: [0m eta: 0:09:14  iter: 3839  total_loss: 0.467  loss_cls: 0.079  loss_box_reg: 0.169  loss_mask: 0.155  loss_rpn_cls: 0.009  loss_rpn_loc: 0.013  time: 0.4794  data_time: 0.0089  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:04:12 d2.utils.events]: [0m eta: 0:09:04  iter: 3859  total_loss: 0.441  loss_cls: 0.102  loss_box_reg: 0.179  loss_mask: 0.133  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.4794  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:04:22 d2.utils.events]: [0m eta: 0:08:55  iter: 3879  total_loss: 0.458  loss_cls: 0.094  loss_box_reg: 0.190  loss_mask: 0.143  loss_rpn_cls: 0.006  loss_rpn_loc: 0.016  time: 0.4794  data_time: 0.0110  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:04:32 d2.utils.events]: [0m eta: 0:08:45  iter: 3899  total_loss: 0.514  loss_cls: 0.115  loss_box_reg: 0.208  loss_mask: 0.154  loss_rpn_cls: 0.005  loss_rpn_loc: 0.016  time: 0.4794  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:04:41 d2.utils.events]: [0m eta: 0:08:36  iter: 3919  total_loss: 0.443  loss_cls: 0.100  loss_box_reg: 0.186  loss_mask: 0.148  loss_rpn_cls: 0.007  loss_rpn_loc: 0.015  time: 0.4794  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:04:51 d2.utils.events]: [0m eta: 0:08:26  iter: 3939  total_loss: 0.471  loss_cls: 0.087  loss_box_reg: 0.178  loss_mask: 0.162  loss_rpn_cls: 0.003  loss_rpn_loc: 0.019  time: 0.4794  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:05:01 d2.utils.events]: [0m eta: 0:08:17  iter: 3959  total_loss: 0.478  loss_cls: 0.092  loss_box_reg: 0.204  loss_mask: 0.146  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.4795  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:05:10 d2.utils.events]: [0m eta: 0:08:07  iter: 3979  total_loss: 0.523  loss_cls: 0.112  loss_box_reg: 0.205  loss_mask: 0.175  loss_rpn_cls: 0.006  loss_rpn_loc: 0.017  time: 0.4795  data_time: 0.0106  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:05:20 d2.utils.events]: [0m eta: 0:07:58  iter: 3999  total_loss: 0.470  loss_cls: 0.089  loss_box_reg: 0.194  loss_mask: 0.160  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.4795  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:05:30 d2.utils.events]: [0m eta: 0:07:48  iter: 4019  total_loss: 0.457  loss_cls: 0.094  loss_box_reg: 0.172  loss_mask: 0.124  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.4795  data_time: 0.0097  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:05:39 d2.utils.events]: [0m eta: 0:07:38  iter: 4039  total_loss: 0.465  loss_cls: 0.104  loss_box_reg: 0.176  loss_mask: 0.159  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.4795  data_time: 0.0096  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:05:49 d2.utils.events]: [0m eta: 0:07:29  iter: 4059  total_loss: 0.403  loss_cls: 0.088  loss_box_reg: 0.180  loss_mask: 0.122  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  time: 0.4795  data_time: 0.0108  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:05:59 d2.utils.events]: [0m eta: 0:07:20  iter: 4079  total_loss: 0.493  loss_cls: 0.112  loss_box_reg: 0.213  loss_mask: 0.162  loss_rpn_cls: 0.007  loss_rpn_loc: 0.023  time: 0.4796  data_time: 0.0129  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:06:08 d2.utils.events]: [0m eta: 0:07:10  iter: 4099  total_loss: 0.465  loss_cls: 0.090  loss_box_reg: 0.207  loss_mask: 0.149  loss_rpn_cls: 0.005  loss_rpn_loc: 0.013  time: 0.4796  data_time: 0.0102  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:06:18 d2.utils.events]: [0m eta: 0:07:00  iter: 4119  total_loss: 0.474  loss_cls: 0.082  loss_box_reg: 0.189  loss_mask: 0.144  loss_rpn_cls: 0.006  loss_rpn_loc: 0.015  time: 0.4796  data_time: 0.0101  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:06:28 d2.utils.events]: [0m eta: 0:06:51  iter: 4139  total_loss: 0.425  loss_cls: 0.089  loss_box_reg: 0.175  loss_mask: 0.137  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 0.4796  data_time: 0.0113  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:06:37 d2.utils.events]: [0m eta: 0:06:42  iter: 4159  total_loss: 0.428  loss_cls: 0.085  loss_box_reg: 0.184  loss_mask: 0.141  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  time: 0.4796  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:06:47 d2.utils.events]: [0m eta: 0:06:32  iter: 4179  total_loss: 0.449  loss_cls: 0.093  loss_box_reg: 0.189  loss_mask: 0.136  loss_rpn_cls: 0.007  loss_rpn_loc: 0.014  time: 0.4796  data_time: 0.0096  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:06:56 d2.utils.events]: [0m eta: 0:06:22  iter: 4199  total_loss: 0.442  loss_cls: 0.104  loss_box_reg: 0.184  loss_mask: 0.127  loss_rpn_cls: 0.003  loss_rpn_loc: 0.012  time: 0.4796  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:07:06 d2.utils.events]: [0m eta: 0:06:13  iter: 4219  total_loss: 0.520  loss_cls: 0.110  loss_box_reg: 0.219  loss_mask: 0.169  loss_rpn_cls: 0.003  loss_rpn_loc: 0.016  time: 0.4796  data_time: 0.0111  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:07:16 d2.utils.events]: [0m eta: 0:06:03  iter: 4239  total_loss: 0.387  loss_cls: 0.083  loss_box_reg: 0.148  loss_mask: 0.115  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.4796  data_time: 0.0109  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:07:25 d2.utils.events]: [0m eta: 0:05:54  iter: 4259  total_loss: 0.431  loss_cls: 0.084  loss_box_reg: 0.194  loss_mask: 0.138  loss_rpn_cls: 0.002  loss_rpn_loc: 0.011  time: 0.4796  data_time: 0.0113  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:07:35 d2.utils.events]: [0m eta: 0:05:44  iter: 4279  total_loss: 0.451  loss_cls: 0.086  loss_box_reg: 0.187  loss_mask: 0.145  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.4797  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:07:45 d2.utils.events]: [0m eta: 0:05:35  iter: 4299  total_loss: 0.379  loss_cls: 0.068  loss_box_reg: 0.160  loss_mask: 0.156  loss_rpn_cls: 0.004  loss_rpn_loc: 0.013  time: 0.4797  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:07:54 d2.utils.events]: [0m eta: 0:05:25  iter: 4319  total_loss: 0.440  loss_cls: 0.090  loss_box_reg: 0.171  loss_mask: 0.141  loss_rpn_cls: 0.005  loss_rpn_loc: 0.014  time: 0.4797  data_time: 0.0111  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:08:04 d2.utils.events]: [0m eta: 0:05:16  iter: 4339  total_loss: 0.499  loss_cls: 0.096  loss_box_reg: 0.203  loss_mask: 0.151  loss_rpn_cls: 0.006  loss_rpn_loc: 0.017  time: 0.4797  data_time: 0.0111  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:08:14 d2.utils.events]: [0m eta: 0:05:06  iter: 4359  total_loss: 0.398  loss_cls: 0.088  loss_box_reg: 0.174  loss_mask: 0.135  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.4797  data_time: 0.0104  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:08:23 d2.utils.events]: [0m eta: 0:04:56  iter: 4379  total_loss: 0.474  loss_cls: 0.081  loss_box_reg: 0.205  loss_mask: 0.157  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.4797  data_time: 0.0106  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:08:33 d2.utils.events]: [0m eta: 0:04:47  iter: 4399  total_loss: 0.424  loss_cls: 0.094  loss_box_reg: 0.178  loss_mask: 0.134  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.4797  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:08:43 d2.utils.events]: [0m eta: 0:04:37  iter: 4419  total_loss: 0.486  loss_cls: 0.093  loss_box_reg: 0.186  loss_mask: 0.156  loss_rpn_cls: 0.005  loss_rpn_loc: 0.014  time: 0.4797  data_time: 0.0108  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:08:52 d2.utils.events]: [0m eta: 0:04:28  iter: 4439  total_loss: 0.466  loss_cls: 0.092  loss_box_reg: 0.193  loss_mask: 0.143  loss_rpn_cls: 0.005  loss_rpn_loc: 0.017  time: 0.4797  data_time: 0.0108  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:09:02 d2.utils.events]: [0m eta: 0:04:18  iter: 4459  total_loss: 0.522  loss_cls: 0.132  loss_box_reg: 0.217  loss_mask: 0.145  loss_rpn_cls: 0.005  loss_rpn_loc: 0.018  time: 0.4797  data_time: 0.0114  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:09:12 d2.utils.events]: [0m eta: 0:04:09  iter: 4479  total_loss: 0.506  loss_cls: 0.101  loss_box_reg: 0.199  loss_mask: 0.160  loss_rpn_cls: 0.004  loss_rpn_loc: 0.015  time: 0.4798  data_time: 0.0084  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:09:21 d2.utils.events]: [0m eta: 0:03:59  iter: 4499  total_loss: 0.518  loss_cls: 0.112  loss_box_reg: 0.189  loss_mask: 0.169  loss_rpn_cls: 0.007  loss_rpn_loc: 0.022  time: 0.4798  data_time: 0.0104  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:09:31 d2.utils.events]: [0m eta: 0:03:50  iter: 4519  total_loss: 0.409  loss_cls: 0.096  loss_box_reg: 0.179  loss_mask: 0.128  loss_rpn_cls: 0.003  loss_rpn_loc: 0.013  time: 0.4798  data_time: 0.0099  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:09:41 d2.utils.events]: [0m eta: 0:03:40  iter: 4539  total_loss: 0.477  loss_cls: 0.094  loss_box_reg: 0.200  loss_mask: 0.155  loss_rpn_cls: 0.002  loss_rpn_loc: 0.016  time: 0.4798  data_time: 0.0115  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:09:50 d2.utils.events]: [0m eta: 0:03:31  iter: 4559  total_loss: 0.465  loss_cls: 0.100  loss_box_reg: 0.176  loss_mask: 0.150  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 0.4798  data_time: 0.0089  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:10:00 d2.utils.events]: [0m eta: 0:03:21  iter: 4579  total_loss: 0.402  loss_cls: 0.071  loss_box_reg: 0.159  loss_mask: 0.130  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.4799  data_time: 0.0109  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:10:10 d2.utils.events]: [0m eta: 0:03:12  iter: 4599  total_loss: 0.439  loss_cls: 0.099  loss_box_reg: 0.172  loss_mask: 0.132  loss_rpn_cls: 0.004  loss_rpn_loc: 0.020  time: 0.4799  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:10:19 d2.utils.events]: [0m eta: 0:03:02  iter: 4619  total_loss: 0.447  loss_cls: 0.100  loss_box_reg: 0.159  loss_mask: 0.125  loss_rpn_cls: 0.005  loss_rpn_loc: 0.012  time: 0.4799  data_time: 0.0092  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:10:29 d2.utils.events]: [0m eta: 0:02:52  iter: 4639  total_loss: 0.462  loss_cls: 0.085  loss_box_reg: 0.200  loss_mask: 0.147  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 0.4799  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:10:39 d2.utils.events]: [0m eta: 0:02:43  iter: 4659  total_loss: 0.467  loss_cls: 0.096  loss_box_reg: 0.202  loss_mask: 0.146  loss_rpn_cls: 0.002  loss_rpn_loc: 0.017  time: 0.4799  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:10:48 d2.utils.events]: [0m eta: 0:02:33  iter: 4679  total_loss: 0.410  loss_cls: 0.083  loss_box_reg: 0.182  loss_mask: 0.134  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.4799  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:10:58 d2.utils.events]: [0m eta: 0:02:24  iter: 4699  total_loss: 0.416  loss_cls: 0.062  loss_box_reg: 0.163  loss_mask: 0.160  loss_rpn_cls: 0.005  loss_rpn_loc: 0.010  time: 0.4799  data_time: 0.0098  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:11:08 d2.utils.events]: [0m eta: 0:02:14  iter: 4719  total_loss: 0.414  loss_cls: 0.089  loss_box_reg: 0.188  loss_mask: 0.130  loss_rpn_cls: 0.004  loss_rpn_loc: 0.013  time: 0.4800  data_time: 0.0107  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:11:18 d2.utils.events]: [0m eta: 0:02:05  iter: 4739  total_loss: 0.419  loss_cls: 0.087  loss_box_reg: 0.169  loss_mask: 0.123  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.4800  data_time: 0.0109  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:11:27 d2.utils.events]: [0m eta: 0:01:55  iter: 4759  total_loss: 0.389  loss_cls: 0.070  loss_box_reg: 0.161  loss_mask: 0.137  loss_rpn_cls: 0.002  loss_rpn_loc: 0.010  time: 0.4800  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:11:37 d2.utils.events]: [0m eta: 0:01:45  iter: 4779  total_loss: 0.481  loss_cls: 0.097  loss_box_reg: 0.192  loss_mask: 0.141  loss_rpn_cls: 0.003  loss_rpn_loc: 0.020  time: 0.4800  data_time: 0.0105  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:11:47 d2.utils.events]: [0m eta: 0:01:36  iter: 4799  total_loss: 0.436  loss_cls: 0.095  loss_box_reg: 0.182  loss_mask: 0.137  loss_rpn_cls: 0.002  loss_rpn_loc: 0.013  time: 0.4800  data_time: 0.0108  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:11:56 d2.utils.events]: [0m eta: 0:01:26  iter: 4819  total_loss: 0.508  loss_cls: 0.095  loss_box_reg: 0.209  loss_mask: 0.153  loss_rpn_cls: 0.003  loss_rpn_loc: 0.024  time: 0.4800  data_time: 0.0103  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:12:06 d2.utils.events]: [0m eta: 0:01:17  iter: 4839  total_loss: 0.414  loss_cls: 0.081  loss_box_reg: 0.186  loss_mask: 0.134  loss_rpn_cls: 0.002  loss_rpn_loc: 0.012  time: 0.4800  data_time: 0.0100  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:12:16 d2.utils.events]: [0m eta: 0:01:07  iter: 4859  total_loss: 0.485  loss_cls: 0.105  loss_box_reg: 0.201  loss_mask: 0.153  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 0.4801  data_time: 0.0108  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:12:25 d2.utils.events]: [0m eta: 0:00:58  iter: 4879  total_loss: 0.445  loss_cls: 0.084  loss_box_reg: 0.190  loss_mask: 0.128  loss_rpn_cls: 0.002  loss_rpn_loc: 0.014  time: 0.4801  data_time: 0.0115  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:12:35 d2.utils.events]: [0m eta: 0:00:48  iter: 4899  total_loss: 0.471  loss_cls: 0.100  loss_box_reg: 0.200  loss_mask: 0.137  loss_rpn_cls: 0.003  loss_rpn_loc: 0.014  time: 0.4801  data_time: 0.0093  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:12:45 d2.utils.events]: [0m eta: 0:00:38  iter: 4919  total_loss: 0.472  loss_cls: 0.086  loss_box_reg: 0.197  loss_mask: 0.141  loss_rpn_cls: 0.004  loss_rpn_loc: 0.017  time: 0.4801  data_time: 0.0111  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:12:54 d2.utils.events]: [0m eta: 0:00:29  iter: 4939  total_loss: 0.470  loss_cls: 0.095  loss_box_reg: 0.196  loss_mask: 0.139  loss_rpn_cls: 0.004  loss_rpn_loc: 0.014  time: 0.4801  data_time: 0.0110  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:13:04 d2.utils.events]: [0m eta: 0:00:19  iter: 4959  total_loss: 0.446  loss_cls: 0.098  loss_box_reg: 0.165  loss_mask: 0.153  loss_rpn_cls: 0.003  loss_rpn_loc: 0.010  time: 0.4801  data_time: 0.0094  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:13:14 d2.utils.events]: [0m eta: 0:00:10  iter: 4979  total_loss: 0.549  loss_cls: 0.117  loss_box_reg: 0.238  loss_mask: 0.154  loss_rpn_cls: 0.004  loss_rpn_loc: 0.022  time: 0.4801  data_time: 0.0112  lr: 0.000250  max_mem: 4061M
Loading sequence 0002
Loading sequence 0006
Loading sequence 0007
Loading sequence 0008
Loading sequence 0010
Loading sequence 0013
Loading sequence 0014
Loading sequence 0016
Loading sequence 0018
0002
0006
0007
0008
0010
0013
0014
0016
0018
Loaded 2920 images!
[32m[03/28 12:14:31 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    None    | 0            |    Car     | 8029         | Pedestrian | 3347         |
|            |              |            |              |            |              |
|   total    | 11376        |            |              |            |              |[0m
[32m[03/28 12:14:31 d2.data.common]: [0mSerializing 2920 elements to byte tensors and concatenating them all ...
[32m[03/28 12:14:31 d2.data.common]: [0mSerialized dataset takes 7.44 MiB
[5m[31mWARNING[0m [32m[03/28 12:14:31 d2.engine.defaults]: [0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
[32m[03/28 12:14:31 d2.utils.events]: [0m eta: 0:00:00  iter: 4999  total_loss: 0.493  loss_cls: 0.106  loss_box_reg: 0.187  loss_mask: 0.157  loss_rpn_cls: 0.004  loss_rpn_loc: 0.019  time: 0.4801  data_time: 0.0095  lr: 0.000250  max_mem: 4061M
[32m[03/28 12:14:31 d2.engine.hooks]: [0mOverall training speed: 4997 iterations in 0:39:59 (0.4803 s / it)
[32m[03/28 12:14:31 d2.engine.hooks]: [0mTotal training time: 0:41:10 (0:01:11 on hooks)
[32m[03/28 12:14:37 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=4, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
Loading sequence 0002
Loading sequence 0005
Loading sequence 0009
Loading sequence 0011
0002
0005
0009
0011
Loaded 2862 images!
[32m[03/28 12:21:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2862 images left.
[32m[03/28 12:21:13 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    None    | 0            |    Car     | 0            | Pedestrian | 26892        |
|            |              |            |              |            |              |
|   total    | 26892        |            |              |            |              |[0m
[32m[03/28 12:21:13 d2.data.common]: [0mSerializing 2862 elements to byte tensors and concatenating them all ...
[32m[03/28 12:21:16 d2.data.common]: [0mSerialized dataset takes 57.16 MiB
[32m[03/28 12:21:16 d2.data.detection_utils]: [0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(800, 832, 864, 896, 928, 960, 992, 1024), max_size=2048, sample_style='choice'), RandomFlip()]
[32m[03/28 12:21:16 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/28 12:21:17 d2.engine.train_loop]: [0mStarting training from iteration 5000
[32m[03/28 12:21:17 d2.engine.hooks]: [0mTotal training time: 0:00:00 (0:00:00 on hooks)
Loading sequence 0002
Loading sequence 0006
