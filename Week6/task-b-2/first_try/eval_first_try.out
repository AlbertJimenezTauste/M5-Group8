/home/grupo08/datasets/KITTI_MOTS/instances_txt/
['0004', '0005', '0007', '0008', '0009', '0011', '0015']
Loading sequence 0004
Loading sequence 0005
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0011
Loading sequence 0015
0004
0005
0007
0008
0009
0011
0015
Loaded 3266 images!
trained_model_sim_1
[5m[31mWARNING[0m [32m[04/08 11:29:00 d2.evaluation.coco_evaluation]: [0mjson_file was not found in MetaDataCatalog for 'KITTI_MOTS_test'. Trying to convert it to COCO format ...
[32m[04/08 11:29:00 d2.data.datasets.coco]: [0mConverting annotations of dataset 'KITTI_MOTS_test' to COCO format ...)
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
['0004', '0005', '0007', '0008', '0009', '0011', '0015']
Loading sequence 0004
Loading sequence 0005
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0011
Loading sequence 0015
0004
0005
0007
0008
0009
0011
0015
Loaded 3266 images!
[32m[04/08 11:30:36 d2.data.datasets.coco]: [0mConverting dataset dicts into COCO format
[32m[04/08 11:30:42 d2.data.datasets.coco]: [0mConversion finished, num images: 3266, num annotations: 13435
[32m[04/08 11:30:42 d2.data.datasets.coco]: [0mCaching COCO format annotations at '../trained_model_sim_1/KITTI_MOTS_test_coco_format.json' ...
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
['0004', '0005', '0007', '0008', '0009', '0011', '0015']
Loading sequence 0004
Loading sequence 0005
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0011
Loading sequence 0015
0004
0005
0007
0008
0009
0011
0015
Loaded 3266 images!
[32m[04/08 11:31:57 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    None    | 0            |    Car     | 12385        | Pedestrian | 1050         |
|            |              |            |              |            |              |
|   total    | 13435        |            |              |            |              |[0m
[32m[04/08 11:31:57 d2.data.common]: [0mSerializing 3266 elements to byte tensors and concatenating them all ...
[32m[04/08 11:31:58 d2.data.common]: [0mSerialized dataset takes 8.46 MiB
[32m[04/08 11:31:58 d2.evaluation.evaluator]: [0mStart inference on 3266 images
[32m[04/08 11:32:07 d2.evaluation.evaluator]: [0mInference done 1/3266. 8.7978 s / img. ETA=8:12:58
[32m[04/08 11:32:12 d2.evaluation.evaluator]: [0mInference done 24/3266. 0.1548 s / img. ETA=0:13:25
[32m[04/08 11:32:17 d2.evaluation.evaluator]: [0mInference done 50/3266. 0.1485 s / img. ETA=0:11:37
[32m[04/08 11:32:22 d2.evaluation.evaluator]: [0mInference done 123/3266. 0.0967 s / img. ETA=0:06:34
[32m[04/08 11:32:27 d2.evaluation.evaluator]: [0mInference done 195/3266. 0.0848 s / img. ETA=0:05:20
[32m[04/08 11:32:32 d2.evaluation.evaluator]: [0mInference done 267/3266. 0.0796 s / img. ETA=0:04:44
[32m[04/08 11:32:37 d2.evaluation.evaluator]: [0mInference done 334/3266. 0.0777 s / img. ETA=0:04:26
[32m[04/08 11:32:42 d2.evaluation.evaluator]: [0mInference done 405/3266. 0.0756 s / img. ETA=0:04:09
[32m[04/08 11:32:47 d2.evaluation.evaluator]: [0mInference done 478/3266. 0.0739 s / img. ETA=0:03:55
[32m[04/08 11:32:52 d2.evaluation.evaluator]: [0mInference done 541/3266. 0.0741 s / img. ETA=0:03:48
[32m[04/08 11:32:57 d2.evaluation.evaluator]: [0mInference done 613/3266. 0.0731 s / img. ETA=0:03:38
[32m[04/08 11:33:02 d2.evaluation.evaluator]: [0mInference done 685/3266. 0.0723 s / img. ETA=0:03:29
[32m[04/08 11:33:07 d2.evaluation.evaluator]: [0mInference done 759/3266. 0.0715 s / img. ETA=0:03:19
[32m[04/08 11:33:12 d2.evaluation.evaluator]: [0mInference done 832/3266. 0.0709 s / img. ETA=0:03:11
[32m[04/08 11:33:17 d2.evaluation.evaluator]: [0mInference done 891/3266. 0.0715 s / img. ETA=0:03:08
[32m[04/08 11:33:22 d2.evaluation.evaluator]: [0mInference done 965/3266. 0.0709 s / img. ETA=0:03:00
[32m[04/08 11:33:27 d2.evaluation.evaluator]: [0mInference done 1037/3266. 0.0705 s / img. ETA=0:02:53
[32m[04/08 11:33:32 d2.evaluation.evaluator]: [0mInference done 1110/3266. 0.0701 s / img. ETA=0:02:46
[32m[04/08 11:33:37 d2.evaluation.evaluator]: [0mInference done 1182/3266. 0.0699 s / img. ETA=0:02:39
[32m[04/08 11:33:42 d2.evaluation.evaluator]: [0mInference done 1254/3266. 0.0696 s / img. ETA=0:02:33
[32m[04/08 11:33:47 d2.evaluation.evaluator]: [0mInference done 1326/3266. 0.0694 s / img. ETA=0:02:27
[32m[04/08 11:33:52 d2.evaluation.evaluator]: [0mInference done 1400/3266. 0.0691 s / img. ETA=0:02:21
[32m[04/08 11:33:58 d2.evaluation.evaluator]: [0mInference done 1473/3266. 0.0689 s / img. ETA=0:02:14
[32m[04/08 11:34:03 d2.evaluation.evaluator]: [0mInference done 1546/3266. 0.0688 s / img. ETA=0:02:08
[32m[04/08 11:34:08 d2.evaluation.evaluator]: [0mInference done 1619/3266. 0.0686 s / img. ETA=0:02:03
[32m[04/08 11:34:13 d2.evaluation.evaluator]: [0mInference done 1692/3266. 0.0684 s / img. ETA=0:01:57
[32m[04/08 11:34:18 d2.evaluation.evaluator]: [0mInference done 1765/3266. 0.0683 s / img. ETA=0:01:51
[32m[04/08 11:34:23 d2.evaluation.evaluator]: [0mInference done 1839/3266. 0.0681 s / img. ETA=0:01:45
[32m[04/08 11:34:28 d2.evaluation.evaluator]: [0mInference done 1911/3266. 0.0680 s / img. ETA=0:01:40
[32m[04/08 11:34:33 d2.evaluation.evaluator]: [0mInference done 1985/3266. 0.0679 s / img. ETA=0:01:34
[32m[04/08 11:34:38 d2.evaluation.evaluator]: [0mInference done 2058/3266. 0.0678 s / img. ETA=0:01:28
[32m[04/08 11:34:43 d2.evaluation.evaluator]: [0mInference done 2130/3266. 0.0677 s / img. ETA=0:01:23
[32m[04/08 11:34:48 d2.evaluation.evaluator]: [0mInference done 2204/3266. 0.0676 s / img. ETA=0:01:17
[32m[04/08 11:34:53 d2.evaluation.evaluator]: [0mInference done 2275/3266. 0.0676 s / img. ETA=0:01:12
[32m[04/08 11:34:58 d2.evaluation.evaluator]: [0mInference done 2346/3266. 0.0675 s / img. ETA=0:01:07
[32m[04/08 11:35:03 d2.evaluation.evaluator]: [0mInference done 2418/3266. 0.0675 s / img. ETA=0:01:01
[32m[04/08 11:35:08 d2.evaluation.evaluator]: [0mInference done 2490/3266. 0.0674 s / img. ETA=0:00:56
[32m[04/08 11:35:13 d2.evaluation.evaluator]: [0mInference done 2559/3266. 0.0674 s / img. ETA=0:00:51
[32m[04/08 11:35:18 d2.evaluation.evaluator]: [0mInference done 2626/3266. 0.0674 s / img. ETA=0:00:46
[32m[04/08 11:35:23 d2.evaluation.evaluator]: [0mInference done 2692/3266. 0.0674 s / img. ETA=0:00:41
[32m[04/08 11:35:28 d2.evaluation.evaluator]: [0mInference done 2758/3266. 0.0675 s / img. ETA=0:00:37
[32m[04/08 11:35:33 d2.evaluation.evaluator]: [0mInference done 2825/3266. 0.0675 s / img. ETA=0:00:32
[32m[04/08 11:35:38 d2.evaluation.evaluator]: [0mInference done 2892/3266. 0.0675 s / img. ETA=0:00:27
[32m[04/08 11:35:43 d2.evaluation.evaluator]: [0mInference done 2964/3266. 0.0674 s / img. ETA=0:00:22
[32m[04/08 11:35:48 d2.evaluation.evaluator]: [0mInference done 3036/3266. 0.0674 s / img. ETA=0:00:16
[32m[04/08 11:35:53 d2.evaluation.evaluator]: [0mInference done 3107/3266. 0.0674 s / img. ETA=0:00:11
[32m[04/08 11:35:58 d2.evaluation.evaluator]: [0mInference done 3179/3266. 0.0673 s / img. ETA=0:00:06
[32m[04/08 11:36:03 d2.evaluation.evaluator]: [0mInference done 3250/3266. 0.0673 s / img. ETA=0:00:01
[32m[04/08 11:36:05 d2.evaluation.evaluator]: [0mTotal inference time: 0:03:57.569859 (0.072852 s / img per device, on 1 devices)
[32m[04/08 11:36:05 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:03:39 (0.067307 s / img per device, on 1 devices)
[32m[04/08 11:36:05 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/08 11:36:05 d2.evaluation.coco_evaluation]: [0mSaving results to ../trained_model_sim_1/coco_instances_results.json
[32m[04/08 11:36:05 d2.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=8.04s).
Accumulating evaluation results...
DONE (t=1.91s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.487
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.700
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.334
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.555
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.546
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.369
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.705
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.740
[32m[04/08 11:36:15 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.696 | 69.984 | 53.347 | 33.364 | 61.112 | 55.503 |
[32m[04/08 11:36:15 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 67.368 | Pedestrian | 30.023 |
Loading and preparing results...
DONE (t=0.27s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
DONE (t=6.37s).
Accumulating evaluation results...
DONE (t=0.85s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.435
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.269
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696
[32m[04/08 11:36:23 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.476 | 66.333 | 43.470 | 26.860 | 53.252 | 67.782 |
[32m[04/08 11:36:23 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 65.270 | Pedestrian | 19.682 |
trained_model_sim_0.8
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
['0004', '0005', '0007', '0008', '0009', '0011', '0015']
Loading sequence 0004
Loading sequence 0005
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0011
Loading sequence 0015
0004
0005
0007
0008
0009
0011
0015
Loaded 3266 images!
[32m[04/08 11:37:57 d2.data.common]: [0mSerializing 3266 elements to byte tensors and concatenating them all ...
[32m[04/08 11:37:58 d2.data.common]: [0mSerialized dataset takes 8.46 MiB
[32m[04/08 11:37:58 d2.evaluation.evaluator]: [0mStart inference on 3266 images
[32m[04/08 11:38:05 d2.evaluation.evaluator]: [0mInference done 11/3266. 0.0644 s / img. ETA=0:03:42
[32m[04/08 11:38:10 d2.evaluation.evaluator]: [0mInference done 82/3266. 0.0668 s / img. ETA=0:03:45
[32m[04/08 11:38:15 d2.evaluation.evaluator]: [0mInference done 154/3266. 0.0659 s / img. ETA=0:03:39
[32m[04/08 11:38:20 d2.evaluation.evaluator]: [0mInference done 225/3266. 0.0659 s / img. ETA=0:03:34
[32m[04/08 11:38:25 d2.evaluation.evaluator]: [0mInference done 286/3266. 0.0686 s / img. ETA=0:03:38
[32m[04/08 11:38:30 d2.evaluation.evaluator]: [0mInference done 357/3266. 0.0680 s / img. ETA=0:03:31
[32m[04/08 11:38:35 d2.evaluation.evaluator]: [0mInference done 429/3266. 0.0675 s / img. ETA=0:03:24
[32m[04/08 11:38:40 d2.evaluation.evaluator]: [0mInference done 457/3266. 0.0676 s / img. ETA=0:03:41
[32m[04/08 11:38:45 d2.evaluation.evaluator]: [0mInference done 527/3266. 0.0675 s / img. ETA=0:03:33
[32m[04/08 11:38:50 d2.evaluation.evaluator]: [0mInference done 597/3266. 0.0674 s / img. ETA=0:03:26
[32m[04/08 11:38:55 d2.evaluation.evaluator]: [0mInference done 668/3266. 0.0672 s / img. ETA=0:03:18
[32m[04/08 11:39:00 d2.evaluation.evaluator]: [0mInference done 740/3266. 0.0670 s / img. ETA=0:03:11
[32m[04/08 11:39:07 d2.evaluation.evaluator]: [0mInference done 754/3266. 0.0747 s / img. ETA=0:03:29
[32m[04/08 11:39:12 d2.evaluation.evaluator]: [0mInference done 824/3266. 0.0740 s / img. ETA=0:03:21
[32m[04/08 11:39:17 d2.evaluation.evaluator]: [0mInference done 882/3266. 0.0735 s / img. ETA=0:03:19
[32m[04/08 11:39:26 d2.evaluation.evaluator]: [0mInference done 916/3266. 0.0729 s / img. ETA=0:03:30
[32m[04/08 11:39:31 d2.evaluation.evaluator]: [0mInference done 985/3266. 0.0725 s / img. ETA=0:03:21
[32m[04/08 11:39:36 d2.evaluation.evaluator]: [0mInference done 1055/3266. 0.0722 s / img. ETA=0:03:13
[32m[04/08 11:39:41 d2.evaluation.evaluator]: [0mInference done 1126/3266. 0.0718 s / img. ETA=0:03:04
[32m[04/08 11:39:46 d2.evaluation.evaluator]: [0mInference done 1196/3266. 0.0716 s / img. ETA=0:02:57
[32m[04/08 11:39:51 d2.evaluation.evaluator]: [0mInference done 1268/3266. 0.0712 s / img. ETA=0:02:49
[32m[04/08 11:39:56 d2.evaluation.evaluator]: [0mInference done 1340/3266. 0.0709 s / img. ETA=0:02:41
[32m[04/08 11:40:01 d2.evaluation.evaluator]: [0mInference done 1412/3266. 0.0706 s / img. ETA=0:02:34
[32m[04/08 11:40:06 d2.evaluation.evaluator]: [0mInference done 1483/3266. 0.0704 s / img. ETA=0:02:27
[32m[04/08 11:40:11 d2.evaluation.evaluator]: [0mInference done 1554/3266. 0.0702 s / img. ETA=0:02:20
[32m[04/08 11:40:16 d2.evaluation.evaluator]: [0mInference done 1625/3266. 0.0700 s / img. ETA=0:02:13
[32m[04/08 11:40:21 d2.evaluation.evaluator]: [0mInference done 1696/3266. 0.0699 s / img. ETA=0:02:07
[32m[04/08 11:40:26 d2.evaluation.evaluator]: [0mInference done 1767/3266. 0.0697 s / img. ETA=0:02:00
[32m[04/08 11:40:31 d2.evaluation.evaluator]: [0mInference done 1837/3266. 0.0696 s / img. ETA=0:01:54
[32m[04/08 11:40:36 d2.evaluation.evaluator]: [0mInference done 1908/3266. 0.0695 s / img. ETA=0:01:48
[32m[04/08 11:40:41 d2.evaluation.evaluator]: [0mInference done 1982/3266. 0.0693 s / img. ETA=0:01:42
[32m[04/08 11:40:46 d2.evaluation.evaluator]: [0mInference done 2053/3266. 0.0692 s / img. ETA=0:01:36
[32m[04/08 11:40:51 d2.evaluation.evaluator]: [0mInference done 2123/3266. 0.0691 s / img. ETA=0:01:30
[32m[04/08 11:40:57 d2.evaluation.evaluator]: [0mInference done 2197/3266. 0.0690 s / img. ETA=0:01:24
[32m[04/08 11:41:02 d2.evaluation.evaluator]: [0mInference done 2255/3266. 0.0693 s / img. ETA=0:01:19
[32m[04/08 11:41:07 d2.evaluation.evaluator]: [0mInference done 2326/3266. 0.0692 s / img. ETA=0:01:13
[32m[04/08 11:41:12 d2.evaluation.evaluator]: [0mInference done 2395/3266. 0.0691 s / img. ETA=0:01:08
[32m[04/08 11:41:17 d2.evaluation.evaluator]: [0mInference done 2465/3266. 0.0691 s / img. ETA=0:01:02
[32m[04/08 11:41:22 d2.evaluation.evaluator]: [0mInference done 2533/3266. 0.0690 s / img. ETA=0:00:57
[32m[04/08 11:41:27 d2.evaluation.evaluator]: [0mInference done 2598/3266. 0.0690 s / img. ETA=0:00:52
[32m[04/08 11:41:32 d2.evaluation.evaluator]: [0mInference done 2650/3266. 0.0690 s / img. ETA=0:00:48
[32m[04/08 11:41:38 d2.evaluation.evaluator]: [0mInference done 2709/3266. 0.0690 s / img. ETA=0:00:44
[32m[04/08 11:41:43 d2.evaluation.evaluator]: [0mInference done 2731/3266. 0.0690 s / img. ETA=0:00:43
[32m[04/08 11:41:49 d2.evaluation.evaluator]: [0mInference done 2796/3266. 0.0690 s / img. ETA=0:00:37
[32m[04/08 11:41:54 d2.evaluation.evaluator]: [0mInference done 2861/3266. 0.0690 s / img. ETA=0:00:32
[32m[04/08 11:41:59 d2.evaluation.evaluator]: [0mInference done 2928/3266. 0.0690 s / img. ETA=0:00:27
[32m[04/08 11:42:04 d2.evaluation.evaluator]: [0mInference done 2998/3266. 0.0690 s / img. ETA=0:00:21
[32m[04/08 11:42:09 d2.evaluation.evaluator]: [0mInference done 3066/3266. 0.0689 s / img. ETA=0:00:15
[32m[04/08 11:42:14 d2.evaluation.evaluator]: [0mInference done 3135/3266. 0.0689 s / img. ETA=0:00:10
[32m[04/08 11:42:19 d2.evaluation.evaluator]: [0mInference done 3205/3266. 0.0689 s / img. ETA=0:00:04
[32m[04/08 11:42:23 d2.evaluation.evaluator]: [0mTotal inference time: 0:04:18.995362 (0.079422 s / img per device, on 1 devices)
[32m[04/08 11:42:23 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:03:44 (0.068856 s / img per device, on 1 devices)
[32m[04/08 11:42:23 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/08 11:42:23 d2.evaluation.coco_evaluation]: [0mSaving results to ../trained_model_sim_0.8/coco_instances_results.json
[32m[04/08 11:42:23 d2.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=5.74s).
Accumulating evaluation results...
DONE (t=0.75s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.713
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.544
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.340
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.552
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.389
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.725
[32m[04/08 11:42:30 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 48.951 | 71.325 | 54.362 | 34.014 | 61.122 | 56.180 |
[32m[04/08 11:42:30 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 67.237 | Pedestrian | 30.664 |
Loading and preparing results...
DONE (t=0.26s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
DONE (t=6.89s).
Accumulating evaluation results...
DONE (t=0.58s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.418
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.663
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.429
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.269
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.613
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.155
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.325
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.654
[32m[04/08 11:42:38 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.762 | 66.326 | 42.930 | 26.877 | 51.791 | 61.319 |
[32m[04/08 11:42:38 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 65.569 | Pedestrian | 17.956 |
trained_model_sim_0.6
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
['0004', '0005', '0007', '0008', '0009', '0011', '0015']
Loading sequence 0004
Loading sequence 0005
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0011
Loading sequence 0015
0004
0005
0007
0008
0009
0011
0015
Loaded 3266 images!
[32m[04/08 11:44:04 d2.data.common]: [0mSerializing 3266 elements to byte tensors and concatenating them all ...
[32m[04/08 11:44:05 d2.data.common]: [0mSerialized dataset takes 8.46 MiB
[32m[04/08 11:44:05 d2.evaluation.evaluator]: [0mStart inference on 3266 images
[32m[04/08 11:44:12 d2.evaluation.evaluator]: [0mInference done 11/3266. 0.0682 s / img. ETA=0:03:56
[32m[04/08 11:44:20 d2.evaluation.evaluator]: [0mInference done 26/3266. 0.0672 s / img. ETA=0:20:35
[32m[04/08 11:44:25 d2.evaluation.evaluator]: [0mInference done 89/3266. 0.0677 s / img. ETA=0:08:13
[32m[04/08 11:44:30 d2.evaluation.evaluator]: [0mInference done 142/3266. 0.0762 s / img. ETA=0:06:52
[32m[04/08 11:44:35 d2.evaluation.evaluator]: [0mInference done 210/3266. 0.0738 s / img. ETA=0:05:44
[32m[04/08 11:44:40 d2.evaluation.evaluator]: [0mInference done 282/3266. 0.0717 s / img. ETA=0:05:03
[32m[04/08 11:44:45 d2.evaluation.evaluator]: [0mInference done 353/3266. 0.0705 s / img. ETA=0:04:37
[32m[04/08 11:44:50 d2.evaluation.evaluator]: [0mInference done 423/3266. 0.0699 s / img. ETA=0:04:19
[32m[04/08 11:44:55 d2.evaluation.evaluator]: [0mInference done 494/3266. 0.0693 s / img. ETA=0:04:05
[32m[04/08 11:45:00 d2.evaluation.evaluator]: [0mInference done 564/3266. 0.0689 s / img. ETA=0:03:53
[32m[04/08 11:45:05 d2.evaluation.evaluator]: [0mInference done 634/3266. 0.0686 s / img. ETA=0:03:43
[32m[04/08 11:45:10 d2.evaluation.evaluator]: [0mInference done 705/3266. 0.0684 s / img. ETA=0:03:33
[32m[04/08 11:45:15 d2.evaluation.evaluator]: [0mInference done 775/3266. 0.0683 s / img. ETA=0:03:24
[32m[04/08 11:45:20 d2.evaluation.evaluator]: [0mInference done 845/3266. 0.0682 s / img. ETA=0:03:17
[32m[04/08 11:45:25 d2.evaluation.evaluator]: [0mInference done 916/3266. 0.0680 s / img. ETA=0:03:09
[32m[04/08 11:45:30 d2.evaluation.evaluator]: [0mInference done 986/3266. 0.0680 s / img. ETA=0:03:02
[32m[04/08 11:45:35 d2.evaluation.evaluator]: [0mInference done 1055/3266. 0.0679 s / img. ETA=0:02:55
[32m[04/08 11:45:40 d2.evaluation.evaluator]: [0mInference done 1125/3266. 0.0679 s / img. ETA=0:02:49
[32m[04/08 11:45:45 d2.evaluation.evaluator]: [0mInference done 1195/3266. 0.0679 s / img. ETA=0:02:42
[32m[04/08 11:45:50 d2.evaluation.evaluator]: [0mInference done 1265/3266. 0.0679 s / img. ETA=0:02:36
[32m[04/08 11:45:55 d2.evaluation.evaluator]: [0mInference done 1334/3266. 0.0678 s / img. ETA=0:02:30
[32m[04/08 11:46:00 d2.evaluation.evaluator]: [0mInference done 1405/3266. 0.0678 s / img. ETA=0:02:24
[32m[04/08 11:46:05 d2.evaluation.evaluator]: [0mInference done 1476/3266. 0.0677 s / img. ETA=0:02:18
[32m[04/08 11:46:10 d2.evaluation.evaluator]: [0mInference done 1547/3266. 0.0676 s / img. ETA=0:02:12
[32m[04/08 11:46:15 d2.evaluation.evaluator]: [0mInference done 1616/3266. 0.0676 s / img. ETA=0:02:06
[32m[04/08 11:46:20 d2.evaluation.evaluator]: [0mInference done 1675/3266. 0.0681 s / img. ETA=0:02:02
[32m[04/08 11:46:25 d2.evaluation.evaluator]: [0mInference done 1745/3266. 0.0681 s / img. ETA=0:01:56
[32m[04/08 11:46:30 d2.evaluation.evaluator]: [0mInference done 1814/3266. 0.0680 s / img. ETA=0:01:51
[32m[04/08 11:46:35 d2.evaluation.evaluator]: [0mInference done 1885/3266. 0.0680 s / img. ETA=0:01:45
[32m[04/08 11:46:41 d2.evaluation.evaluator]: [0mInference done 1955/3266. 0.0679 s / img. ETA=0:01:40
[32m[04/08 11:46:46 d2.evaluation.evaluator]: [0mInference done 2025/3266. 0.0679 s / img. ETA=0:01:34
[32m[04/08 11:46:51 d2.evaluation.evaluator]: [0mInference done 2092/3266. 0.0680 s / img. ETA=0:01:29
[32m[04/08 11:46:56 d2.evaluation.evaluator]: [0mInference done 2163/3266. 0.0679 s / img. ETA=0:01:23
[32m[04/08 11:47:01 d2.evaluation.evaluator]: [0mInference done 2234/3266. 0.0678 s / img. ETA=0:01:18
[32m[04/08 11:47:06 d2.evaluation.evaluator]: [0mInference done 2304/3266. 0.0678 s / img. ETA=0:01:12
[32m[04/08 11:47:11 d2.evaluation.evaluator]: [0mInference done 2372/3266. 0.0678 s / img. ETA=0:01:07
[32m[04/08 11:47:16 d2.evaluation.evaluator]: [0mInference done 2442/3266. 0.0678 s / img. ETA=0:01:02
[32m[04/08 11:47:21 d2.evaluation.evaluator]: [0mInference done 2511/3266. 0.0678 s / img. ETA=0:00:57
[32m[04/08 11:47:26 d2.evaluation.evaluator]: [0mInference done 2576/3266. 0.0678 s / img. ETA=0:00:52
[32m[04/08 11:47:31 d2.evaluation.evaluator]: [0mInference done 2639/3266. 0.0679 s / img. ETA=0:00:47
[32m[04/08 11:47:36 d2.evaluation.evaluator]: [0mInference done 2704/3266. 0.0680 s / img. ETA=0:00:42
[32m[04/08 11:47:41 d2.evaluation.evaluator]: [0mInference done 2767/3266. 0.0680 s / img. ETA=0:00:37
[32m[04/08 11:47:47 d2.evaluation.evaluator]: [0mInference done 2796/3266. 0.0680 s / img. ETA=0:00:36
[32m[04/08 11:47:52 d2.evaluation.evaluator]: [0mInference done 2860/3266. 0.0681 s / img. ETA=0:00:31
[32m[04/08 11:47:58 d2.evaluation.evaluator]: [0mInference done 2927/3266. 0.0681 s / img. ETA=0:00:26
[32m[04/08 11:48:03 d2.evaluation.evaluator]: [0mInference done 2975/3266. 0.0686 s / img. ETA=0:00:22
[32m[04/08 11:48:08 d2.evaluation.evaluator]: [0mInference done 3044/3266. 0.0686 s / img. ETA=0:00:17
[32m[04/08 11:48:13 d2.evaluation.evaluator]: [0mInference done 3113/3266. 0.0686 s / img. ETA=0:00:11
[32m[04/08 11:48:18 d2.evaluation.evaluator]: [0mInference done 3182/3266. 0.0686 s / img. ETA=0:00:06
[32m[04/08 11:48:23 d2.evaluation.evaluator]: [0mInference done 3251/3266. 0.0686 s / img. ETA=0:00:01
[32m[04/08 11:48:26 d2.evaluation.evaluator]: [0mTotal inference time: 0:04:14.274248 (0.077974 s / img per device, on 1 devices)
[32m[04/08 11:48:26 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:03:43 (0.068546 s / img per device, on 1 devices)
[32m[04/08 11:48:26 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/08 11:48:26 d2.evaluation.coco_evaluation]: [0mSaving results to ../trained_model_sim_0.6/coco_instances_results.json
[32m[04/08 11:48:26 d2.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=6.29s).
Accumulating evaluation results...
DONE (t=0.82s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.491
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.724
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.537
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.345
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.559
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.557
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.564
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.400
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.759
[32m[04/08 11:48:34 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 49.125 | 72.365 | 53.680 | 34.487 | 60.816 | 55.916 |
[32m[04/08 11:48:34 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 68.436 | Pedestrian | 29.814 |
Loading and preparing results...
DONE (t=0.36s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
DONE (t=7.16s).
Accumulating evaluation results...
DONE (t=0.58s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.678
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.434
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.279
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.535
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.498
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.339
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.696
[32m[04/08 11:48:42 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.981 | 67.837 | 43.360 | 27.949 | 53.487 | 67.689 |
[32m[04/08 11:48:42 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 66.666 | Pedestrian | 19.295 |
trained_model_sim_0.4
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
['0004', '0005', '0007', '0008', '0009', '0011', '0015']
Loading sequence 0004
Loading sequence 0005
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0011
Loading sequence 0015
0004
0005
0007
0008
0009
0011
0015
Loaded 3266 images!
[32m[04/08 11:50:08 d2.data.common]: [0mSerializing 3266 elements to byte tensors and concatenating them all ...
[32m[04/08 11:50:08 d2.data.common]: [0mSerialized dataset takes 8.46 MiB
[32m[04/08 11:50:08 d2.evaluation.evaluator]: [0mStart inference on 3266 images
[32m[04/08 11:50:09 d2.evaluation.evaluator]: [0mInference done 11/3266. 0.0638 s / img. ETA=0:03:40
[32m[04/08 11:50:14 d2.evaluation.evaluator]: [0mInference done 81/3266. 0.0661 s / img. ETA=0:03:48
[32m[04/08 11:50:19 d2.evaluation.evaluator]: [0mInference done 115/3266. 0.0904 s / img. ETA=0:05:01
[32m[04/08 11:50:25 d2.evaluation.evaluator]: [0mInference done 179/3266. 0.0901 s / img. ETA=0:04:53
[32m[04/08 11:50:30 d2.evaluation.evaluator]: [0mInference done 252/3266. 0.0824 s / img. ETA=0:04:23
[32m[04/08 11:50:38 d2.evaluation.evaluator]: [0mInference done 311/3266. 0.0787 s / img. ETA=0:04:40
[32m[04/08 11:50:43 d2.evaluation.evaluator]: [0mInference done 377/3266. 0.0764 s / img. ETA=0:04:24
[32m[04/08 11:50:48 d2.evaluation.evaluator]: [0mInference done 449/3266. 0.0745 s / img. ETA=0:04:08
[32m[04/08 11:50:53 d2.evaluation.evaluator]: [0mInference done 521/3266. 0.0731 s / img. ETA=0:03:55
[32m[04/08 11:50:58 d2.evaluation.evaluator]: [0mInference done 592/3266. 0.0722 s / img. ETA=0:03:44
[32m[04/08 11:51:03 d2.evaluation.evaluator]: [0mInference done 664/3266. 0.0714 s / img. ETA=0:03:34
[32m[04/08 11:51:08 d2.evaluation.evaluator]: [0mInference done 738/3266. 0.0706 s / img. ETA=0:03:24
[32m[04/08 11:51:13 d2.evaluation.evaluator]: [0mInference done 796/3266. 0.0714 s / img. ETA=0:03:21
[32m[04/08 11:51:18 d2.evaluation.evaluator]: [0mInference done 868/3266. 0.0708 s / img. ETA=0:03:13
[32m[04/08 11:51:23 d2.evaluation.evaluator]: [0mInference done 940/3266. 0.0703 s / img. ETA=0:03:05
[32m[04/08 11:51:28 d2.evaluation.evaluator]: [0mInference done 1011/3266. 0.0700 s / img. ETA=0:02:58
[32m[04/08 11:51:33 d2.evaluation.evaluator]: [0mInference done 1083/3266. 0.0696 s / img. ETA=0:02:51
[32m[04/08 11:51:38 d2.evaluation.evaluator]: [0mInference done 1155/3266. 0.0693 s / img. ETA=0:02:44
[32m[04/08 11:51:43 d2.evaluation.evaluator]: [0mInference done 1227/3266. 0.0691 s / img. ETA=0:02:37
[32m[04/08 11:51:48 d2.evaluation.evaluator]: [0mInference done 1263/3266. 0.0709 s / img. ETA=0:02:38
[32m[04/08 11:51:53 d2.evaluation.evaluator]: [0mInference done 1335/3266. 0.0706 s / img. ETA=0:02:31
[32m[04/08 11:51:58 d2.evaluation.evaluator]: [0mInference done 1408/3266. 0.0703 s / img. ETA=0:02:25
[32m[04/08 11:52:04 d2.evaluation.evaluator]: [0mInference done 1482/3266. 0.0700 s / img. ETA=0:02:18
[32m[04/08 11:52:09 d2.evaluation.evaluator]: [0mInference done 1556/3266. 0.0697 s / img. ETA=0:02:12
[32m[04/08 11:52:14 d2.evaluation.evaluator]: [0mInference done 1628/3266. 0.0695 s / img. ETA=0:02:06
[32m[04/08 11:52:19 d2.evaluation.evaluator]: [0mInference done 1701/3266. 0.0693 s / img. ETA=0:01:59
[32m[04/08 11:52:24 d2.evaluation.evaluator]: [0mInference done 1774/3266. 0.0690 s / img. ETA=0:01:53
[32m[04/08 11:52:29 d2.evaluation.evaluator]: [0mInference done 1848/3266. 0.0687 s / img. ETA=0:01:47
[32m[04/08 11:52:34 d2.evaluation.evaluator]: [0mInference done 1882/3266. 0.0687 s / img. ETA=0:01:47
[32m[04/08 11:52:39 d2.evaluation.evaluator]: [0mInference done 1900/3266. 0.0700 s / img. ETA=0:01:48
[32m[04/08 11:52:44 d2.evaluation.evaluator]: [0mInference done 1975/3266. 0.0698 s / img. ETA=0:01:41
[32m[04/08 11:52:49 d2.evaluation.evaluator]: [0mInference done 2048/3266. 0.0695 s / img. ETA=0:01:35
[32m[04/08 11:52:54 d2.evaluation.evaluator]: [0mInference done 2118/3266. 0.0694 s / img. ETA=0:01:29
[32m[04/08 11:52:59 d2.evaluation.evaluator]: [0mInference done 2192/3266. 0.0692 s / img. ETA=0:01:23
[32m[04/08 11:53:04 d2.evaluation.evaluator]: [0mInference done 2264/3266. 0.0691 s / img. ETA=0:01:17
[32m[04/08 11:53:09 d2.evaluation.evaluator]: [0mInference done 2336/3266. 0.0689 s / img. ETA=0:01:12
[32m[04/08 11:53:14 d2.evaluation.evaluator]: [0mInference done 2388/3266. 0.0688 s / img. ETA=0:01:08
[32m[04/08 11:53:19 d2.evaluation.evaluator]: [0mInference done 2459/3266. 0.0687 s / img. ETA=0:01:02
[32m[04/08 11:53:24 d2.evaluation.evaluator]: [0mInference done 2528/3266. 0.0686 s / img. ETA=0:00:57
[32m[04/08 11:53:29 d2.evaluation.evaluator]: [0mInference done 2593/3266. 0.0686 s / img. ETA=0:00:52
[32m[04/08 11:53:35 d2.evaluation.evaluator]: [0mInference done 2655/3266. 0.0686 s / img. ETA=0:00:47
[32m[04/08 11:53:40 d2.evaluation.evaluator]: [0mInference done 2721/3266. 0.0685 s / img. ETA=0:00:42
[32m[04/08 11:53:45 d2.evaluation.evaluator]: [0mInference done 2788/3266. 0.0685 s / img. ETA=0:00:37
[32m[04/08 11:53:51 d2.evaluation.evaluator]: [0mInference done 2855/3266. 0.0684 s / img. ETA=0:00:31
[32m[04/08 11:53:56 d2.evaluation.evaluator]: [0mInference done 2916/3266. 0.0685 s / img. ETA=0:00:27
[32m[04/08 11:54:01 d2.evaluation.evaluator]: [0mInference done 2989/3266. 0.0684 s / img. ETA=0:00:21
[32m[04/08 11:54:06 d2.evaluation.evaluator]: [0mInference done 3058/3266. 0.0683 s / img. ETA=0:00:16
[32m[04/08 11:54:11 d2.evaluation.evaluator]: [0mInference done 3129/3266. 0.0683 s / img. ETA=0:00:10
[32m[04/08 11:54:16 d2.evaluation.evaluator]: [0mInference done 3199/3266. 0.0683 s / img. ETA=0:00:05
[32m[04/08 11:54:21 d2.evaluation.evaluator]: [0mInference done 3258/3266. 0.0685 s / img. ETA=0:00:00
[32m[04/08 11:54:21 d2.evaluation.evaluator]: [0mTotal inference time: 0:04:12.657139 (0.077478 s / img per device, on 1 devices)
[32m[04/08 11:54:21 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:03:43 (0.068454 s / img per device, on 1 devices)
[32m[04/08 11:54:22 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/08 11:54:22 d2.evaluation.coco_evaluation]: [0mSaving results to ../trained_model_sim_0.4/coco_instances_results.json
[32m[04/08 11:54:22 d2.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=5.97s).
Accumulating evaluation results...
DONE (t=0.80s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.712
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.343
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.584
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.397
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735
[32m[04/08 11:54:29 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 47.996 | 71.161 | 51.331 | 34.332 | 58.440 | 57.652 |
[32m[04/08 11:54:29 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 68.101 | Pedestrian | 27.892 |
Loading and preparing results...
DONE (t=0.27s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
DONE (t=7.07s).
Accumulating evaluation results...
DONE (t=0.60s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.420
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.667
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.278
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.515
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.156
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.488
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.496
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.341
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.612
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.668
[32m[04/08 11:54:37 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 41.979 | 66.750 | 42.322 | 27.829 | 51.458 | 63.018 |
[32m[04/08 11:54:37 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 66.557 | Pedestrian | 17.401 |
trained_model_sim_0.2
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
['0004', '0005', '0007', '0008', '0009', '0011', '0015']
Loading sequence 0004
Loading sequence 0005
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0011
Loading sequence 0015
0004
0005
0007
0008
0009
0011
0015
Loaded 3266 images!
[32m[04/08 11:56:10 d2.data.common]: [0mSerializing 3266 elements to byte tensors and concatenating them all ...
[32m[04/08 11:56:11 d2.data.common]: [0mSerialized dataset takes 8.46 MiB
[32m[04/08 11:56:11 d2.evaluation.evaluator]: [0mStart inference on 3266 images
[32m[04/08 11:56:12 d2.evaluation.evaluator]: [0mInference done 11/3266. 0.0636 s / img. ETA=0:03:39
[32m[04/08 11:56:17 d2.evaluation.evaluator]: [0mInference done 55/3266. 0.0987 s / img. ETA=0:05:51
[32m[04/08 11:56:22 d2.evaluation.evaluator]: [0mInference done 126/3266. 0.0797 s / img. ETA=0:04:32
[32m[04/08 11:56:27 d2.evaluation.evaluator]: [0mInference done 196/3266. 0.0750 s / img. ETA=0:04:09
[32m[04/08 11:56:32 d2.evaluation.evaluator]: [0mInference done 267/3266. 0.0726 s / img. ETA=0:03:54
[32m[04/08 11:56:37 d2.evaluation.evaluator]: [0mInference done 337/3266. 0.0714 s / img. ETA=0:03:45
[32m[04/08 11:56:42 d2.evaluation.evaluator]: [0mInference done 406/3266. 0.0707 s / img. ETA=0:03:37
[32m[04/08 11:56:47 d2.evaluation.evaluator]: [0mInference done 475/3266. 0.0702 s / img. ETA=0:03:31
[32m[04/08 11:56:52 d2.evaluation.evaluator]: [0mInference done 543/3266. 0.0700 s / img. ETA=0:03:25
[32m[04/08 11:56:57 d2.evaluation.evaluator]: [0mInference done 612/3266. 0.0698 s / img. ETA=0:03:19
[32m[04/08 11:57:02 d2.evaluation.evaluator]: [0mInference done 681/3266. 0.0696 s / img. ETA=0:03:13
[32m[04/08 11:57:07 d2.evaluation.evaluator]: [0mInference done 750/3266. 0.0694 s / img. ETA=0:03:07
[32m[04/08 11:57:12 d2.evaluation.evaluator]: [0mInference done 819/3266. 0.0693 s / img. ETA=0:03:02
[32m[04/08 11:57:17 d2.evaluation.evaluator]: [0mInference done 888/3266. 0.0691 s / img. ETA=0:02:57
[32m[04/08 11:57:22 d2.evaluation.evaluator]: [0mInference done 957/3266. 0.0690 s / img. ETA=0:02:51
[32m[04/08 11:57:27 d2.evaluation.evaluator]: [0mInference done 1026/3266. 0.0690 s / img. ETA=0:02:46
[32m[04/08 11:57:32 d2.evaluation.evaluator]: [0mInference done 1095/3266. 0.0689 s / img. ETA=0:02:41
[32m[04/08 11:57:37 d2.evaluation.evaluator]: [0mInference done 1164/3266. 0.0689 s / img. ETA=0:02:35
[32m[04/08 11:57:43 d2.evaluation.evaluator]: [0mInference done 1234/3266. 0.0688 s / img. ETA=0:02:30
[32m[04/08 11:57:48 d2.evaluation.evaluator]: [0mInference done 1303/3266. 0.0687 s / img. ETA=0:02:25
[32m[04/08 11:57:53 d2.evaluation.evaluator]: [0mInference done 1372/3266. 0.0687 s / img. ETA=0:02:19
[32m[04/08 11:57:58 d2.evaluation.evaluator]: [0mInference done 1443/3266. 0.0686 s / img. ETA=0:02:14
[32m[04/08 11:58:03 d2.evaluation.evaluator]: [0mInference done 1509/3266. 0.0686 s / img. ETA=0:02:09
[32m[04/08 11:58:08 d2.evaluation.evaluator]: [0mInference done 1578/3266. 0.0686 s / img. ETA=0:02:04
[32m[04/08 11:58:13 d2.evaluation.evaluator]: [0mInference done 1647/3266. 0.0686 s / img. ETA=0:01:59
[32m[04/08 11:58:18 d2.evaluation.evaluator]: [0mInference done 1718/3266. 0.0685 s / img. ETA=0:01:54
[32m[04/08 11:58:23 d2.evaluation.evaluator]: [0mInference done 1787/3266. 0.0684 s / img. ETA=0:01:48
[32m[04/08 11:58:28 d2.evaluation.evaluator]: [0mInference done 1856/3266. 0.0684 s / img. ETA=0:01:43
[32m[04/08 11:58:33 d2.evaluation.evaluator]: [0mInference done 1926/3266. 0.0683 s / img. ETA=0:01:38
[32m[04/08 11:58:38 d2.evaluation.evaluator]: [0mInference done 1996/3266. 0.0683 s / img. ETA=0:01:33
[32m[04/08 11:58:43 d2.evaluation.evaluator]: [0mInference done 2066/3266. 0.0683 s / img. ETA=0:01:28
[32m[04/08 11:58:48 d2.evaluation.evaluator]: [0mInference done 2134/3266. 0.0682 s / img. ETA=0:01:23
[32m[04/08 11:58:53 d2.evaluation.evaluator]: [0mInference done 2204/3266. 0.0682 s / img. ETA=0:01:17
[32m[04/08 11:58:58 d2.evaluation.evaluator]: [0mInference done 2273/3266. 0.0682 s / img. ETA=0:01:12
[32m[04/08 11:59:03 d2.evaluation.evaluator]: [0mInference done 2342/3266. 0.0682 s / img. ETA=0:01:07
[32m[04/08 11:59:08 d2.evaluation.evaluator]: [0mInference done 2412/3266. 0.0682 s / img. ETA=0:01:02
[32m[04/08 11:59:13 d2.evaluation.evaluator]: [0mInference done 2480/3266. 0.0682 s / img. ETA=0:00:57
[32m[04/08 11:59:18 d2.evaluation.evaluator]: [0mInference done 2547/3266. 0.0682 s / img. ETA=0:00:52
[32m[04/08 11:59:23 d2.evaluation.evaluator]: [0mInference done 2610/3266. 0.0683 s / img. ETA=0:00:48
[32m[04/08 11:59:28 d2.evaluation.evaluator]: [0mInference done 2674/3266. 0.0683 s / img. ETA=0:00:43
[32m[04/08 11:59:33 d2.evaluation.evaluator]: [0mInference done 2738/3266. 0.0683 s / img. ETA=0:00:38
[32m[04/08 11:59:38 d2.evaluation.evaluator]: [0mInference done 2798/3266. 0.0684 s / img. ETA=0:00:34
[32m[04/08 11:59:43 d2.evaluation.evaluator]: [0mInference done 2863/3266. 0.0684 s / img. ETA=0:00:29
[32m[04/08 11:59:48 d2.evaluation.evaluator]: [0mInference done 2930/3266. 0.0684 s / img. ETA=0:00:24
[32m[04/08 11:59:53 d2.evaluation.evaluator]: [0mInference done 2999/3266. 0.0684 s / img. ETA=0:00:19
[32m[04/08 11:59:59 d2.evaluation.evaluator]: [0mInference done 3068/3266. 0.0684 s / img. ETA=0:00:14
[32m[04/08 12:00:04 d2.evaluation.evaluator]: [0mInference done 3138/3266. 0.0684 s / img. ETA=0:00:09
[32m[04/08 12:00:09 d2.evaluation.evaluator]: [0mInference done 3207/3266. 0.0684 s / img. ETA=0:00:04
[32m[04/08 12:00:13 d2.evaluation.evaluator]: [0mTotal inference time: 0:04:01.352940 (0.074012 s / img per device, on 1 devices)
[32m[04/08 12:00:13 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:03:43 (0.068398 s / img per device, on 1 devices)
[32m[04/08 12:00:13 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/08 12:00:13 d2.evaluation.coco_evaluation]: [0mSaving results to ../trained_model_sim_0.2/coco_instances_results.json
[32m[04/08 12:00:13 d2.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=5.83s).
Accumulating evaluation results...
DONE (t=0.82s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.643
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.428
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.310
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.508
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.487
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.494
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647
[32m[04/08 12:00:20 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 42.556 | 64.336 | 42.795 | 30.953 | 50.837 | 49.970 |
[32m[04/08 12:00:20 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 67.552 | Pedestrian | 17.560 |
Loading and preparing results...
DONE (t=0.25s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
DONE (t=6.85s).
Accumulating evaluation results...
DONE (t=0.56s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.626
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.261
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.574
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.454
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.566
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595
[32m[04/08 12:00:28 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 39.849 | 62.642 | 39.872 | 26.074 | 48.599 | 57.407 |
[32m[04/08 12:00:28 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 65.874 | Pedestrian | 13.823 |
trained_model_sim_0.1
/home/grupo08/datasets/KITTI_MOTS/instances_txt/
['0004', '0005', '0007', '0008', '0009', '0011', '0015']
Loading sequence 0004
Loading sequence 0005
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0011
Loading sequence 0015
0004
0005
0007
0008
0009
0011
0015
Loaded 3266 images!
[32m[04/08 12:02:00 d2.data.common]: [0mSerializing 3266 elements to byte tensors and concatenating them all ...
[32m[04/08 12:02:01 d2.data.common]: [0mSerialized dataset takes 8.46 MiB
[32m[04/08 12:02:01 d2.evaluation.evaluator]: [0mStart inference on 3266 images
[32m[04/08 12:02:02 d2.evaluation.evaluator]: [0mInference done 11/3266. 0.0626 s / img. ETA=0:03:36
[32m[04/08 12:02:07 d2.evaluation.evaluator]: [0mInference done 84/3266. 0.0646 s / img. ETA=0:03:39
[32m[04/08 12:02:12 d2.evaluation.evaluator]: [0mInference done 158/3266. 0.0641 s / img. ETA=0:03:33
[32m[04/08 12:02:17 d2.evaluation.evaluator]: [0mInference done 234/3266. 0.0636 s / img. ETA=0:03:26
[32m[04/08 12:02:22 d2.evaluation.evaluator]: [0mInference done 307/3266. 0.0637 s / img. ETA=0:03:21
[32m[04/08 12:02:27 d2.evaluation.evaluator]: [0mInference done 379/3266. 0.0639 s / img. ETA=0:03:17
[32m[04/08 12:02:32 d2.evaluation.evaluator]: [0mInference done 452/3266. 0.0638 s / img. ETA=0:03:12
[32m[04/08 12:02:37 d2.evaluation.evaluator]: [0mInference done 524/3266. 0.0639 s / img. ETA=0:03:08
[32m[04/08 12:02:42 d2.evaluation.evaluator]: [0mInference done 596/3266. 0.0639 s / img. ETA=0:03:03
[32m[04/08 12:02:47 d2.evaluation.evaluator]: [0mInference done 668/3266. 0.0640 s / img. ETA=0:02:59
[32m[04/08 12:02:52 d2.evaluation.evaluator]: [0mInference done 741/3266. 0.0640 s / img. ETA=0:02:54
[32m[04/08 12:02:57 d2.evaluation.evaluator]: [0mInference done 812/3266. 0.0640 s / img. ETA=0:02:49
[32m[04/08 12:03:02 d2.evaluation.evaluator]: [0mInference done 885/3266. 0.0640 s / img. ETA=0:02:44
[32m[04/08 12:03:07 d2.evaluation.evaluator]: [0mInference done 956/3266. 0.0641 s / img. ETA=0:02:39
[32m[04/08 12:03:12 d2.evaluation.evaluator]: [0mInference done 1027/3266. 0.0642 s / img. ETA=0:02:35
[32m[04/08 12:03:17 d2.evaluation.evaluator]: [0mInference done 1099/3266. 0.0642 s / img. ETA=0:02:30
[32m[04/08 12:03:22 d2.evaluation.evaluator]: [0mInference done 1172/3266. 0.0642 s / img. ETA=0:02:25
[32m[04/08 12:03:27 d2.evaluation.evaluator]: [0mInference done 1244/3266. 0.0642 s / img. ETA=0:02:20
[32m[04/08 12:03:34 d2.evaluation.evaluator]: [0mInference done 1302/3266. 0.0659 s / img. ETA=0:02:19
[32m[04/08 12:03:39 d2.evaluation.evaluator]: [0mInference done 1375/3266. 0.0658 s / img. ETA=0:02:14
[32m[04/08 12:03:44 d2.evaluation.evaluator]: [0mInference done 1449/3266. 0.0657 s / img. ETA=0:02:08
[32m[04/08 12:03:49 d2.evaluation.evaluator]: [0mInference done 1522/3266. 0.0657 s / img. ETA=0:02:03
[32m[04/08 12:03:54 d2.evaluation.evaluator]: [0mInference done 1596/3266. 0.0656 s / img. ETA=0:01:57
[32m[04/08 12:03:59 d2.evaluation.evaluator]: [0mInference done 1669/3266. 0.0655 s / img. ETA=0:01:52
[32m[04/08 12:04:04 d2.evaluation.evaluator]: [0mInference done 1742/3266. 0.0654 s / img. ETA=0:01:47
[32m[04/08 12:04:09 d2.evaluation.evaluator]: [0mInference done 1814/3266. 0.0654 s / img. ETA=0:01:42
[32m[04/08 12:04:14 d2.evaluation.evaluator]: [0mInference done 1887/3266. 0.0653 s / img. ETA=0:01:37
[32m[04/08 12:04:19 d2.evaluation.evaluator]: [0mInference done 1960/3266. 0.0653 s / img. ETA=0:01:31
[32m[04/08 12:04:24 d2.evaluation.evaluator]: [0mInference done 2031/3266. 0.0653 s / img. ETA=0:01:26
[32m[04/08 12:04:29 d2.evaluation.evaluator]: [0mInference done 2102/3266. 0.0653 s / img. ETA=0:01:21
[32m[04/08 12:04:34 d2.evaluation.evaluator]: [0mInference done 2174/3266. 0.0653 s / img. ETA=0:01:16
[32m[04/08 12:04:39 d2.evaluation.evaluator]: [0mInference done 2247/3266. 0.0652 s / img. ETA=0:01:11
[32m[04/08 12:04:44 d2.evaluation.evaluator]: [0mInference done 2319/3266. 0.0652 s / img. ETA=0:01:06
[32m[04/08 12:04:49 d2.evaluation.evaluator]: [0mInference done 2390/3266. 0.0652 s / img. ETA=0:01:01
[32m[04/08 12:04:54 d2.evaluation.evaluator]: [0mInference done 2462/3266. 0.0651 s / img. ETA=0:00:56
[32m[04/08 12:04:59 d2.evaluation.evaluator]: [0mInference done 2531/3266. 0.0652 s / img. ETA=0:00:51
[32m[04/08 12:05:04 d2.evaluation.evaluator]: [0mInference done 2597/3266. 0.0652 s / img. ETA=0:00:47
[32m[04/08 12:05:09 d2.evaluation.evaluator]: [0mInference done 2663/3266. 0.0653 s / img. ETA=0:00:42
[32m[04/08 12:05:14 d2.evaluation.evaluator]: [0mInference done 2730/3266. 0.0653 s / img. ETA=0:00:37
[32m[04/08 12:05:19 d2.evaluation.evaluator]: [0mInference done 2797/3266. 0.0654 s / img. ETA=0:00:33
[32m[04/08 12:05:25 d2.evaluation.evaluator]: [0mInference done 2864/3266. 0.0654 s / img. ETA=0:00:28
[32m[04/08 12:05:30 d2.evaluation.evaluator]: [0mInference done 2935/3266. 0.0654 s / img. ETA=0:00:23
[32m[04/08 12:05:35 d2.evaluation.evaluator]: [0mInference done 3008/3266. 0.0654 s / img. ETA=0:00:18
[32m[04/08 12:05:40 d2.evaluation.evaluator]: [0mInference done 3082/3266. 0.0654 s / img. ETA=0:00:13
[32m[04/08 12:05:45 d2.evaluation.evaluator]: [0mInference done 3154/3266. 0.0654 s / img. ETA=0:00:07
[32m[04/08 12:05:50 d2.evaluation.evaluator]: [0mInference done 3227/3266. 0.0654 s / img. ETA=0:00:02
[32m[04/08 12:05:52 d2.evaluation.evaluator]: [0mTotal inference time: 0:03:51.156093 (0.070885 s / img per device, on 1 devices)
[32m[04/08 12:05:52 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:03:33 (0.065376 s / img per device, on 1 devices)
[32m[04/08 12:05:53 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[04/08 12:05:53 d2.evaluation.coco_evaluation]: [0mSaving results to ../trained_model_sim_0.1/coco_instances_results.json
[32m[04/08 12:05:53 d2.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.03s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=5.82s).
Accumulating evaluation results...
DONE (t=0.59s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.235
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.443
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.097
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.357
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.270
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473
[32m[04/08 12:05:59 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 33.659 | 42.605 | 38.775 | 23.455 | 38.633 | 44.347 |
[32m[04/08 12:05:59 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP    |
|:-----------|:-----|:-----------|:-------|:-----------|:------|
| None       | nan  | Car        | 67.318 | Pedestrian | 0.000 |
Loading and preparing results...
DONE (t=0.27s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
DONE (t=7.03s).
Accumulating evaluation results...
DONE (t=0.59s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.215
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.095
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.345
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.353
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.256
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472
[32m[04/08 12:06:08 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 32.493 | 42.564 | 37.698 | 21.548 | 36.856 | 44.751 |
[32m[04/08 12:06:08 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP   | category   | AP     | category   | AP    |
|:-----------|:-----|:-----------|:-------|:-----------|:------|
| None       | nan  | Car        | 64.986 | Pedestrian | 0.000 |
