Metadata(name='KITTI_MOTS_train', thing_classes=['None', 'Car', 'Pedestrian'])
Loading sequence 0000
Loading sequence 0001
Loading sequence 0002
Loading sequence 0003
Loading sequence 0004
Loading sequence 0005
Loading sequence 0006
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0010
Loading sequence 0011
Loading sequence 0012
Loading sequence 0013
Loading sequence 0014
Loading sequence 0015
Loading sequence 0016
Loading sequence 0017
Loading sequence 0018
Loading sequence 0019
Loading sequence 0020
0000
0001
0002
0003
0004
0005
0006
0007
0008
0009
0010
0011
0012
0013
0014
0015
0016
0017
0018
0019
0020
Loaded 5549 images!
Loading sequence 0000
Loading sequence 0001
Loading sequence 0002
Loading sequence 0003
Loading sequence 0004
Loading sequence 0005
Loading sequence 0006
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0010
Loading sequence 0011
Loading sequence 0012
Loading sequence 0013
Loading sequence 0014
Loading sequence 0015
Loading sequence 0016
Loading sequence 0017
Loading sequence 0018
Loading sequence 0019
Loading sequence 0020
0000
0001
0002
0003
0004
0005
0006
0007
0008
0009
0010
0011
0012
0013
0014
0015
0016
0017
0018
0019
0020
Loaded 2336 images!
[5m[31mWARNING[0m [32m[03/12 13:43:14 d2.evaluation.coco_evaluation]: [0mjson_file was not found in MetaDataCatalog for 'KITTI_MOTS_val'. Trying to convert it to COCO format ...
[32m[03/12 13:43:14 d2.data.datasets.coco]: [0mCached annotations in COCO format already exist: ./output/KITTI_MOTS_val_coco_format.json
Loading sequence 0000
Loading sequence 0001
Loading sequence 0002
Loading sequence 0003
Loading sequence 0004
Loading sequence 0005
Loading sequence 0006
Loading sequence 0007
Loading sequence 0008
Loading sequence 0009
Loading sequence 0010
Loading sequence 0011
Loading sequence 0012
Loading sequence 0013
Loading sequence 0014
Loading sequence 0015
Loading sequence 0016
Loading sequence 0017
Loading sequence 0018
Loading sequence 0019
Loading sequence 0020
0000
0001
0002
0003
0004
0005
0006
0007
0008
0009
0010
0011
0012
0013
0014
0015
0016
0017
0018
0019
0020
Loaded 2336 images!
[32m[03/12 13:43:37 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|    None    | 0            |    Car     | 7896         | Pedestrian | 3340         |
|            |              |            |              |            |              |
|   total    | 11236        |            |              |            |              |[0m
[32m[03/12 13:43:37 d2.data.common]: [0mSerializing 2336 elements to byte tensors and concatenating them all ...
[32m[03/12 13:43:37 d2.data.common]: [0mSerialized dataset takes 1.67 MiB
[32m[03/12 13:43:37 d2.evaluation.evaluator]: [0mStart inference on 2336 images
[32m[03/12 13:43:38 d2.evaluation.evaluator]: [0mInference done 11/2336. 0.0679 s / img. ETA=0:02:40
[32m[03/12 13:43:43 d2.evaluation.evaluator]: [0mInference done 89/2336. 0.0638 s / img. ETA=0:02:25
[32m[03/12 13:43:48 d2.evaluation.evaluator]: [0mInference done 167/2336. 0.0637 s / img. ETA=0:02:20
[32m[03/12 13:43:53 d2.evaluation.evaluator]: [0mInference done 245/2336. 0.0636 s / img. ETA=0:02:14
[32m[03/12 13:43:58 d2.evaluation.evaluator]: [0mInference done 323/2336. 0.0635 s / img. ETA=0:02:09
[32m[03/12 13:44:03 d2.evaluation.evaluator]: [0mInference done 401/2336. 0.0635 s / img. ETA=0:02:04
[32m[03/12 13:44:08 d2.evaluation.evaluator]: [0mInference done 479/2336. 0.0636 s / img. ETA=0:01:59
[32m[03/12 13:44:13 d2.evaluation.evaluator]: [0mInference done 557/2336. 0.0636 s / img. ETA=0:01:54
[32m[03/12 13:44:18 d2.evaluation.evaluator]: [0mInference done 635/2336. 0.0636 s / img. ETA=0:01:49
[32m[03/12 13:44:23 d2.evaluation.evaluator]: [0mInference done 713/2336. 0.0636 s / img. ETA=0:01:44
[32m[03/12 13:44:28 d2.evaluation.evaluator]: [0mInference done 789/2336. 0.0638 s / img. ETA=0:01:40
[32m[03/12 13:44:33 d2.evaluation.evaluator]: [0mInference done 865/2336. 0.0639 s / img. ETA=0:01:35
[32m[03/12 13:44:38 d2.evaluation.evaluator]: [0mInference done 941/2336. 0.0640 s / img. ETA=0:01:30
[32m[03/12 13:44:43 d2.evaluation.evaluator]: [0mInference done 1017/2336. 0.0641 s / img. ETA=0:01:25
[32m[03/12 13:44:48 d2.evaluation.evaluator]: [0mInference done 1092/2336. 0.0643 s / img. ETA=0:01:21
[32m[03/12 13:44:53 d2.evaluation.evaluator]: [0mInference done 1166/2336. 0.0644 s / img. ETA=0:01:16
[32m[03/12 13:44:58 d2.evaluation.evaluator]: [0mInference done 1240/2336. 0.0646 s / img. ETA=0:01:11
[32m[03/12 13:45:03 d2.evaluation.evaluator]: [0mInference done 1313/2336. 0.0648 s / img. ETA=0:01:07
[32m[03/12 13:45:08 d2.evaluation.evaluator]: [0mInference done 1388/2336. 0.0649 s / img. ETA=0:01:02
[32m[03/12 13:45:13 d2.evaluation.evaluator]: [0mInference done 1462/2336. 0.0650 s / img. ETA=0:00:57
[32m[03/12 13:45:18 d2.evaluation.evaluator]: [0mInference done 1536/2336. 0.0651 s / img. ETA=0:00:52
[32m[03/12 13:45:23 d2.evaluation.evaluator]: [0mInference done 1610/2336. 0.0652 s / img. ETA=0:00:48
[32m[03/12 13:45:28 d2.evaluation.evaluator]: [0mInference done 1683/2336. 0.0653 s / img. ETA=0:00:43
[32m[03/12 13:45:33 d2.evaluation.evaluator]: [0mInference done 1756/2336. 0.0654 s / img. ETA=0:00:38
[32m[03/12 13:45:39 d2.evaluation.evaluator]: [0mInference done 1830/2336. 0.0655 s / img. ETA=0:00:33
[32m[03/12 13:45:44 d2.evaluation.evaluator]: [0mInference done 1904/2336. 0.0656 s / img. ETA=0:00:28
[32m[03/12 13:45:49 d2.evaluation.evaluator]: [0mInference done 1978/2336. 0.0656 s / img. ETA=0:00:23
[32m[03/12 13:45:54 d2.evaluation.evaluator]: [0mInference done 2052/2336. 0.0657 s / img. ETA=0:00:18
[32m[03/12 13:45:59 d2.evaluation.evaluator]: [0mInference done 2127/2336. 0.0657 s / img. ETA=0:00:13
[32m[03/12 13:46:04 d2.evaluation.evaluator]: [0mInference done 2198/2336. 0.0658 s / img. ETA=0:00:09
[32m[03/12 13:46:09 d2.evaluation.evaluator]: [0mInference done 2272/2336. 0.0659 s / img. ETA=0:00:04
[32m[03/12 13:46:13 d2.evaluation.evaluator]: [0mTotal inference time: 0:02:35.864233 (0.066866 s / img per device, on 1 devices)
[32m[03/12 13:46:13 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:33 (0.065903 s / img per device, on 1 devices)
[32m[03/12 13:46:13 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/12 13:46:13 d2.evaluation.coco_evaluation]: [0mSaving results to ./output/coco_instances_results.json
[32m[03/12 13:46:13 d2.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.02s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=4.03s).
Accumulating evaluation results...
DONE (t=0.41s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.888
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.779
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.427
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.706
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.713
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.726
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.537
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.755
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.891
[32m[03/12 13:46:18 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 67.109 | 88.757 | 77.882 | 42.706 | 70.591 | 84.985 |
[32m[03/12 13:46:18 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP   | category   | AP     | category   | AP     |
|:-----------|:-----|:-----------|:-------|:-----------|:-------|
| None       | nan  | Car        | 73.656 | Pedestrian | 60.562 |
