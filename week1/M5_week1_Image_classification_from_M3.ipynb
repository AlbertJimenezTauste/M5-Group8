{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "M5 week1 - Image classification from M3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6LVjQ2vMTx5",
        "colab_type": "text"
      },
      "source": [
        "**M5:** Image classification from M3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuvuMDuCZ5ox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1076720e-e3b8-478e-90c9-9af55b7951a7"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm1fVyiCcRaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!unzip /content/drive/My\\ Drive/Colab\\ Notebooks/MCV/M3/MIT_split.zip -d /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CazEarl0ITF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example NN (working, acc=0.6)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ExampleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBzLFofVMJg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First approach:\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Create our custom class for the NN\n",
        "class ClassificationNN(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super(ClassificationNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.num_classes = num_classes\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.conv1 = nn.Conv2d(3, 64, 3)\n",
        "    self.bn64 = nn.BatchNorm2d(64)\n",
        "    self.bn32 = nn.BatchNorm2d(32)\n",
        "    self.bn = nn.BatchNorm2d(16)\n",
        "    self.conv2 = nn.Conv2d(64, 32, 1)\n",
        "    self.conv3 = nn.Conv2d(32, 32, 3)\n",
        "    self.conv4 = nn.Conv2d(32, 16, 1)\n",
        "    self.conv5 = nn.Conv2d(16, 32, 3)\n",
        "    self.conv6 = nn.Conv2d(32, 16, 3)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc = nn.Linear(16,8)\n",
        "    self.avgpool = nn.AvgPool2d(24)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.bn64(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.bn32(x)\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = F.relu(self.conv5(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.bn32(x)\n",
        "    x = F.relu(self.conv6(x))\n",
        "    x = self.avgpool(x)\n",
        "    x = self.bn(x)\n",
        "    x = x.view(-1,16)\n",
        "    x = self.fc(x)\n",
        "    output = self.softmax(x)\n",
        "    return(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07zzgzCPXjys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomResidualNetwork(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "      super(CustomResidualNetwork, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=2, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(32)\n",
        "      self.conv2 = nn.Conv2d(32, 32, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "      self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=2, bias=False)\n",
        "      self.fc = nn.Linear(32,num_classes)\n",
        "      self.globalAveragePool = nn.AvgPool2d(int(input_size/4))\n",
        "\n",
        "  def forward(self, x):\n",
        "      # First block\n",
        "      out = F.relu(self.bn1(self.conv1(x)))\n",
        "      out = out + self.bn1(self.conv2(out))\n",
        "      out = F.relu(out)\n",
        "\n",
        "      # Second block\n",
        "      out = self.bn1(self.conv3(out))\n",
        "      out = F.relu(out)\n",
        "\n",
        "      # Final layers\n",
        "      out = self.globalAveragePool(out)\n",
        "      out = out.view(out.size(0), -1)\n",
        "      out = self.fc(out)\n",
        "      return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qA3lNd0Y_wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some constants\n",
        "INPUT_SIZE = 64\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 8\n",
        "\n",
        "# Define the NN\n",
        "net = CustomResidualNetwork(INPUT_SIZE, NUM_CLASSES)\n",
        "net.cuda()\n",
        "\n",
        "# Create the dataloaders\n",
        "transform = {\n",
        "        'train': transforms.Compose(\n",
        "            [transforms.Resize([INPUT_SIZE, INPUT_SIZE]),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])]),\n",
        "        'test': transforms.Compose(\n",
        "            [transforms.Resize([INPUT_SIZE, INPUT_SIZE]),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])])\n",
        "        }\n",
        "\n",
        "trainData = torchvision.datasets.ImageFolder(root = 'train', transform=transform['train'])\n",
        "testData = torchvision.datasets.ImageFolder(root = 'test', transform=transform['test'])\n",
        "\n",
        "data_loader_train = torch.utils.data.DataLoader(trainData, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "data_loader_test = torch.utils.data.DataLoader(testData, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFgaU82qYpVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the optimizer\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dXqzt2slfyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c953903-8c8d-4f32-fa79-f1df31d6421d"
      },
      "source": [
        "# Check the tensor size\n",
        "for i, data in enumerate(data_loader_train, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "    print(np.shape(inputs))\n",
        "    break"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 64, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsR7u3lOYslV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce46415d-2085-439f-a234-cf98b82e1c4a"
      },
      "source": [
        "# TRAINING #\n",
        "NUM_EPOCHS = 150\n",
        "\n",
        "hist_train_loss = []\n",
        "hist_train_acc = []\n",
        "hist_val_loss = []\n",
        "hist_val_acc = []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
        "    epoch_train_loss = 0.0\n",
        "    epoch_train_acc = 0.0\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    val_acc = 0.0\n",
        "    for i, data in enumerate(data_loader_train, 0):\n",
        "        #net.train()\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute statistics\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        batch_acc = (predicted == labels).sum().item()/BATCH_SIZE\n",
        "        train_acc += batch_acc\n",
        "        epoch_train_loss += loss.item()\n",
        "        epoch_train_acc += batch_acc\n",
        "        if i % 10 == 9:    # log every 10 mini-batches\n",
        "            print('[%d, %5d] Train loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, train_loss / 10))\n",
        "            print('[%d, %5d] Train acc: %.3f' %\n",
        "                  (epoch + 1, i + 1, train_acc / 10))\n",
        "            train_loss = 0.0\n",
        "            train_acc = 0.0\n",
        "        exp_lr_scheduler.step()\n",
        "    \n",
        "    # Pass through the validation data and log the results\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0\n",
        "    net.eval()\n",
        "    for data in data_loader_test:\n",
        "        images, labels = data\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = net(images)\n",
        "        vloss = criterion(outputs, labels)\n",
        "        val_loss += vloss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    hist_val_acc.append(correct/total)\n",
        "    hist_val_loss.append(val_loss/len(data_loader_test))\n",
        "    hist_train_acc.append(epoch_train_acc/len(data_loader_train))\n",
        "    hist_train_loss.append(epoch_train_loss/len(data_loader_train))\n",
        "    print(\"Epoch train accuracy \", epoch_train_acc/len(data_loader_train))\n",
        "    print(\"Epoch val accuracy \", correct/total)\n",
        "\n",
        "\n",
        "print('Finished Training, plotting history...')\n",
        "\n",
        "plt.title('Loss')\n",
        "plt.plot(hist_train_loss)\n",
        "plt.plot(hist_val_loss)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Accuracy')\n",
        "plt.plot(hist_train_acc)\n",
        "plt.plot(hist_val_acc)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,    10] Train loss: 1.955\n",
            "[1,    10] Train acc: 0.281\n",
            "[1,    20] Train loss: 1.787\n",
            "[1,    20] Train acc: 0.316\n",
            "[1,    30] Train loss: 1.743\n",
            "[1,    30] Train acc: 0.334\n",
            "[1,    40] Train loss: 1.645\n",
            "[1,    40] Train acc: 0.391\n",
            "[1,    50] Train loss: 1.499\n",
            "[1,    50] Train acc: 0.491\n",
            "Epoch train accuracy  0.37823275862068967\n",
            "Epoch val accuracy  0.19454770755885997\n",
            "[2,    10] Train loss: 1.889\n",
            "[2,    10] Train acc: 0.237\n",
            "[2,    20] Train loss: 1.765\n",
            "[2,    20] Train acc: 0.347\n",
            "[2,    30] Train loss: 1.721\n",
            "[2,    30] Train acc: 0.353\n",
            "[2,    40] Train loss: 1.554\n",
            "[2,    40] Train acc: 0.447\n",
            "[2,    50] Train loss: 1.598\n",
            "[2,    50] Train acc: 0.416\n",
            "Epoch train accuracy  0.3739224137931034\n",
            "Epoch val accuracy  0.45229244114002476\n",
            "[3,    10] Train loss: 1.529\n",
            "[3,    10] Train acc: 0.431\n",
            "[3,    20] Train loss: 1.516\n",
            "[3,    20] Train acc: 0.422\n",
            "[3,    30] Train loss: 1.606\n",
            "[3,    30] Train acc: 0.403\n",
            "[3,    40] Train loss: 1.476\n",
            "[3,    40] Train acc: 0.494\n",
            "[3,    50] Train loss: 1.440\n",
            "[3,    50] Train acc: 0.537\n",
            "Epoch train accuracy  0.47198275862068967\n",
            "Epoch val accuracy  0.516728624535316\n",
            "[4,    10] Train loss: 1.359\n",
            "[4,    10] Train acc: 0.537\n",
            "[4,    20] Train loss: 1.289\n",
            "[4,    20] Train acc: 0.541\n",
            "[4,    30] Train loss: 1.392\n",
            "[4,    30] Train acc: 0.516\n",
            "[4,    40] Train loss: 1.304\n",
            "[4,    40] Train acc: 0.481\n",
            "[4,    50] Train loss: 1.313\n",
            "[4,    50] Train acc: 0.534\n",
            "Epoch train accuracy  0.5258620689655172\n",
            "Epoch val accuracy  0.5439900867410161\n",
            "[5,    10] Train loss: 1.337\n",
            "[5,    10] Train acc: 0.506\n",
            "[5,    20] Train loss: 1.241\n",
            "[5,    20] Train acc: 0.531\n",
            "[5,    30] Train loss: 1.220\n",
            "[5,    30] Train acc: 0.534\n",
            "[5,    40] Train loss: 1.094\n",
            "[5,    40] Train acc: 0.647\n",
            "[5,    50] Train loss: 1.260\n",
            "[5,    50] Train acc: 0.531\n",
            "Epoch train accuracy  0.5431034482758621\n",
            "Epoch val accuracy  0.5613382899628253\n",
            "[6,    10] Train loss: 1.185\n",
            "[6,    10] Train acc: 0.566\n",
            "[6,    20] Train loss: 1.198\n",
            "[6,    20] Train acc: 0.556\n",
            "[6,    30] Train loss: 1.154\n",
            "[6,    30] Train acc: 0.625\n",
            "[6,    40] Train loss: 1.177\n",
            "[6,    40] Train acc: 0.584\n",
            "[6,    50] Train loss: 1.177\n",
            "[6,    50] Train acc: 0.556\n",
            "Epoch train accuracy  0.5754310344827587\n",
            "Epoch val accuracy  0.5551425030978935\n",
            "[7,    10] Train loss: 1.237\n",
            "[7,    10] Train acc: 0.519\n",
            "[7,    20] Train loss: 1.198\n",
            "[7,    20] Train acc: 0.566\n",
            "[7,    30] Train loss: 1.136\n",
            "[7,    30] Train acc: 0.591\n",
            "[7,    40] Train loss: 1.124\n",
            "[7,    40] Train acc: 0.600\n",
            "[7,    50] Train loss: 1.049\n",
            "[7,    50] Train acc: 0.603\n",
            "Epoch train accuracy  0.5818965517241379\n",
            "Epoch val accuracy  0.6009913258983891\n",
            "[8,    10] Train loss: 1.168\n",
            "[8,    10] Train acc: 0.588\n",
            "[8,    20] Train loss: 1.065\n",
            "[8,    20] Train acc: 0.581\n",
            "[8,    30] Train loss: 1.137\n",
            "[8,    30] Train acc: 0.591\n",
            "[8,    40] Train loss: 1.026\n",
            "[8,    40] Train acc: 0.606\n",
            "[8,    50] Train loss: 1.298\n",
            "[8,    50] Train acc: 0.550\n",
            "Epoch train accuracy  0.5867456896551724\n",
            "Epoch val accuracy  0.5774473358116481\n",
            "[9,    10] Train loss: 1.303\n",
            "[9,    10] Train acc: 0.537\n",
            "[9,    20] Train loss: 1.135\n",
            "[9,    20] Train acc: 0.553\n",
            "[9,    30] Train loss: 1.089\n",
            "[9,    30] Train acc: 0.603\n",
            "[9,    40] Train loss: 1.107\n",
            "[9,    40] Train acc: 0.613\n",
            "[9,    50] Train loss: 1.022\n",
            "[9,    50] Train acc: 0.656\n",
            "Epoch train accuracy  0.5835129310344828\n",
            "Epoch val accuracy  0.6294919454770755\n",
            "[10,    10] Train loss: 1.116\n",
            "[10,    10] Train acc: 0.597\n",
            "[10,    20] Train loss: 1.044\n",
            "[10,    20] Train acc: 0.656\n",
            "[10,    30] Train loss: 1.105\n",
            "[10,    30] Train acc: 0.588\n",
            "[10,    40] Train loss: 1.132\n",
            "[10,    40] Train acc: 0.600\n",
            "[10,    50] Train loss: 1.083\n",
            "[10,    50] Train acc: 0.622\n",
            "Epoch train accuracy  0.615301724137931\n",
            "Epoch val accuracy  0.6158612143742255\n",
            "[11,    10] Train loss: 0.997\n",
            "[11,    10] Train acc: 0.650\n",
            "[11,    20] Train loss: 0.982\n",
            "[11,    20] Train acc: 0.666\n",
            "[11,    30] Train loss: 1.087\n",
            "[11,    30] Train acc: 0.600\n",
            "[11,    40] Train loss: 1.125\n",
            "[11,    40] Train acc: 0.581\n",
            "[11,    50] Train loss: 1.065\n",
            "[11,    50] Train acc: 0.609\n",
            "Epoch train accuracy  0.6136853448275862\n",
            "Epoch val accuracy  0.6059479553903345\n",
            "[12,    10] Train loss: 1.043\n",
            "[12,    10] Train acc: 0.659\n",
            "[12,    20] Train loss: 1.055\n",
            "[12,    20] Train acc: 0.600\n",
            "[12,    30] Train loss: 1.056\n",
            "[12,    30] Train acc: 0.613\n",
            "[12,    40] Train loss: 1.014\n",
            "[12,    40] Train acc: 0.594\n",
            "[12,    50] Train loss: 1.047\n",
            "[12,    50] Train acc: 0.637\n",
            "Epoch train accuracy  0.6260775862068966\n",
            "Epoch val accuracy  0.6294919454770755\n",
            "[13,    10] Train loss: 0.999\n",
            "[13,    10] Train acc: 0.637\n",
            "[13,    20] Train loss: 0.896\n",
            "[13,    20] Train acc: 0.706\n",
            "[13,    30] Train loss: 0.951\n",
            "[13,    30] Train acc: 0.666\n",
            "[13,    40] Train loss: 0.845\n",
            "[13,    40] Train acc: 0.697\n",
            "[13,    50] Train loss: 0.950\n",
            "[13,    50] Train acc: 0.659\n",
            "Epoch train accuracy  0.6670258620689655\n",
            "Epoch val accuracy  0.6840148698884758\n",
            "[14,    10] Train loss: 0.966\n",
            "[14,    10] Train acc: 0.656\n",
            "[14,    20] Train loss: 0.937\n",
            "[14,    20] Train acc: 0.644\n",
            "[14,    30] Train loss: 0.885\n",
            "[14,    30] Train acc: 0.703\n",
            "[14,    40] Train loss: 0.805\n",
            "[14,    40] Train acc: 0.706\n",
            "[14,    50] Train loss: 0.880\n",
            "[14,    50] Train acc: 0.700\n",
            "Epoch train accuracy  0.6880387931034483\n",
            "Epoch val accuracy  0.7137546468401487\n",
            "[15,    10] Train loss: 0.759\n",
            "[15,    10] Train acc: 0.769\n",
            "[15,    20] Train loss: 0.764\n",
            "[15,    20] Train acc: 0.725\n",
            "[15,    30] Train loss: 0.832\n",
            "[15,    30] Train acc: 0.734\n",
            "[15,    40] Train loss: 0.967\n",
            "[15,    40] Train acc: 0.675\n",
            "[15,    50] Train loss: 0.747\n",
            "[15,    50] Train acc: 0.744\n",
            "Epoch train accuracy  0.7219827586206896\n",
            "Epoch val accuracy  0.6827757125154895\n",
            "[16,    10] Train loss: 0.759\n",
            "[16,    10] Train acc: 0.713\n",
            "[16,    20] Train loss: 0.808\n",
            "[16,    20] Train acc: 0.719\n",
            "[16,    30] Train loss: 0.823\n",
            "[16,    30] Train acc: 0.688\n",
            "[16,    40] Train loss: 0.867\n",
            "[16,    40] Train acc: 0.716\n",
            "[16,    50] Train loss: 0.688\n",
            "[16,    50] Train acc: 0.747\n",
            "Epoch train accuracy  0.7198275862068966\n",
            "Epoch val accuracy  0.7137546468401487\n",
            "[17,    10] Train loss: 0.751\n",
            "[17,    10] Train acc: 0.722\n",
            "[17,    20] Train loss: 0.713\n",
            "[17,    20] Train acc: 0.791\n",
            "[17,    30] Train loss: 0.686\n",
            "[17,    30] Train acc: 0.756\n",
            "[17,    40] Train loss: 0.828\n",
            "[17,    40] Train acc: 0.719\n",
            "[17,    50] Train loss: 0.760\n",
            "[17,    50] Train acc: 0.716\n",
            "Epoch train accuracy  0.7359913793103449\n",
            "Epoch val accuracy  0.7273853779429987\n",
            "[18,    10] Train loss: 0.686\n",
            "[18,    10] Train acc: 0.756\n",
            "[18,    20] Train loss: 0.752\n",
            "[18,    20] Train acc: 0.747\n",
            "[18,    30] Train loss: 0.670\n",
            "[18,    30] Train acc: 0.803\n",
            "[18,    40] Train loss: 0.696\n",
            "[18,    40] Train acc: 0.769\n",
            "[18,    50] Train loss: 0.654\n",
            "[18,    50] Train acc: 0.772\n",
            "Epoch train accuracy  0.7677801724137931\n",
            "Epoch val accuracy  0.7682775712515489\n",
            "[19,    10] Train loss: 0.686\n",
            "[19,    10] Train acc: 0.744\n",
            "[19,    20] Train loss: 0.683\n",
            "[19,    20] Train acc: 0.766\n",
            "[19,    30] Train loss: 0.683\n",
            "[19,    30] Train acc: 0.778\n",
            "[19,    40] Train loss: 0.691\n",
            "[19,    40] Train acc: 0.759\n",
            "[19,    50] Train loss: 0.717\n",
            "[19,    50] Train acc: 0.775\n",
            "Epoch train accuracy  0.7677801724137931\n",
            "Epoch val accuracy  0.7472118959107806\n",
            "[20,    10] Train loss: 0.651\n",
            "[20,    10] Train acc: 0.787\n",
            "[20,    20] Train loss: 0.723\n",
            "[20,    20] Train acc: 0.769\n",
            "[20,    30] Train loss: 0.597\n",
            "[20,    30] Train acc: 0.784\n",
            "[20,    40] Train loss: 0.620\n",
            "[20,    40] Train acc: 0.791\n",
            "[20,    50] Train loss: 0.626\n",
            "[20,    50] Train acc: 0.794\n",
            "Epoch train accuracy  0.7780172413793104\n",
            "Epoch val accuracy  0.7546468401486989\n",
            "[21,    10] Train loss: 0.618\n",
            "[21,    10] Train acc: 0.769\n",
            "[21,    20] Train loss: 0.648\n",
            "[21,    20] Train acc: 0.809\n",
            "[21,    30] Train loss: 0.662\n",
            "[21,    30] Train acc: 0.787\n",
            "[21,    40] Train loss: 0.703\n",
            "[21,    40] Train acc: 0.762\n",
            "[21,    50] Train loss: 0.685\n",
            "[21,    50] Train acc: 0.734\n",
            "Epoch train accuracy  0.7726293103448276\n",
            "Epoch val accuracy  0.7732342007434945\n",
            "[22,    10] Train loss: 0.568\n",
            "[22,    10] Train acc: 0.809\n",
            "[22,    20] Train loss: 0.639\n",
            "[22,    20] Train acc: 0.775\n",
            "[22,    30] Train loss: 0.613\n",
            "[22,    30] Train acc: 0.809\n",
            "[22,    40] Train loss: 0.746\n",
            "[22,    40] Train acc: 0.784\n",
            "[22,    50] Train loss: 0.770\n",
            "[22,    50] Train acc: 0.719\n",
            "Epoch train accuracy  0.7774784482758621\n",
            "Epoch val accuracy  0.7596034696406444\n",
            "[23,    10] Train loss: 0.661\n",
            "[23,    10] Train acc: 0.750\n",
            "[23,    20] Train loss: 0.645\n",
            "[23,    20] Train acc: 0.806\n",
            "[23,    30] Train loss: 0.671\n",
            "[23,    30] Train acc: 0.759\n",
            "[23,    40] Train loss: 0.625\n",
            "[23,    40] Train acc: 0.787\n",
            "[23,    50] Train loss: 0.559\n",
            "[23,    50] Train acc: 0.812\n",
            "Epoch train accuracy  0.7850215517241379\n",
            "Epoch val accuracy  0.7868649318463445\n",
            "[24,    10] Train loss: 0.565\n",
            "[24,    10] Train acc: 0.816\n",
            "[24,    20] Train loss: 0.713\n",
            "[24,    20] Train acc: 0.747\n",
            "[24,    30] Train loss: 0.551\n",
            "[24,    30] Train acc: 0.775\n",
            "[24,    40] Train loss: 0.665\n",
            "[24,    40] Train acc: 0.797\n",
            "[24,    50] Train loss: 0.568\n",
            "[24,    50] Train acc: 0.819\n",
            "Epoch train accuracy  0.7882543103448276\n",
            "Epoch val accuracy  0.7893432465923172\n",
            "[25,    10] Train loss: 0.626\n",
            "[25,    10] Train acc: 0.787\n",
            "[25,    20] Train loss: 0.503\n",
            "[25,    20] Train acc: 0.806\n",
            "[25,    30] Train loss: 0.691\n",
            "[25,    30] Train acc: 0.750\n",
            "[25,    40] Train loss: 0.628\n",
            "[25,    40] Train acc: 0.838\n",
            "[25,    50] Train loss: 0.616\n",
            "[25,    50] Train acc: 0.791\n",
            "Epoch train accuracy  0.7898706896551724\n",
            "Epoch val accuracy  0.7942998760842627\n",
            "[26,    10] Train loss: 0.678\n",
            "[26,    10] Train acc: 0.753\n",
            "[26,    20] Train loss: 0.481\n",
            "[26,    20] Train acc: 0.809\n",
            "[26,    30] Train loss: 0.575\n",
            "[26,    30] Train acc: 0.787\n",
            "[26,    40] Train loss: 0.580\n",
            "[26,    40] Train acc: 0.822\n",
            "[26,    50] Train loss: 0.632\n",
            "[26,    50] Train acc: 0.766\n",
            "Epoch train accuracy  0.7904094827586207\n",
            "Epoch val accuracy  0.8017348203221809\n",
            "[27,    10] Train loss: 0.546\n",
            "[27,    10] Train acc: 0.834\n",
            "[27,    20] Train loss: 0.616\n",
            "[27,    20] Train acc: 0.794\n",
            "[27,    30] Train loss: 0.610\n",
            "[27,    30] Train acc: 0.778\n",
            "[27,    40] Train loss: 0.554\n",
            "[27,    40] Train acc: 0.822\n",
            "[27,    50] Train loss: 0.554\n",
            "[27,    50] Train acc: 0.822\n",
            "Epoch train accuracy  0.8017241379310345\n",
            "Epoch val accuracy  0.7620817843866171\n",
            "[28,    10] Train loss: 0.606\n",
            "[28,    10] Train acc: 0.781\n",
            "[28,    20] Train loss: 0.482\n",
            "[28,    20] Train acc: 0.834\n",
            "[28,    30] Train loss: 0.615\n",
            "[28,    30] Train acc: 0.791\n",
            "[28,    40] Train loss: 0.667\n",
            "[28,    40] Train acc: 0.772\n",
            "[28,    50] Train loss: 0.575\n",
            "[28,    50] Train acc: 0.812\n",
            "[29,    10] Train loss: 0.473\n",
            "[29,    10] Train acc: 0.847\n",
            "[29,    20] Train loss: 0.551\n",
            "[29,    20] Train acc: 0.844\n",
            "[29,    30] Train loss: 0.501\n",
            "[29,    30] Train acc: 0.800\n",
            "[29,    40] Train loss: 0.565\n",
            "[29,    40] Train acc: 0.800\n",
            "[29,    50] Train loss: 0.564\n",
            "[29,    50] Train acc: 0.797\n",
            "Epoch train accuracy  0.8146551724137931\n",
            "Epoch val accuracy  0.7980173482032218\n",
            "[30,    10] Train loss: 0.498\n",
            "[30,    10] Train acc: 0.822\n",
            "[30,    20] Train loss: 0.506\n",
            "[30,    20] Train acc: 0.809\n",
            "[30,    30] Train loss: 0.536\n",
            "[30,    30] Train acc: 0.838\n",
            "[30,    40] Train loss: 0.624\n",
            "[30,    40] Train acc: 0.775\n",
            "[30,    50] Train loss: 0.598\n",
            "[30,    50] Train acc: 0.809\n",
            "Epoch train accuracy  0.8076508620689655\n",
            "Epoch val accuracy  0.7695167286245354\n",
            "[31,    10] Train loss: 0.628\n",
            "[31,    10] Train acc: 0.797\n",
            "[31,    20] Train loss: 0.582\n",
            "[31,    20] Train acc: 0.772\n",
            "[31,    30] Train loss: 0.644\n",
            "[31,    30] Train acc: 0.772\n",
            "[31,    40] Train loss: 0.555\n",
            "[31,    40] Train acc: 0.819\n",
            "[31,    50] Train loss: 0.510\n",
            "[31,    50] Train acc: 0.838\n",
            "Epoch train accuracy  0.8033405172413793\n",
            "Epoch val accuracy  0.8042131350681536\n",
            "[32,    10] Train loss: 0.475\n",
            "[32,    10] Train acc: 0.834\n",
            "[32,    20] Train loss: 0.607\n",
            "[32,    20] Train acc: 0.806\n",
            "[32,    30] Train loss: 0.450\n",
            "[32,    30] Train acc: 0.856\n",
            "[32,    40] Train loss: 0.597\n",
            "[32,    40] Train acc: 0.809\n",
            "[32,    50] Train loss: 0.490\n",
            "[32,    50] Train acc: 0.800\n",
            "Epoch train accuracy  0.8195043103448276\n",
            "Epoch val accuracy  0.7967781908302355\n",
            "[33,    10] Train loss: 0.531\n",
            "[33,    10] Train acc: 0.806\n",
            "[33,    20] Train loss: 0.604\n",
            "[33,    20] Train acc: 0.787\n",
            "[33,    30] Train loss: 0.612\n",
            "[33,    30] Train acc: 0.812\n",
            "[33,    40] Train loss: 0.484\n",
            "[33,    40] Train acc: 0.838\n",
            "[33,    50] Train loss: 0.483\n",
            "[33,    50] Train acc: 0.838\n",
            "Epoch train accuracy  0.8195043103448276\n",
            "Epoch val accuracy  0.7843866171003717\n",
            "[34,    10] Train loss: 0.561\n",
            "[34,    10] Train acc: 0.844\n",
            "[34,    20] Train loss: 0.525\n",
            "[34,    20] Train acc: 0.828\n",
            "[34,    30] Train loss: 0.531\n",
            "[34,    30] Train acc: 0.803\n",
            "[34,    40] Train loss: 0.528\n",
            "[34,    40] Train acc: 0.819\n",
            "[34,    50] Train loss: 0.511\n",
            "[34,    50] Train acc: 0.834\n",
            "Epoch train accuracy  0.828125\n",
            "Epoch val accuracy  0.7905824039653035\n",
            "[35,    10] Train loss: 0.423\n",
            "[35,    10] Train acc: 0.859\n",
            "[35,    20] Train loss: 0.491\n",
            "[35,    20] Train acc: 0.822\n",
            "[35,    30] Train loss: 0.644\n",
            "[35,    30] Train acc: 0.812\n",
            "[35,    40] Train loss: 0.534\n",
            "[35,    40] Train acc: 0.838\n",
            "[35,    50] Train loss: 0.590\n",
            "[35,    50] Train acc: 0.800\n",
            "Epoch train accuracy  0.8243534482758621\n",
            "Epoch val accuracy  0.8029739776951673\n",
            "[36,    10] Train loss: 0.437\n",
            "[36,    10] Train acc: 0.850\n",
            "[36,    20] Train loss: 0.544\n",
            "[36,    20] Train acc: 0.809\n",
            "[36,    30] Train loss: 0.621\n",
            "[36,    30] Train acc: 0.794\n",
            "[36,    40] Train loss: 0.470\n",
            "[36,    40] Train acc: 0.844\n",
            "[36,    50] Train loss: 0.543\n",
            "[36,    50] Train acc: 0.825\n",
            "Epoch train accuracy  0.8302801724137931\n",
            "Epoch val accuracy  0.7868649318463445\n",
            "[37,    10] Train loss: 0.490\n",
            "[37,    10] Train acc: 0.822\n",
            "[37,    20] Train loss: 0.461\n",
            "[37,    20] Train acc: 0.856\n",
            "[37,    30] Train loss: 0.462\n",
            "[37,    30] Train acc: 0.850\n",
            "[37,    40] Train loss: 0.493\n",
            "[37,    40] Train acc: 0.834\n",
            "[37,    50] Train loss: 0.491\n",
            "[37,    50] Train acc: 0.822\n",
            "Epoch train accuracy  0.8362068965517241\n",
            "Epoch val accuracy  0.7905824039653035\n",
            "[38,    10] Train loss: 0.550\n",
            "[38,    10] Train acc: 0.828\n",
            "[38,    20] Train loss: 0.444\n",
            "[38,    20] Train acc: 0.863\n",
            "[38,    30] Train loss: 0.558\n",
            "[38,    30] Train acc: 0.812\n",
            "[38,    40] Train loss: 0.471\n",
            "[38,    40] Train acc: 0.850\n",
            "[38,    50] Train loss: 0.497\n",
            "[38,    50] Train acc: 0.841\n",
            "Epoch train accuracy  0.8383620689655172\n",
            "Epoch val accuracy  0.80545229244114\n",
            "[39,    10] Train loss: 0.370\n",
            "[39,    10] Train acc: 0.863\n",
            "[39,    20] Train loss: 0.515\n",
            "[39,    20] Train acc: 0.806\n",
            "[39,    30] Train loss: 0.568\n",
            "[39,    30] Train acc: 0.787\n",
            "[39,    40] Train loss: 0.503\n",
            "[39,    40] Train acc: 0.828\n",
            "[39,    50] Train loss: 0.547\n",
            "[39,    50] Train acc: 0.828\n",
            "Epoch train accuracy  0.8227370689655172\n",
            "Epoch val accuracy  0.7608426270136307\n",
            "[40,    10] Train loss: 0.440\n",
            "[40,    10] Train acc: 0.841\n",
            "[40,    20] Train loss: 0.397\n",
            "[40,    20] Train acc: 0.900\n",
            "[40,    30] Train loss: 0.476\n",
            "[40,    30] Train acc: 0.844\n",
            "[40,    40] Train loss: 0.508\n",
            "[40,    40] Train acc: 0.800\n",
            "[40,    50] Train loss: 0.492\n",
            "[40,    50] Train acc: 0.828\n",
            "Epoch train accuracy  0.834051724137931\n",
            "Epoch val accuracy  0.7744733581164808\n",
            "[41,    10] Train loss: 0.515\n",
            "[41,    10] Train acc: 0.825\n",
            "[41,    20] Train loss: 0.447\n",
            "[41,    20] Train acc: 0.850\n",
            "[41,    30] Train loss: 0.422\n",
            "[41,    30] Train acc: 0.844\n",
            "[41,    40] Train loss: 0.537\n",
            "[41,    40] Train acc: 0.831\n",
            "[41,    50] Train loss: 0.500\n",
            "[41,    50] Train acc: 0.816\n",
            "Epoch train accuracy  0.8313577586206896\n",
            "Epoch val accuracy  0.8166047087980174\n",
            "[42,    10] Train loss: 0.533\n",
            "[42,    10] Train acc: 0.828\n",
            "[42,    20] Train loss: 0.483\n",
            "[42,    20] Train acc: 0.812\n",
            "[42,    30] Train loss: 0.397\n",
            "[42,    30] Train acc: 0.853\n",
            "[42,    40] Train loss: 0.414\n",
            "[42,    40] Train acc: 0.894\n",
            "[42,    50] Train loss: 0.407\n",
            "[42,    50] Train acc: 0.844\n",
            "Epoch train accuracy  0.8459051724137931\n",
            "Epoch val accuracy  0.7856257744733581\n",
            "[43,    10] Train loss: 0.487\n",
            "[43,    10] Train acc: 0.819\n",
            "[43,    20] Train loss: 0.389\n",
            "[43,    20] Train acc: 0.878\n",
            "[43,    30] Train loss: 0.303\n",
            "[43,    30] Train acc: 0.903\n",
            "[43,    40] Train loss: 0.424\n",
            "[43,    40] Train acc: 0.847\n",
            "[43,    50] Train loss: 0.614\n",
            "[43,    50] Train acc: 0.775\n",
            "Epoch train accuracy  0.8426724137931034\n",
            "Epoch val accuracy  0.7893432465923172\n",
            "[44,    10] Train loss: 0.517\n",
            "[44,    10] Train acc: 0.831\n",
            "[44,    20] Train loss: 0.480\n",
            "[44,    20] Train acc: 0.847\n",
            "[44,    30] Train loss: 0.453\n",
            "[44,    30] Train acc: 0.850\n",
            "[44,    40] Train loss: 0.458\n",
            "[44,    40] Train acc: 0.844\n",
            "[44,    50] Train loss: 0.446\n",
            "[44,    50] Train acc: 0.841\n",
            "Epoch train accuracy  0.8448275862068966\n",
            "Epoch val accuracy  0.8190830235439901\n",
            "[45,    10] Train loss: 0.327\n",
            "[45,    10] Train acc: 0.891\n",
            "[45,    20] Train loss: 0.446\n",
            "[45,    20] Train acc: 0.841\n",
            "[45,    30] Train loss: 0.476\n",
            "[45,    30] Train acc: 0.869\n",
            "[45,    40] Train loss: 0.479\n",
            "[45,    40] Train acc: 0.856\n",
            "[45,    50] Train loss: 0.500\n",
            "[45,    50] Train acc: 0.828\n",
            "Epoch train accuracy  0.8588362068965517\n",
            "Epoch val accuracy  0.7657992565055762\n",
            "[46,    10] Train loss: 0.357\n",
            "[46,    10] Train acc: 0.900\n",
            "[46,    20] Train loss: 0.405\n",
            "[46,    20] Train acc: 0.847\n",
            "[46,    30] Train loss: 0.491\n",
            "[46,    30] Train acc: 0.834\n",
            "[46,    40] Train loss: 0.413\n",
            "[46,    40] Train acc: 0.875\n",
            "[46,    50] Train loss: 0.508\n",
            "[46,    50] Train acc: 0.844\n",
            "Epoch train accuracy  0.8556034482758621\n",
            "Epoch val accuracy  0.7744733581164808\n",
            "[47,    10] Train loss: 0.468\n",
            "[47,    10] Train acc: 0.863\n",
            "[47,    20] Train loss: 0.387\n",
            "[47,    20] Train acc: 0.859\n",
            "[47,    30] Train loss: 0.370\n",
            "[47,    30] Train acc: 0.878\n",
            "[47,    40] Train loss: 0.384\n",
            "[47,    40] Train acc: 0.866\n",
            "[47,    50] Train loss: 0.431\n",
            "[47,    50] Train acc: 0.838\n",
            "Epoch train accuracy  0.8604525862068966\n",
            "Epoch val accuracy  0.7992565055762082\n",
            "[48,    10] Train loss: 0.437\n",
            "[48,    10] Train acc: 0.863\n",
            "[48,    20] Train loss: 0.454\n",
            "[48,    20] Train acc: 0.866\n",
            "[48,    30] Train loss: 0.425\n",
            "[48,    30] Train acc: 0.834\n",
            "[48,    40] Train loss: 0.412\n",
            "[48,    40] Train acc: 0.863\n",
            "[48,    50] Train loss: 0.443\n",
            "[48,    50] Train acc: 0.875\n",
            "Epoch train accuracy  0.8577586206896551\n",
            "Epoch val accuracy  0.7992565055762082\n",
            "[49,    10] Train loss: 0.382\n",
            "[49,    10] Train acc: 0.850\n",
            "[49,    20] Train loss: 0.458\n",
            "[49,    20] Train acc: 0.838\n",
            "[49,    30] Train loss: 0.319\n",
            "[49,    30] Train acc: 0.887\n",
            "[49,    40] Train loss: 0.406\n",
            "[49,    40] Train acc: 0.869\n",
            "[49,    50] Train loss: 0.423\n",
            "[49,    50] Train acc: 0.844\n",
            "Epoch train accuracy  0.8572198275862069\n",
            "Epoch val accuracy  0.8116480793060719\n",
            "[50,    10] Train loss: 0.273\n",
            "[50,    10] Train acc: 0.922\n",
            "[50,    20] Train loss: 0.393\n",
            "[50,    20] Train acc: 0.856\n",
            "[50,    30] Train loss: 0.362\n",
            "[50,    30] Train acc: 0.869\n",
            "[50,    40] Train loss: 0.319\n",
            "[50,    40] Train acc: 0.897\n",
            "[50,    50] Train loss: 0.452\n",
            "[50,    50] Train acc: 0.831\n",
            "Epoch train accuracy  0.8674568965517241\n",
            "Epoch val accuracy  0.80545229244114\n",
            "[51,    10] Train loss: 0.322\n",
            "[51,    10] Train acc: 0.887\n",
            "[51,    20] Train loss: 0.396\n",
            "[51,    20] Train acc: 0.859\n",
            "[51,    30] Train loss: 0.400\n",
            "[51,    30] Train acc: 0.853\n",
            "[51,    40] Train loss: 0.382\n",
            "[51,    40] Train acc: 0.872\n",
            "[51,    50] Train loss: 0.527\n",
            "[51,    50] Train acc: 0.838\n",
            "Epoch train accuracy  0.8626077586206896\n",
            "Epoch val accuracy  0.79182156133829\n",
            "[52,    10] Train loss: 0.355\n",
            "[52,    10] Train acc: 0.881\n",
            "[52,    20] Train loss: 0.416\n",
            "[52,    20] Train acc: 0.872\n",
            "[52,    30] Train loss: 0.402\n",
            "[52,    30] Train acc: 0.869\n",
            "[52,    40] Train loss: 0.322\n",
            "[52,    40] Train acc: 0.875\n",
            "[52,    50] Train loss: 0.407\n",
            "[52,    50] Train acc: 0.869\n",
            "Epoch train accuracy  0.8728448275862069\n",
            "Epoch val accuracy  0.8042131350681536\n",
            "[53,    10] Train loss: 0.505\n",
            "[53,    10] Train acc: 0.822\n",
            "[53,    20] Train loss: 0.419\n",
            "[53,    20] Train acc: 0.850\n",
            "[53,    30] Train loss: 0.422\n",
            "[53,    30] Train acc: 0.847\n",
            "[53,    40] Train loss: 0.332\n",
            "[53,    40] Train acc: 0.887\n",
            "[53,    50] Train loss: 0.334\n",
            "[53,    50] Train acc: 0.878\n",
            "Epoch train accuracy  0.8572198275862069\n",
            "Epoch val accuracy  0.7670384138785625\n",
            "[54,    10] Train loss: 0.338\n",
            "[54,    10] Train acc: 0.884\n",
            "[54,    20] Train loss: 0.464\n",
            "[54,    20] Train acc: 0.875\n",
            "[54,    30] Train loss: 0.387\n",
            "[54,    30] Train acc: 0.841\n",
            "[54,    40] Train loss: 0.373\n",
            "[54,    40] Train acc: 0.863\n",
            "[54,    50] Train loss: 0.373\n",
            "[54,    50] Train acc: 0.863\n",
            "Epoch train accuracy  0.8685344827586207\n",
            "Epoch val accuracy  0.8190830235439901\n",
            "[55,    10] Train loss: 0.345\n",
            "[55,    10] Train acc: 0.859\n",
            "[55,    20] Train loss: 0.370\n",
            "[55,    20] Train acc: 0.863\n",
            "[55,    30] Train loss: 0.329\n",
            "[55,    30] Train acc: 0.891\n",
            "[55,    40] Train loss: 0.345\n",
            "[55,    40] Train acc: 0.853\n",
            "[55,    50] Train loss: 0.357\n",
            "[55,    50] Train acc: 0.906\n",
            "Epoch train accuracy  0.8723060344827587\n",
            "Epoch val accuracy  0.8017348203221809\n",
            "[56,    10] Train loss: 0.313\n",
            "[56,    10] Train acc: 0.884\n",
            "[56,    20] Train loss: 0.331\n",
            "[56,    20] Train acc: 0.897\n",
            "[56,    30] Train loss: 0.379\n",
            "[56,    30] Train acc: 0.859\n",
            "[56,    40] Train loss: 0.276\n",
            "[56,    40] Train acc: 0.906\n",
            "[56,    50] Train loss: 0.456\n",
            "[56,    50] Train acc: 0.856\n",
            "Epoch train accuracy  0.8830818965517241\n",
            "Epoch val accuracy  0.7769516728624535\n",
            "[57,    10] Train loss: 0.395\n",
            "[57,    10] Train acc: 0.863\n",
            "[57,    20] Train loss: 0.315\n",
            "[57,    20] Train acc: 0.894\n",
            "[57,    30] Train loss: 0.445\n",
            "[57,    30] Train acc: 0.859\n",
            "[57,    40] Train loss: 0.416\n",
            "[57,    40] Train acc: 0.878\n",
            "[57,    50] Train loss: 0.404\n",
            "[57,    50] Train acc: 0.875\n",
            "Epoch train accuracy  0.8739224137931034\n",
            "Epoch val accuracy  0.8178438661710037\n",
            "[58,    10] Train loss: 0.343\n",
            "[58,    10] Train acc: 0.869\n",
            "[58,    20] Train loss: 0.339\n",
            "[58,    20] Train acc: 0.891\n",
            "[58,    30] Train loss: 0.274\n",
            "[58,    30] Train acc: 0.897\n",
            "[58,    40] Train loss: 0.303\n",
            "[58,    40] Train acc: 0.894\n",
            "[58,    50] Train loss: 0.425\n",
            "[58,    50] Train acc: 0.872\n",
            "Epoch train accuracy  0.8814655172413793\n",
            "Epoch val accuracy  0.7794299876084263\n",
            "[59,    10] Train loss: 0.298\n",
            "[59,    10] Train acc: 0.887\n",
            "[59,    20] Train loss: 0.376\n",
            "[59,    20] Train acc: 0.847\n",
            "[59,    30] Train loss: 0.423\n",
            "[59,    30] Train acc: 0.875\n",
            "[59,    40] Train loss: 0.400\n",
            "[59,    40] Train acc: 0.878\n",
            "[59,    50] Train loss: 0.353\n",
            "[59,    50] Train acc: 0.869\n",
            "Epoch train accuracy  0.8744612068965517\n",
            "Epoch val accuracy  0.8116480793060719\n",
            "[60,    10] Train loss: 0.308\n",
            "[60,    10] Train acc: 0.887\n",
            "[60,    20] Train loss: 0.261\n",
            "[60,    20] Train acc: 0.897\n",
            "[60,    30] Train loss: 0.355\n",
            "[60,    30] Train acc: 0.887\n",
            "[60,    40] Train loss: 0.368\n",
            "[60,    40] Train acc: 0.866\n",
            "[60,    50] Train loss: 0.367\n",
            "[60,    50] Train acc: 0.878\n",
            "Epoch train accuracy  0.8798491379310345\n",
            "Epoch val accuracy  0.8302354399008675\n",
            "[61,    10] Train loss: 0.274\n",
            "[61,    10] Train acc: 0.897\n",
            "[61,    20] Train loss: 0.289\n",
            "[61,    20] Train acc: 0.897\n",
            "[61,    30] Train loss: 0.296\n",
            "[61,    30] Train acc: 0.891\n",
            "[61,    40] Train loss: 0.300\n",
            "[61,    40] Train acc: 0.897\n",
            "[61,    50] Train loss: 0.349\n",
            "[61,    50] Train acc: 0.884\n",
            "Epoch train accuracy  0.8890086206896551\n",
            "Epoch val accuracy  0.8215613382899628\n",
            "[62,    10] Train loss: 0.294\n",
            "[62,    10] Train acc: 0.887\n",
            "[62,    20] Train loss: 0.306\n",
            "[62,    20] Train acc: 0.909\n",
            "[62,    30] Train loss: 0.391\n",
            "[62,    30] Train acc: 0.847\n",
            "[62,    40] Train loss: 0.333\n",
            "[62,    40] Train acc: 0.878\n",
            "[62,    50] Train loss: 0.314\n",
            "[62,    50] Train acc: 0.894\n",
            "Epoch train accuracy  0.884698275862069\n",
            "Epoch val accuracy  0.7930607187112764\n",
            "[63,    10] Train loss: 0.312\n",
            "[63,    10] Train acc: 0.903\n",
            "[63,    20] Train loss: 0.360\n",
            "[63,    20] Train acc: 0.891\n",
            "[63,    30] Train loss: 0.299\n",
            "[63,    30] Train acc: 0.887\n",
            "[63,    40] Train loss: 0.290\n",
            "[63,    40] Train acc: 0.884\n",
            "[63,    50] Train loss: 0.321\n",
            "[63,    50] Train acc: 0.891\n",
            "Epoch train accuracy  0.8868534482758621\n",
            "Epoch val accuracy  0.7930607187112764\n",
            "[64,    10] Train loss: 0.305\n",
            "[64,    10] Train acc: 0.891\n",
            "[64,    20] Train loss: 0.229\n",
            "[64,    20] Train acc: 0.912\n",
            "[64,    30] Train loss: 0.286\n",
            "[64,    30] Train acc: 0.912\n",
            "[64,    40] Train loss: 0.336\n",
            "[64,    40] Train acc: 0.891\n",
            "[64,    50] Train loss: 0.338\n",
            "[64,    50] Train acc: 0.872\n",
            "Epoch train accuracy  0.8890086206896551\n",
            "Epoch val accuracy  0.8203221809169765\n",
            "[65,    10] Train loss: 0.254\n",
            "[65,    10] Train acc: 0.938\n",
            "[65,    20] Train loss: 0.239\n",
            "[65,    20] Train acc: 0.922\n",
            "[65,    30] Train loss: 0.251\n",
            "[65,    30] Train acc: 0.909\n",
            "[65,    40] Train loss: 0.363\n",
            "[65,    40] Train acc: 0.891\n",
            "[65,    50] Train loss: 0.256\n",
            "[65,    50] Train acc: 0.894\n",
            "Epoch train accuracy  0.9084051724137931\n",
            "Epoch val accuracy  0.8104089219330854\n",
            "[66,    10] Train loss: 0.294\n",
            "[66,    10] Train acc: 0.884\n",
            "[66,    20] Train loss: 0.273\n",
            "[66,    20] Train acc: 0.900\n",
            "[66,    30] Train loss: 0.318\n",
            "[66,    30] Train acc: 0.919\n",
            "[66,    40] Train loss: 0.321\n",
            "[66,    40] Train acc: 0.878\n",
            "[66,    50] Train loss: 0.299\n",
            "[66,    50] Train acc: 0.900\n",
            "Epoch train accuracy  0.8938577586206896\n",
            "Epoch val accuracy  0.8066914498141264\n",
            "[67,    10] Train loss: 0.236\n",
            "[67,    10] Train acc: 0.928\n",
            "[67,    20] Train loss: 0.297\n",
            "[67,    20] Train acc: 0.909\n",
            "[67,    30] Train loss: 0.284\n",
            "[67,    30] Train acc: 0.903\n",
            "[67,    40] Train loss: 0.356\n",
            "[67,    40] Train acc: 0.884\n",
            "[67,    50] Train loss: 0.296\n",
            "[67,    50] Train acc: 0.912\n",
            "Epoch train accuracy  0.9084051724137931\n",
            "Epoch val accuracy  0.7992565055762082\n",
            "[68,    10] Train loss: 0.298\n",
            "[68,    10] Train acc: 0.884\n",
            "[68,    20] Train loss: 0.282\n",
            "[68,    20] Train acc: 0.900\n",
            "[68,    30] Train loss: 0.218\n",
            "[68,    30] Train acc: 0.931\n",
            "[68,    40] Train loss: 0.304\n",
            "[68,    40] Train acc: 0.909\n",
            "[68,    50] Train loss: 0.266\n",
            "[68,    50] Train acc: 0.906\n",
            "Epoch train accuracy  0.9008620689655172\n",
            "Epoch val accuracy  0.8178438661710037\n",
            "[69,    10] Train loss: 0.224\n",
            "[69,    10] Train acc: 0.925\n",
            "[69,    20] Train loss: 0.245\n",
            "[69,    20] Train acc: 0.919\n",
            "[69,    30] Train loss: 0.279\n",
            "[69,    30] Train acc: 0.900\n",
            "[69,    40] Train loss: 0.226\n",
            "[69,    40] Train acc: 0.919\n",
            "[69,    50] Train loss: 0.291\n",
            "[69,    50] Train acc: 0.900\n",
            "Epoch train accuracy  0.90625\n",
            "Epoch val accuracy  0.8190830235439901\n",
            "[70,    10] Train loss: 0.199\n",
            "[70,    10] Train acc: 0.941\n",
            "[70,    20] Train loss: 0.365\n",
            "[70,    20] Train acc: 0.884\n",
            "[70,    30] Train loss: 0.229\n",
            "[70,    30] Train acc: 0.922\n",
            "[70,    40] Train loss: 0.285\n",
            "[70,    40] Train acc: 0.906\n",
            "[70,    50] Train loss: 0.304\n",
            "[70,    50] Train acc: 0.891\n",
            "Epoch train accuracy  0.9094827586206896\n",
            "Epoch val accuracy  0.8141263940520446\n",
            "[71,    10] Train loss: 0.201\n",
            "[71,    10] Train acc: 0.934\n",
            "[71,    20] Train loss: 0.282\n",
            "[71,    20] Train acc: 0.906\n",
            "[71,    30] Train loss: 0.237\n",
            "[71,    30] Train acc: 0.934\n",
            "[71,    40] Train loss: 0.237\n",
            "[71,    40] Train acc: 0.900\n",
            "[71,    50] Train loss: 0.264\n",
            "[71,    50] Train acc: 0.906\n",
            "Epoch train accuracy  0.9100215517241379\n",
            "Epoch val accuracy  0.7732342007434945\n",
            "[72,    10] Train loss: 0.326\n",
            "[72,    10] Train acc: 0.866\n",
            "[72,    20] Train loss: 0.320\n",
            "[72,    20] Train acc: 0.891\n",
            "[72,    30] Train loss: 0.227\n",
            "[72,    30] Train acc: 0.906\n",
            "[72,    40] Train loss: 0.296\n",
            "[72,    40] Train acc: 0.887\n",
            "[72,    50] Train loss: 0.255\n",
            "[72,    50] Train acc: 0.887\n",
            "Epoch train accuracy  0.8884698275862069\n",
            "Epoch val accuracy  0.8128872366790583\n",
            "[73,    10] Train loss: 0.179\n",
            "[73,    10] Train acc: 0.944\n",
            "[73,    20] Train loss: 0.191\n",
            "[73,    20] Train acc: 0.941\n",
            "[73,    30] Train loss: 0.274\n",
            "[73,    30] Train acc: 0.919\n",
            "[73,    40] Train loss: 0.233\n",
            "[73,    40] Train acc: 0.909\n",
            "[73,    50] Train loss: 0.280\n",
            "[73,    50] Train acc: 0.912\n",
            "Epoch train accuracy  0.9213362068965517\n",
            "Epoch val accuracy  0.8203221809169765\n",
            "[74,    10] Train loss: 0.234\n",
            "[74,    10] Train acc: 0.922\n",
            "[74,    20] Train loss: 0.142\n",
            "[74,    20] Train acc: 0.956\n",
            "[74,    30] Train loss: 0.320\n",
            "[74,    30] Train acc: 0.872\n",
            "[74,    40] Train loss: 0.284\n",
            "[74,    40] Train acc: 0.906\n",
            "[74,    50] Train loss: 0.331\n",
            "[74,    50] Train acc: 0.875\n",
            "Epoch train accuracy  0.9105603448275862\n",
            "Epoch val accuracy  0.8364312267657993\n",
            "[75,    10] Train loss: 0.177\n",
            "[75,    10] Train acc: 0.947\n",
            "[75,    20] Train loss: 0.211\n",
            "[75,    20] Train acc: 0.928\n",
            "[75,    30] Train loss: 0.280\n",
            "[75,    30] Train acc: 0.906\n",
            "[75,    40] Train loss: 0.230\n",
            "[75,    40] Train acc: 0.925\n",
            "[75,    50] Train loss: 0.256\n",
            "[75,    50] Train acc: 0.912\n",
            "Epoch train accuracy  0.9224137931034483\n",
            "Epoch val accuracy  0.7930607187112764\n",
            "[76,    10] Train loss: 0.275\n",
            "[76,    10] Train acc: 0.894\n",
            "[76,    20] Train loss: 0.212\n",
            "[76,    20] Train acc: 0.934\n",
            "[76,    30] Train loss: 0.281\n",
            "[76,    30] Train acc: 0.922\n",
            "[76,    40] Train loss: 0.196\n",
            "[76,    40] Train acc: 0.925\n",
            "[76,    50] Train loss: 0.309\n",
            "[76,    50] Train acc: 0.881\n",
            "Epoch train accuracy  0.9094827586206896\n",
            "Epoch val accuracy  0.7955390334572491\n",
            "[77,    10] Train loss: 0.245\n",
            "[77,    10] Train acc: 0.919\n",
            "[77,    20] Train loss: 0.255\n",
            "[77,    20] Train acc: 0.909\n",
            "[77,    30] Train loss: 0.302\n",
            "[77,    30] Train acc: 0.897\n",
            "[77,    40] Train loss: 0.171\n",
            "[77,    40] Train acc: 0.938\n",
            "[77,    50] Train loss: 0.260\n",
            "[77,    50] Train acc: 0.900\n",
            "Epoch train accuracy  0.9170258620689655\n",
            "Epoch val accuracy  0.8029739776951673\n",
            "[78,    10] Train loss: 0.149\n",
            "[78,    10] Train acc: 0.956\n",
            "[78,    20] Train loss: 0.229\n",
            "[78,    20] Train acc: 0.909\n",
            "[78,    30] Train loss: 0.302\n",
            "[78,    30] Train acc: 0.887\n",
            "[78,    40] Train loss: 0.185\n",
            "[78,    40] Train acc: 0.938\n",
            "[78,    50] Train loss: 0.223\n",
            "[78,    50] Train acc: 0.916\n",
            "Epoch train accuracy  0.921875\n",
            "Epoch val accuracy  0.838909541511772\n",
            "[79,    10] Train loss: 0.154\n",
            "[79,    10] Train acc: 0.944\n",
            "[79,    20] Train loss: 0.163\n",
            "[79,    20] Train acc: 0.944\n",
            "[79,    30] Train loss: 0.243\n",
            "[79,    30] Train acc: 0.928\n",
            "[79,    40] Train loss: 0.265\n",
            "[79,    40] Train acc: 0.897\n",
            "[79,    50] Train loss: 0.243\n",
            "[79,    50] Train acc: 0.912\n",
            "Epoch train accuracy  0.921875\n",
            "Epoch val accuracy  0.8277571251548946\n",
            "[80,    10] Train loss: 0.246\n",
            "[80,    10] Train acc: 0.909\n",
            "[80,    20] Train loss: 0.207\n",
            "[80,    20] Train acc: 0.938\n",
            "[80,    30] Train loss: 0.149\n",
            "[80,    30] Train acc: 0.953\n",
            "[80,    40] Train loss: 0.191\n",
            "[80,    40] Train acc: 0.944\n",
            "[80,    50] Train loss: 0.181\n",
            "[80,    50] Train acc: 0.919\n",
            "Epoch train accuracy  0.9326508620689655\n",
            "Epoch val accuracy  0.8215613382899628\n",
            "[81,    10] Train loss: 0.159\n",
            "[81,    10] Train acc: 0.944\n",
            "[81,    20] Train loss: 0.170\n",
            "[81,    20] Train acc: 0.941\n",
            "[81,    30] Train loss: 0.180\n",
            "[81,    30] Train acc: 0.947\n",
            "[81,    40] Train loss: 0.226\n",
            "[81,    40] Train acc: 0.922\n",
            "[81,    50] Train loss: 0.195\n",
            "[81,    50] Train acc: 0.916\n",
            "Epoch train accuracy  0.9261853448275862\n",
            "Epoch val accuracy  0.7980173482032218\n",
            "[82,    10] Train loss: 0.187\n",
            "[82,    10] Train acc: 0.922\n",
            "[82,    20] Train loss: 0.218\n",
            "[82,    20] Train acc: 0.928\n",
            "[82,    30] Train loss: 0.278\n",
            "[82,    30] Train acc: 0.909\n",
            "[82,    40] Train loss: 0.196\n",
            "[82,    40] Train acc: 0.938\n",
            "[82,    50] Train loss: 0.237\n",
            "[82,    50] Train acc: 0.919\n",
            "Epoch train accuracy  0.9213362068965517\n",
            "Epoch val accuracy  0.7843866171003717\n",
            "[83,    10] Train loss: 0.233\n",
            "[83,    10] Train acc: 0.919\n",
            "[83,    20] Train loss: 0.198\n",
            "[83,    20] Train acc: 0.928\n",
            "[83,    30] Train loss: 0.250\n",
            "[83,    30] Train acc: 0.900\n",
            "[83,    40] Train loss: 0.233\n",
            "[83,    40] Train acc: 0.912\n",
            "[83,    50] Train loss: 0.257\n",
            "[83,    50] Train acc: 0.925\n",
            "Epoch train accuracy  0.9186422413793104\n",
            "Epoch val accuracy  0.8104089219330854\n",
            "[84,    10] Train loss: 0.116\n",
            "[84,    10] Train acc: 0.959\n",
            "[84,    20] Train loss: 0.189\n",
            "[84,    20] Train acc: 0.941\n",
            "[84,    30] Train loss: 0.158\n",
            "[84,    30] Train acc: 0.944\n",
            "[84,    40] Train loss: 0.187\n",
            "[84,    40] Train acc: 0.941\n",
            "[84,    50] Train loss: 0.246\n",
            "[84,    50] Train acc: 0.919\n",
            "Epoch train accuracy  0.9401939655172413\n",
            "Epoch val accuracy  0.8215613382899628\n",
            "[85,    10] Train loss: 0.115\n",
            "[85,    10] Train acc: 0.966\n",
            "[85,    20] Train loss: 0.186\n",
            "[85,    20] Train acc: 0.934\n",
            "[85,    30] Train loss: 0.251\n",
            "[85,    30] Train acc: 0.906\n",
            "[85,    40] Train loss: 0.359\n",
            "[85,    40] Train acc: 0.881\n",
            "[85,    50] Train loss: 0.282\n",
            "[85,    50] Train acc: 0.903\n",
            "Epoch train accuracy  0.9164870689655172\n",
            "Epoch val accuracy  0.8178438661710037\n",
            "[86,    10] Train loss: 0.192\n",
            "[86,    10] Train acc: 0.925\n",
            "[86,    20] Train loss: 0.185\n",
            "[86,    20] Train acc: 0.931\n",
            "[86,    30] Train loss: 0.206\n",
            "[86,    30] Train acc: 0.925\n",
            "[86,    40] Train loss: 0.204\n",
            "[86,    40] Train acc: 0.938\n",
            "[86,    50] Train loss: 0.223\n",
            "[86,    50] Train acc: 0.906\n",
            "Epoch train accuracy  0.9267241379310345\n",
            "Epoch val accuracy  0.8277571251548946\n",
            "[87,    10] Train loss: 0.160\n",
            "[87,    10] Train acc: 0.941\n",
            "[87,    20] Train loss: 0.219\n",
            "[87,    20] Train acc: 0.934\n",
            "[87,    30] Train loss: 0.243\n",
            "[87,    30] Train acc: 0.912\n",
            "[87,    40] Train loss: 0.165\n",
            "[87,    40] Train acc: 0.944\n",
            "[87,    50] Train loss: 0.225\n",
            "[87,    50] Train acc: 0.944\n",
            "Epoch train accuracy  0.9326508620689655\n",
            "Epoch val accuracy  0.8178438661710037\n",
            "[88,    10] Train loss: 0.153\n",
            "[88,    10] Train acc: 0.963\n",
            "[88,    20] Train loss: 0.187\n",
            "[88,    20] Train acc: 0.950\n",
            "[88,    30] Train loss: 0.172\n",
            "[88,    30] Train acc: 0.953\n",
            "[88,    40] Train loss: 0.124\n",
            "[88,    40] Train acc: 0.959\n",
            "[88,    50] Train loss: 0.170\n",
            "[88,    50] Train acc: 0.941\n",
            "Epoch train accuracy  0.9498922413793104\n",
            "Epoch val accuracy  0.8265179677819083\n",
            "[89,    10] Train loss: 0.188\n",
            "[89,    10] Train acc: 0.931\n",
            "[89,    20] Train loss: 0.194\n",
            "[89,    20] Train acc: 0.928\n",
            "[89,    30] Train loss: 0.173\n",
            "[89,    30] Train acc: 0.928\n",
            "[89,    40] Train loss: 0.197\n",
            "[89,    40] Train acc: 0.934\n",
            "[89,    50] Train loss: 0.154\n",
            "[89,    50] Train acc: 0.956\n",
            "Epoch train accuracy  0.9358836206896551\n",
            "Epoch val accuracy  0.8190830235439901\n",
            "[90,    10] Train loss: 0.176\n",
            "[90,    10] Train acc: 0.938\n",
            "[90,    20] Train loss: 0.235\n",
            "[90,    20] Train acc: 0.928\n",
            "[90,    30] Train loss: 0.185\n",
            "[90,    30] Train acc: 0.934\n",
            "[90,    40] Train loss: 0.225\n",
            "[90,    40] Train acc: 0.941\n",
            "[90,    50] Train loss: 0.268\n",
            "[90,    50] Train acc: 0.919\n",
            "Epoch train accuracy  0.9294181034482759\n",
            "Epoch val accuracy  0.7967781908302355\n",
            "[91,    10] Train loss: 0.287\n",
            "[91,    10] Train acc: 0.897\n",
            "[91,    20] Train loss: 0.193\n",
            "[91,    20] Train acc: 0.925\n",
            "[91,    30] Train loss: 0.210\n",
            "[91,    30] Train acc: 0.912\n",
            "[91,    40] Train loss: 0.300\n",
            "[91,    40] Train acc: 0.891\n",
            "[91,    50] Train loss: 0.224\n",
            "[91,    50] Train acc: 0.922\n",
            "Epoch train accuracy  0.9110991379310345\n",
            "Epoch val accuracy  0.8166047087980174\n",
            "[92,    10] Train loss: 0.181\n",
            "[92,    10] Train acc: 0.922\n",
            "[92,    20] Train loss: 0.161\n",
            "[92,    20] Train acc: 0.944\n",
            "[92,    30] Train loss: 0.219\n",
            "[92,    30] Train acc: 0.941\n",
            "[92,    40] Train loss: 0.227\n",
            "[92,    40] Train acc: 0.931\n",
            "[92,    50] Train loss: 0.185\n",
            "[92,    50] Train acc: 0.944\n",
            "Epoch train accuracy  0.9337284482758621\n",
            "Epoch val accuracy  0.828996282527881\n",
            "[93,    10] Train loss: 0.207\n",
            "[93,    10] Train acc: 0.919\n",
            "[93,    20] Train loss: 0.156\n",
            "[93,    20] Train acc: 0.941\n",
            "[93,    30] Train loss: 0.154\n",
            "[93,    30] Train acc: 0.947\n",
            "[93,    40] Train loss: 0.175\n",
            "[93,    40] Train acc: 0.931\n",
            "[93,    50] Train loss: 0.118\n",
            "[93,    50] Train acc: 0.959\n",
            "Epoch train accuracy  0.9412715517241379\n",
            "Epoch val accuracy  0.80545229244114\n",
            "[94,    10] Train loss: 0.136\n",
            "[94,    10] Train acc: 0.944\n",
            "[94,    20] Train loss: 0.184\n",
            "[94,    20] Train acc: 0.947\n",
            "[94,    30] Train loss: 0.187\n",
            "[94,    30] Train acc: 0.950\n",
            "[94,    40] Train loss: 0.170\n",
            "[94,    40] Train acc: 0.931\n",
            "[94,    50] Train loss: 0.153\n",
            "[94,    50] Train acc: 0.934\n",
            "Epoch train accuracy  0.9412715517241379\n",
            "Epoch val accuracy  0.8079306071871127\n",
            "[95,    10] Train loss: 0.144\n",
            "[95,    10] Train acc: 0.944\n",
            "[95,    20] Train loss: 0.125\n",
            "[95,    20] Train acc: 0.956\n",
            "[95,    30] Train loss: 0.157\n",
            "[95,    30] Train acc: 0.934\n",
            "[95,    40] Train loss: 0.178\n",
            "[95,    40] Train acc: 0.938\n",
            "[95,    50] Train loss: 0.151\n",
            "[95,    50] Train acc: 0.944\n",
            "Epoch train accuracy  0.9412715517241379\n",
            "Epoch val accuracy  0.8265179677819083\n",
            "[96,    10] Train loss: 0.126\n",
            "[96,    10] Train acc: 0.947\n",
            "[96,    20] Train loss: 0.116\n",
            "[96,    20] Train acc: 0.963\n",
            "[96,    30] Train loss: 0.131\n",
            "[96,    30] Train acc: 0.950\n",
            "[96,    40] Train loss: 0.137\n",
            "[96,    40] Train acc: 0.950\n",
            "[96,    50] Train loss: 0.177\n",
            "[96,    50] Train acc: 0.928\n",
            "Epoch train accuracy  0.9466594827586207\n",
            "Epoch val accuracy  0.8203221809169765\n",
            "[97,    10] Train loss: 0.112\n",
            "[97,    10] Train acc: 0.959\n",
            "[97,    20] Train loss: 0.149\n",
            "[97,    20] Train acc: 0.953\n",
            "[97,    30] Train loss: 0.104\n",
            "[97,    30] Train acc: 0.969\n",
            "[97,    40] Train loss: 0.072\n",
            "[97,    40] Train acc: 0.991\n",
            "[97,    50] Train loss: 0.083\n",
            "[97,    50] Train acc: 0.981\n",
            "Epoch train accuracy  0.9698275862068966\n",
            "Epoch val accuracy  0.828996282527881\n",
            "[98,    10] Train loss: 0.078\n",
            "[98,    10] Train acc: 0.969\n",
            "[98,    20] Train loss: 0.101\n",
            "[98,    20] Train acc: 0.966\n",
            "[98,    30] Train loss: 0.116\n",
            "[98,    30] Train acc: 0.953\n",
            "[98,    40] Train loss: 0.077\n",
            "[98,    40] Train acc: 0.981\n",
            "[98,    50] Train loss: 0.131\n",
            "[98,    50] Train acc: 0.959\n",
            "Epoch train accuracy  0.9649784482758621\n",
            "Epoch val accuracy  0.8265179677819083\n",
            "[99,    10] Train loss: 0.161\n",
            "[99,    10] Train acc: 0.941\n",
            "[99,    20] Train loss: 0.173\n",
            "[99,    20] Train acc: 0.944\n",
            "[99,    30] Train loss: 0.220\n",
            "[99,    30] Train acc: 0.922\n",
            "[99,    40] Train loss: 0.192\n",
            "[99,    40] Train acc: 0.938\n",
            "[99,    50] Train loss: 0.195\n",
            "[99,    50] Train acc: 0.931\n",
            "Epoch train accuracy  0.9396551724137931\n",
            "Epoch val accuracy  0.8042131350681536\n",
            "[100,    10] Train loss: 0.108\n",
            "[100,    10] Train acc: 0.966\n",
            "[100,    20] Train loss: 0.109\n",
            "[100,    20] Train acc: 0.969\n",
            "[100,    30] Train loss: 0.119\n",
            "[100,    30] Train acc: 0.959\n",
            "[100,    40] Train loss: 0.245\n",
            "[100,    40] Train acc: 0.938\n",
            "[100,    50] Train loss: 0.200\n",
            "[100,    50] Train acc: 0.912\n",
            "Epoch train accuracy  0.9450431034482759\n",
            "Epoch val accuracy  0.8004956629491945\n",
            "[101,    10] Train loss: 0.164\n",
            "[101,    10] Train acc: 0.941\n",
            "[101,    20] Train loss: 0.121\n",
            "[101,    20] Train acc: 0.963\n",
            "[101,    30] Train loss: 0.144\n",
            "[101,    30] Train acc: 0.941\n",
            "[101,    40] Train loss: 0.148\n",
            "[101,    40] Train acc: 0.938\n",
            "[101,    50] Train loss: 0.172\n",
            "[101,    50] Train acc: 0.941\n",
            "Epoch train accuracy  0.9418103448275862\n",
            "Epoch val accuracy  0.8128872366790583\n",
            "[102,    10] Train loss: 0.092\n",
            "[102,    10] Train acc: 0.975\n",
            "[102,    20] Train loss: 0.133\n",
            "[102,    20] Train acc: 0.953\n",
            "[102,    30] Train loss: 0.175\n",
            "[102,    30] Train acc: 0.950\n",
            "[102,    40] Train loss: 0.172\n",
            "[102,    40] Train acc: 0.950\n",
            "[102,    50] Train loss: 0.168\n",
            "[102,    50] Train acc: 0.931\n",
            "Epoch train accuracy  0.9504310344827587\n",
            "Epoch val accuracy  0.8252788104089219\n",
            "[103,    10] Train loss: 0.115\n",
            "[103,    10] Train acc: 0.972\n",
            "[103,    20] Train loss: 0.096\n",
            "[103,    20] Train acc: 0.966\n",
            "[103,    30] Train loss: 0.118\n",
            "[103,    30] Train acc: 0.959\n",
            "[103,    40] Train loss: 0.128\n",
            "[103,    40] Train acc: 0.953\n",
            "[103,    50] Train loss: 0.130\n",
            "[103,    50] Train acc: 0.966\n",
            "Epoch train accuracy  0.9644396551724138\n",
            "Epoch val accuracy  0.8104089219330854\n",
            "[104,    10] Train loss: 0.151\n",
            "[104,    10] Train acc: 0.938\n",
            "[104,    20] Train loss: 0.124\n",
            "[104,    20] Train acc: 0.947\n",
            "[104,    30] Train loss: 0.129\n",
            "[104,    30] Train acc: 0.959\n",
            "[104,    40] Train loss: 0.135\n",
            "[104,    40] Train acc: 0.963\n",
            "[104,    50] Train loss: 0.103\n",
            "[104,    50] Train acc: 0.963\n",
            "Epoch train accuracy  0.9542025862068966\n",
            "Epoch val accuracy  0.8327137546468402\n",
            "[105,    10] Train loss: 0.165\n",
            "[105,    10] Train acc: 0.950\n",
            "[105,    20] Train loss: 0.128\n",
            "[105,    20] Train acc: 0.947\n",
            "[105,    30] Train loss: 0.133\n",
            "[105,    30] Train acc: 0.956\n",
            "[105,    40] Train loss: 0.106\n",
            "[105,    40] Train acc: 0.975\n",
            "[105,    50] Train loss: 0.166\n",
            "[105,    50] Train acc: 0.931\n",
            "Epoch train accuracy  0.9482758620689655\n",
            "Epoch val accuracy  0.8042131350681536\n",
            "[106,    10] Train loss: 0.155\n",
            "[106,    10] Train acc: 0.950\n",
            "[106,    20] Train loss: 0.195\n",
            "[106,    20] Train acc: 0.931\n",
            "[106,    30] Train loss: 0.204\n",
            "[106,    30] Train acc: 0.928\n",
            "[106,    40] Train loss: 0.135\n",
            "[106,    40] Train acc: 0.938\n",
            "[106,    50] Train loss: 0.157\n",
            "[106,    50] Train acc: 0.944\n",
            "Epoch train accuracy  0.9423491379310345\n",
            "Epoch val accuracy  0.8302354399008675\n",
            "[107,    10] Train loss: 0.108\n",
            "[107,    10] Train acc: 0.959\n",
            "[107,    20] Train loss: 0.067\n",
            "[107,    20] Train acc: 0.984\n",
            "[107,    30] Train loss: 0.106\n",
            "[107,    30] Train acc: 0.963\n",
            "[107,    40] Train loss: 0.107\n",
            "[107,    40] Train acc: 0.966\n",
            "[107,    50] Train loss: 0.082\n",
            "[107,    50] Train acc: 0.966\n",
            "Epoch train accuracy  0.9709051724137931\n",
            "Epoch val accuracy  0.8141263940520446\n",
            "[108,    10] Train loss: 0.053\n",
            "[108,    10] Train acc: 0.981\n",
            "[108,    20] Train loss: 0.075\n",
            "[108,    20] Train acc: 0.975\n",
            "[108,    30] Train loss: 0.077\n",
            "[108,    30] Train acc: 0.975\n",
            "[108,    40] Train loss: 0.107\n",
            "[108,    40] Train acc: 0.953\n",
            "[108,    50] Train loss: 0.120\n",
            "[108,    50] Train acc: 0.947\n",
            "Epoch train accuracy  0.9617456896551724\n",
            "Epoch val accuracy  0.8190830235439901\n",
            "[109,    10] Train loss: 0.143\n",
            "[109,    10] Train acc: 0.947\n",
            "[109,    20] Train loss: 0.125\n",
            "[109,    20] Train acc: 0.972\n",
            "[109,    30] Train loss: 0.106\n",
            "[109,    30] Train acc: 0.959\n",
            "[109,    40] Train loss: 0.087\n",
            "[109,    40] Train acc: 0.975\n",
            "[109,    50] Train loss: 0.119\n",
            "[109,    50] Train acc: 0.966\n",
            "Epoch train accuracy  0.9612068965517241\n",
            "Epoch val accuracy  0.8128872366790583\n",
            "[110,    10] Train loss: 0.096\n",
            "[110,    10] Train acc: 0.959\n",
            "[110,    20] Train loss: 0.106\n",
            "[110,    20] Train acc: 0.963\n",
            "[110,    30] Train loss: 0.066\n",
            "[110,    30] Train acc: 0.984\n",
            "[110,    40] Train loss: 0.096\n",
            "[110,    40] Train acc: 0.959\n",
            "[110,    50] Train loss: 0.194\n",
            "[110,    50] Train acc: 0.938\n",
            "Epoch train accuracy  0.9612068965517241\n",
            "Epoch val accuracy  0.8042131350681536\n",
            "[111,    10] Train loss: 0.088\n",
            "[111,    10] Train acc: 0.975\n",
            "[111,    20] Train loss: 0.098\n",
            "[111,    20] Train acc: 0.963\n",
            "[111,    30] Train loss: 0.091\n",
            "[111,    30] Train acc: 0.966\n",
            "[111,    40] Train loss: 0.084\n",
            "[111,    40] Train acc: 0.975\n",
            "[111,    50] Train loss: 0.081\n",
            "[111,    50] Train acc: 0.969\n",
            "Epoch train accuracy  0.9698275862068966\n",
            "Epoch val accuracy  0.80545229244114\n",
            "[112,    10] Train loss: 0.093\n",
            "[112,    10] Train acc: 0.959\n",
            "[112,    20] Train loss: 0.097\n",
            "[112,    20] Train acc: 0.963\n",
            "[112,    30] Train loss: 0.088\n",
            "[112,    30] Train acc: 0.978\n",
            "[112,    40] Train loss: 0.123\n",
            "[112,    40] Train acc: 0.963\n",
            "[112,    50] Train loss: 0.104\n",
            "[112,    50] Train acc: 0.959\n",
            "Epoch train accuracy  0.9644396551724138\n",
            "Epoch val accuracy  0.8215613382899628\n",
            "[113,    10] Train loss: 0.046\n",
            "[113,    10] Train acc: 0.988\n",
            "[113,    20] Train loss: 0.112\n",
            "[113,    20] Train acc: 0.966\n",
            "[113,    30] Train loss: 0.162\n",
            "[113,    30] Train acc: 0.938\n",
            "[113,    40] Train loss: 0.143\n",
            "[113,    40] Train acc: 0.953\n",
            "[113,    50] Train loss: 0.161\n",
            "[113,    50] Train acc: 0.947\n",
            "Epoch train accuracy  0.9579741379310345\n",
            "Epoch val accuracy  0.8066914498141264\n",
            "[114,    10] Train loss: 0.172\n",
            "[114,    10] Train acc: 0.941\n",
            "[114,    20] Train loss: 0.092\n",
            "[114,    20] Train acc: 0.969\n",
            "[114,    30] Train loss: 0.155\n",
            "[114,    30] Train acc: 0.950\n",
            "[114,    40] Train loss: 0.158\n",
            "[114,    40] Train acc: 0.941\n",
            "[114,    50] Train loss: 0.171\n",
            "[114,    50] Train acc: 0.941\n",
            "Epoch train accuracy  0.9428879310344828\n",
            "Epoch val accuracy  0.8091697645600991\n",
            "[115,    10] Train loss: 0.254\n",
            "[115,    10] Train acc: 0.922\n",
            "[115,    20] Train loss: 0.193\n",
            "[115,    20] Train acc: 0.931\n",
            "[115,    30] Train loss: 0.152\n",
            "[115,    30] Train acc: 0.947\n",
            "[115,    40] Train loss: 0.244\n",
            "[115,    40] Train acc: 0.928\n",
            "[115,    50] Train loss: 0.176\n",
            "[115,    50] Train acc: 0.944\n",
            "Epoch train accuracy  0.9385775862068966\n",
            "Epoch val accuracy  0.7843866171003717\n",
            "[116,    10] Train loss: 0.135\n",
            "[116,    10] Train acc: 0.953\n",
            "[116,    20] Train loss: 0.099\n",
            "[116,    20] Train acc: 0.966\n",
            "[116,    30] Train loss: 0.069\n",
            "[116,    30] Train acc: 0.969\n",
            "[116,    40] Train loss: 0.073\n",
            "[116,    40] Train acc: 0.966\n",
            "[116,    50] Train loss: 0.107\n",
            "[116,    50] Train acc: 0.959\n",
            "Epoch train accuracy  0.9617456896551724\n",
            "Epoch val accuracy  0.8178438661710037\n",
            "[117,    10] Train loss: 0.052\n",
            "[117,    10] Train acc: 0.991\n",
            "[117,    20] Train loss: 0.085\n",
            "[117,    20] Train acc: 0.963\n",
            "[117,    30] Train loss: 0.112\n",
            "[117,    30] Train acc: 0.963\n",
            "[117,    40] Train loss: 0.113\n",
            "[117,    40] Train acc: 0.953\n",
            "[117,    50] Train loss: 0.112\n",
            "[117,    50] Train acc: 0.956\n",
            "Epoch train accuracy  0.9639008620689655\n",
            "Epoch val accuracy  0.8029739776951673\n",
            "[118,    10] Train loss: 0.160\n",
            "[118,    10] Train acc: 0.934\n",
            "[118,    20] Train loss: 0.161\n",
            "[118,    20] Train acc: 0.944\n",
            "[118,    30] Train loss: 0.138\n",
            "[118,    30] Train acc: 0.941\n",
            "[118,    40] Train loss: 0.127\n",
            "[118,    40] Train acc: 0.953\n",
            "[118,    50] Train loss: 0.175\n",
            "[118,    50] Train acc: 0.941\n",
            "Epoch train accuracy  0.9439655172413793\n",
            "Epoch val accuracy  0.8166047087980174\n",
            "[119,    10] Train loss: 0.099\n",
            "[119,    10] Train acc: 0.966\n",
            "[119,    20] Train loss: 0.083\n",
            "[119,    20] Train acc: 0.978\n",
            "[119,    30] Train loss: 0.082\n",
            "[119,    30] Train acc: 0.978\n",
            "[119,    40] Train loss: 0.115\n",
            "[119,    40] Train acc: 0.956\n",
            "[119,    50] Train loss: 0.110\n",
            "[119,    50] Train acc: 0.956\n",
            "Epoch train accuracy  0.9649784482758621\n",
            "Epoch val accuracy  0.8190830235439901\n",
            "[120,    10] Train loss: 0.099\n",
            "[120,    10] Train acc: 0.953\n",
            "[120,    20] Train loss: 0.090\n",
            "[120,    20] Train acc: 0.975\n",
            "[120,    30] Train loss: 0.076\n",
            "[120,    30] Train acc: 0.972\n",
            "[120,    40] Train loss: 0.074\n",
            "[120,    40] Train acc: 0.969\n",
            "[120,    50] Train loss: 0.073\n",
            "[120,    50] Train acc: 0.972\n",
            "Epoch train accuracy  0.9703663793103449\n",
            "Epoch val accuracy  0.80545229244114\n",
            "[121,    10] Train loss: 0.078\n",
            "[121,    10] Train acc: 0.969\n",
            "[121,    20] Train loss: 0.096\n",
            "[121,    20] Train acc: 0.966\n",
            "[121,    30] Train loss: 0.177\n",
            "[121,    30] Train acc: 0.947\n",
            "[121,    40] Train loss: 0.135\n",
            "[121,    40] Train acc: 0.956\n",
            "[121,    50] Train loss: 0.099\n",
            "[121,    50] Train acc: 0.959\n",
            "Epoch train accuracy  0.9595905172413793\n",
            "Epoch val accuracy  0.80545229244114\n",
            "[122,    10] Train loss: 0.069\n",
            "[122,    10] Train acc: 0.984\n",
            "[122,    20] Train loss: 0.189\n",
            "[122,    20] Train acc: 0.916\n",
            "[122,    30] Train loss: 0.110\n",
            "[122,    30] Train acc: 0.959\n",
            "[122,    40] Train loss: 0.056\n",
            "[122,    40] Train acc: 0.981\n",
            "[122,    50] Train loss: 0.072\n",
            "[122,    50] Train acc: 0.975\n",
            "Epoch train accuracy  0.9665948275862069\n",
            "Epoch val accuracy  0.8178438661710037\n",
            "[123,    10] Train loss: 0.051\n",
            "[123,    10] Train acc: 0.984\n",
            "[123,    20] Train loss: 0.082\n",
            "[123,    20] Train acc: 0.978\n",
            "[123,    30] Train loss: 0.091\n",
            "[123,    30] Train acc: 0.972\n",
            "[123,    40] Train loss: 0.094\n",
            "[123,    40] Train acc: 0.969\n",
            "[123,    50] Train loss: 0.124\n",
            "[123,    50] Train acc: 0.959\n",
            "Epoch train accuracy  0.9730603448275862\n",
            "Epoch val accuracy  0.7992565055762082\n",
            "[124,    10] Train loss: 0.059\n",
            "[124,    10] Train acc: 0.991\n",
            "[124,    20] Train loss: 0.054\n",
            "[124,    20] Train acc: 0.981\n",
            "[124,    30] Train loss: 0.065\n",
            "[124,    30] Train acc: 0.988\n",
            "[124,    40] Train loss: 0.072\n",
            "[124,    40] Train acc: 0.981\n",
            "[124,    50] Train loss: 0.087\n",
            "[124,    50] Train acc: 0.969\n",
            "Epoch train accuracy  0.9806034482758621\n",
            "Epoch val accuracy  0.8166047087980174\n",
            "[125,    10] Train loss: 0.087\n",
            "[125,    10] Train acc: 0.966\n",
            "[125,    20] Train loss: 0.084\n",
            "[125,    20] Train acc: 0.972\n",
            "[125,    30] Train loss: 0.048\n",
            "[125,    30] Train acc: 0.978\n",
            "[125,    40] Train loss: 0.107\n",
            "[125,    40] Train acc: 0.975\n",
            "[125,    50] Train loss: 0.090\n",
            "[125,    50] Train acc: 0.963\n",
            "Epoch train accuracy  0.9698275862068966\n",
            "Epoch val accuracy  0.8178438661710037\n",
            "[126,    10] Train loss: 0.070\n",
            "[126,    10] Train acc: 0.972\n",
            "[126,    20] Train loss: 0.084\n",
            "[126,    20] Train acc: 0.972\n",
            "[126,    30] Train loss: 0.215\n",
            "[126,    30] Train acc: 0.925\n",
            "[126,    40] Train loss: 0.068\n",
            "[126,    40] Train acc: 0.972\n",
            "[126,    50] Train loss: 0.125\n",
            "[126,    50] Train acc: 0.959\n",
            "Epoch train accuracy  0.9520474137931034\n",
            "Epoch val accuracy  0.8066914498141264\n",
            "[127,    10] Train loss: 0.230\n",
            "[127,    10] Train acc: 0.919\n",
            "[127,    20] Train loss: 0.164\n",
            "[127,    20] Train acc: 0.931\n",
            "[127,    30] Train loss: 0.257\n",
            "[127,    30] Train acc: 0.934\n",
            "[127,    40] Train loss: 0.272\n",
            "[127,    40] Train acc: 0.909\n",
            "[127,    50] Train loss: 0.206\n",
            "[127,    50] Train acc: 0.934\n",
            "Epoch train accuracy  0.9240301724137931\n",
            "Epoch val accuracy  0.8017348203221809\n",
            "[128,    10] Train loss: 0.167\n",
            "[128,    10] Train acc: 0.959\n",
            "[128,    20] Train loss: 0.110\n",
            "[128,    20] Train acc: 0.959\n",
            "[128,    30] Train loss: 0.171\n",
            "[128,    30] Train acc: 0.934\n",
            "[128,    40] Train loss: 0.171\n",
            "[128,    40] Train acc: 0.938\n",
            "[128,    50] Train loss: 0.088\n",
            "[128,    50] Train acc: 0.959\n",
            "Epoch train accuracy  0.953125\n",
            "Epoch val accuracy  0.8116480793060719\n",
            "[129,    10] Train loss: 0.084\n",
            "[129,    10] Train acc: 0.978\n",
            "[129,    20] Train loss: 0.126\n",
            "[129,    20] Train acc: 0.953\n",
            "[129,    30] Train loss: 0.070\n",
            "[129,    30] Train acc: 0.978\n",
            "[129,    40] Train loss: 0.085\n",
            "[129,    40] Train acc: 0.963\n",
            "[129,    50] Train loss: 0.062\n",
            "[129,    50] Train acc: 0.984\n",
            "Epoch train accuracy  0.9735991379310345\n",
            "Epoch val accuracy  0.8252788104089219\n",
            "[130,    10] Train loss: 0.030\n",
            "[130,    10] Train acc: 0.997\n",
            "[130,    20] Train loss: 0.066\n",
            "[130,    20] Train acc: 0.984\n",
            "[130,    30] Train loss: 0.090\n",
            "[130,    30] Train acc: 0.972\n",
            "[130,    40] Train loss: 0.047\n",
            "[130,    40] Train acc: 0.988\n",
            "[130,    50] Train loss: 0.062\n",
            "[130,    50] Train acc: 0.978\n",
            "Epoch train accuracy  0.9859913793103449\n",
            "Epoch val accuracy  0.8215613382899628\n",
            "[131,    10] Train loss: 0.054\n",
            "[131,    10] Train acc: 0.984\n",
            "[131,    20] Train loss: 0.047\n",
            "[131,    20] Train acc: 0.991\n",
            "[131,    30] Train loss: 0.061\n",
            "[131,    30] Train acc: 0.978\n",
            "[131,    40] Train loss: 0.029\n",
            "[131,    40] Train acc: 0.997\n",
            "[131,    50] Train loss: 0.040\n",
            "[131,    50] Train acc: 0.988\n",
            "Epoch train accuracy  0.9876077586206896\n",
            "Epoch val accuracy  0.8240396530359355\n",
            "[132,    10] Train loss: 0.030\n",
            "[132,    10] Train acc: 0.994\n",
            "[132,    20] Train loss: 0.060\n",
            "[132,    20] Train acc: 0.978\n",
            "[132,    30] Train loss: 0.042\n",
            "[132,    30] Train acc: 0.984\n",
            "[132,    40] Train loss: 0.065\n",
            "[132,    40] Train acc: 0.966\n",
            "[132,    50] Train loss: 0.067\n",
            "[132,    50] Train acc: 0.978\n",
            "Epoch train accuracy  0.9806034482758621\n",
            "Epoch val accuracy  0.8277571251548946\n",
            "[133,    10] Train loss: 0.033\n",
            "[133,    10] Train acc: 0.991\n",
            "[133,    20] Train loss: 0.025\n",
            "[133,    20] Train acc: 0.991\n",
            "[133,    30] Train loss: 0.017\n",
            "[133,    30] Train acc: 0.997\n",
            "[133,    40] Train loss: 0.019\n",
            "[133,    40] Train acc: 0.997\n",
            "[133,    50] Train loss: 0.026\n",
            "[133,    50] Train acc: 0.994\n",
            "Epoch train accuracy  0.9946120689655172\n",
            "Epoch val accuracy  0.8339529120198265\n",
            "[134,    10] Train loss: 0.018\n",
            "[134,    10] Train acc: 0.997\n",
            "[134,    20] Train loss: 0.023\n",
            "[134,    20] Train acc: 0.994\n",
            "[134,    30] Train loss: 0.018\n",
            "[134,    30] Train acc: 0.997\n",
            "[134,    40] Train loss: 0.045\n",
            "[134,    40] Train acc: 0.981\n",
            "[134,    50] Train loss: 0.070\n",
            "[134,    50] Train acc: 0.972\n",
            "Epoch train accuracy  0.9859913793103449\n",
            "Epoch val accuracy  0.8178438661710037\n",
            "[135,    10] Train loss: 0.079\n",
            "[135,    10] Train acc: 0.959\n",
            "[135,    20] Train loss: 0.134\n",
            "[135,    20] Train acc: 0.956\n",
            "[135,    30] Train loss: 0.129\n",
            "[135,    30] Train acc: 0.972\n",
            "[135,    40] Train loss: 0.111\n",
            "[135,    40] Train acc: 0.963\n",
            "[135,    50] Train loss: 0.197\n",
            "[135,    50] Train acc: 0.931\n",
            "Epoch train accuracy  0.9595905172413793\n",
            "Epoch val accuracy  0.8166047087980174\n",
            "[136,    10] Train loss: 0.057\n",
            "[136,    10] Train acc: 0.988\n",
            "[136,    20] Train loss: 0.053\n",
            "[136,    20] Train acc: 0.981\n",
            "[136,    30] Train loss: 0.070\n",
            "[136,    30] Train acc: 0.972\n",
            "[136,    40] Train loss: 0.120\n",
            "[136,    40] Train acc: 0.963\n",
            "[136,    50] Train loss: 0.132\n",
            "[136,    50] Train acc: 0.941\n",
            "Epoch train accuracy  0.9660560344827587\n",
            "Epoch val accuracy  0.8141263940520446\n",
            "[137,    10] Train loss: 0.063\n",
            "[137,    10] Train acc: 0.975\n",
            "[137,    20] Train loss: 0.092\n",
            "[137,    20] Train acc: 0.969\n",
            "[137,    30] Train loss: 0.139\n",
            "[137,    30] Train acc: 0.944\n",
            "[137,    40] Train loss: 0.132\n",
            "[137,    40] Train acc: 0.969\n",
            "[137,    50] Train loss: 0.113\n",
            "[137,    50] Train acc: 0.963\n",
            "Epoch train accuracy  0.9612068965517241\n",
            "Epoch val accuracy  0.8104089219330854\n",
            "[138,    10] Train loss: 0.091\n",
            "[138,    10] Train acc: 0.969\n",
            "[138,    20] Train loss: 0.080\n",
            "[138,    20] Train acc: 0.969\n",
            "[138,    30] Train loss: 0.103\n",
            "[138,    30] Train acc: 0.956\n",
            "[138,    40] Train loss: 0.057\n",
            "[138,    40] Train acc: 0.975\n",
            "[138,    50] Train loss: 0.047\n",
            "[138,    50] Train acc: 0.975\n",
            "Epoch train accuracy  0.9698275862068966\n",
            "Epoch val accuracy  0.8104089219330854\n",
            "[139,    10] Train loss: 0.036\n",
            "[139,    10] Train acc: 0.991\n",
            "[139,    20] Train loss: 0.036\n",
            "[139,    20] Train acc: 0.988\n",
            "[139,    30] Train loss: 0.025\n",
            "[139,    30] Train acc: 0.997\n",
            "[139,    40] Train loss: 0.050\n",
            "[139,    40] Train acc: 0.984\n",
            "[139,    50] Train loss: 0.066\n",
            "[139,    50] Train acc: 0.981\n",
            "Epoch train accuracy  0.9865301724137931\n",
            "Epoch val accuracy  0.828996282527881\n",
            "[140,    10] Train loss: 0.040\n",
            "[140,    10] Train acc: 0.984\n",
            "[140,    20] Train loss: 0.055\n",
            "[140,    20] Train acc: 0.981\n",
            "[140,    30] Train loss: 0.052\n",
            "[140,    30] Train acc: 0.978\n",
            "[140,    40] Train loss: 0.070\n",
            "[140,    40] Train acc: 0.969\n",
            "[140,    50] Train loss: 0.054\n",
            "[140,    50] Train acc: 0.984\n",
            "Epoch train accuracy  0.9811422413793104\n",
            "Epoch val accuracy  0.8190830235439901\n",
            "[141,    10] Train loss: 0.063\n",
            "[141,    10] Train acc: 0.978\n",
            "[141,    20] Train loss: 0.076\n",
            "[141,    20] Train acc: 0.978\n",
            "[141,    30] Train loss: 0.107\n",
            "[141,    30] Train acc: 0.963\n",
            "[141,    40] Train loss: 0.146\n",
            "[141,    40] Train acc: 0.938\n",
            "[141,    50] Train loss: 0.105\n",
            "[141,    50] Train acc: 0.972\n",
            "Epoch train accuracy  0.9671336206896551\n",
            "Epoch val accuracy  0.8128872366790583\n",
            "[142,    10] Train loss: 0.056\n",
            "[142,    10] Train acc: 0.975\n",
            "[142,    20] Train loss: 0.050\n",
            "[142,    20] Train acc: 0.988\n",
            "[142,    30] Train loss: 0.080\n",
            "[142,    30] Train acc: 0.966\n",
            "[142,    40] Train loss: 0.103\n",
            "[142,    40] Train acc: 0.963\n",
            "[142,    50] Train loss: 0.126\n",
            "[142,    50] Train acc: 0.956\n",
            "Epoch train accuracy  0.96875\n",
            "Epoch val accuracy  0.8004956629491945\n",
            "[143,    10] Train loss: 0.067\n",
            "[143,    10] Train acc: 0.966\n",
            "[143,    20] Train loss: 0.062\n",
            "[143,    20] Train acc: 0.972\n",
            "[143,    30] Train loss: 0.057\n",
            "[143,    30] Train acc: 0.978\n",
            "[143,    40] Train loss: 0.070\n",
            "[143,    40] Train acc: 0.978\n",
            "[143,    50] Train loss: 0.044\n",
            "[143,    50] Train acc: 0.991\n",
            "Epoch train accuracy  0.9762931034482759\n",
            "Epoch val accuracy  0.8252788104089219\n",
            "[144,    10] Train loss: 0.065\n",
            "[144,    10] Train acc: 0.978\n",
            "[144,    20] Train loss: 0.085\n",
            "[144,    20] Train acc: 0.972\n",
            "[144,    30] Train loss: 0.074\n",
            "[144,    30] Train acc: 0.975\n",
            "[144,    40] Train loss: 0.041\n",
            "[144,    40] Train acc: 0.991\n",
            "[144,    50] Train loss: 0.073\n",
            "[144,    50] Train acc: 0.978\n",
            "Epoch train accuracy  0.9768318965517241\n",
            "Epoch val accuracy  0.8029739776951673\n",
            "[145,    10] Train loss: 0.085\n",
            "[145,    10] Train acc: 0.972\n",
            "[145,    20] Train loss: 0.085\n",
            "[145,    20] Train acc: 0.969\n",
            "[145,    30] Train loss: 0.064\n",
            "[145,    30] Train acc: 0.969\n",
            "[145,    40] Train loss: 0.096\n",
            "[145,    40] Train acc: 0.972\n",
            "[145,    50] Train loss: 0.113\n",
            "[145,    50] Train acc: 0.963\n",
            "Epoch train accuracy  0.9660560344827587\n",
            "Epoch val accuracy  0.8079306071871127\n",
            "[146,    10] Train loss: 0.047\n",
            "[146,    10] Train acc: 0.978\n",
            "[146,    20] Train loss: 0.066\n",
            "[146,    20] Train acc: 0.972\n",
            "[146,    30] Train loss: 0.046\n",
            "[146,    30] Train acc: 0.981\n",
            "[146,    40] Train loss: 0.069\n",
            "[146,    40] Train acc: 0.978\n",
            "[146,    50] Train loss: 0.171\n",
            "[146,    50] Train acc: 0.950\n",
            "Epoch train accuracy  0.9709051724137931\n",
            "Epoch val accuracy  0.8104089219330854\n",
            "[147,    10] Train loss: 0.051\n",
            "[147,    10] Train acc: 0.984\n",
            "[147,    20] Train loss: 0.057\n",
            "[147,    20] Train acc: 0.984\n",
            "[147,    30] Train loss: 0.088\n",
            "[147,    30] Train acc: 0.963\n",
            "[147,    40] Train loss: 0.085\n",
            "[147,    40] Train acc: 0.969\n",
            "[147,    50] Train loss: 0.127\n",
            "[147,    50] Train acc: 0.947\n",
            "Epoch train accuracy  0.9682112068965517\n",
            "Epoch val accuracy  0.7843866171003717\n",
            "[148,    10] Train loss: 0.113\n",
            "[148,    10] Train acc: 0.950\n",
            "[148,    20] Train loss: 0.062\n",
            "[148,    20] Train acc: 0.969\n",
            "[148,    30] Train loss: 0.093\n",
            "[148,    30] Train acc: 0.966\n",
            "[148,    40] Train loss: 0.122\n",
            "[148,    40] Train acc: 0.956\n",
            "[148,    50] Train loss: 0.167\n",
            "[148,    50] Train acc: 0.928\n",
            "Epoch train accuracy  0.9520474137931034\n",
            "Epoch val accuracy  0.7942998760842627\n",
            "[149,    10] Train loss: 0.115\n",
            "[149,    10] Train acc: 0.963\n",
            "[149,    20] Train loss: 0.084\n",
            "[149,    20] Train acc: 0.969\n",
            "[149,    30] Train loss: 0.037\n",
            "[149,    30] Train acc: 0.988\n",
            "[149,    40] Train loss: 0.028\n",
            "[149,    40] Train acc: 0.991\n",
            "[149,    50] Train loss: 0.079\n",
            "[149,    50] Train acc: 0.963\n",
            "Epoch train accuracy  0.9757543103448276\n",
            "Epoch val accuracy  0.8116480793060719\n",
            "[150,    10] Train loss: 0.062\n",
            "[150,    10] Train acc: 0.988\n",
            "[150,    20] Train loss: 0.042\n",
            "[150,    20] Train acc: 0.984\n",
            "[150,    30] Train loss: 0.034\n",
            "[150,    30] Train acc: 0.984\n",
            "[150,    40] Train loss: 0.049\n",
            "[150,    40] Train acc: 0.981\n",
            "[150,    50] Train loss: 0.055\n",
            "[150,    50] Train acc: 0.975\n",
            "Epoch train accuracy  0.9806034482758621\n",
            "Epoch val accuracy  0.80545229244114\n",
            "Finished Training, plotting history...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXCf-PmKszSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = ('Opencountry', 'coast', 'forest', 'highway',\n",
        "           'inside_city', 'mountain', 'street', 'tallbuilding')\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGGU8L_0s9hT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "378c782a-648f-412e-90f8-a3ec19c9e494"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in data_loader_test:\n",
        "        images, labels = data\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 80 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PAGhGV6tEO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "e04f85e0-930e-4f5e-b024-2deb25fbe10a"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in data_loader_test:\n",
        "        images, labels = data\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(NUM_CLASSES):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Opencountry : 81 %\n",
            "Accuracy of coast : 81 %\n",
            "Accuracy of forest : 91 %\n",
            "Accuracy of highway : 87 %\n",
            "Accuracy of inside_city : 100 %\n",
            "Accuracy of mountain : 81 %\n",
            "Accuracy of street : 75 %\n",
            "Accuracy of tallbuilding : 87 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}